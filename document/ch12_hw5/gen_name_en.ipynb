{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac385fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ad04478c70>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in data\n",
    "df = pd.read_csv(\"English_Cn_Name_Corpus（48W）.txt\", header=None, names=[\"name\"], skiprows=2)\n",
    "names = df[\"name\"].values\n",
    "\n",
    "# Compute character frequency\n",
    "chars = [list(name) for name in names]\n",
    "chars_flatten = list(itertools.chain(*chars))\n",
    "freq = collections.Counter(chars_flatten)\n",
    "freq = pd.DataFrame(freq.items(), columns=[\"char\", \"freq\"])\n",
    "freq = freq.sort_values(by=\"freq\", ascending=False)\n",
    "\n",
    "# Frequency distribution\n",
    "char_rank = np.arange(freq.shape[0])\n",
    "char_freq = freq[\"freq\"].values\n",
    "plt.plot(char_rank, char_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7aaca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "dict_size = 50\n",
    "charset_size = dict_size + 1  # for EOS\n",
    "dict = list(freq[\"char\"].values[:dict_size])\n",
    "dict_set = set(dict)\n",
    "dat = list(filter(lambda name: set(name).issubset(dict_set), names))\n",
    "\n",
    "# One-hot encoding\n",
    "def char2index(char):\n",
    "    return dict.index(char)\n",
    "\n",
    "def name2index(name):\n",
    "    return [char2index(char) for char in name]\n",
    "\n",
    "def char2tensor(char):\n",
    "    tensor = torch.zeros(1, charset_size)\n",
    "    tensor[0, char2index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, charset_size)\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i, 0, char2index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "def names2tensor(names):\n",
    "    n = len(names)\n",
    "    lens = [len(name) for name in names]\n",
    "    max_len = np.max(lens)\n",
    "    tensor = torch.zeros(max_len, n, charset_size)\n",
    "    target = torch.zeros(max_len, n, dtype=int) + charset_size - 1\n",
    "    for i in range(n):\n",
    "        name = names[i]             # the i-th name\n",
    "        for j in range(len(name)):  # the j-th character in the name\n",
    "            tensor[j, i, char2index(name[j])] = 1\n",
    "            if j < len(name) - 1:\n",
    "                target[j, i] = char2index(name[j + 1])\n",
    "    return tensor, np.array(lens), target\n",
    "\n",
    "char2index(\"斯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764e46bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 17]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2index(\"斯基\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6f59bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2tensor(\"斯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a27e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tensor(\"斯基\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6881233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " array([2, 3]),\n",
       " tensor([[17, 28],\n",
       "         [50,  7],\n",
       "         [50, 50]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names2tensor([\"斯基\", \"斯诺夫\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b323584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, input_size)\n",
    "        self.o2o = nn.Linear(hidden_size + input_size, input_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.relu(self.i2h(input_combined))\n",
    "        output = torch.relu(self.i2o(input_combined))\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.logsoftmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a752a4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.9285, -3.9483, -4.0047, -3.8546, -3.9290, -3.8550, -4.0007, -3.9343,\n",
       "         -3.8665, -3.8373, -3.9946, -4.0264, -3.9087, -4.0209, -3.9290, -3.9034,\n",
       "         -3.9888, -3.8718, -3.9290, -3.8218, -3.9290, -3.9596, -3.9290, -3.9062,\n",
       "         -3.9237, -3.9429, -3.9491, -3.9066, -3.9202, -4.0143, -3.8407, -3.8687,\n",
       "         -3.9293, -4.0459, -3.9319, -4.0004, -3.8999, -3.8910, -3.9484, -3.9278,\n",
       "         -3.9379, -3.8882, -3.9789, -3.9738, -4.0340, -4.0063, -3.8449, -3.9975,\n",
       "         -3.8641, -3.9290, -3.9290]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 64\n",
    "rnn = RNN(charset_size, n_hidden)\n",
    "input = name2tensor(\"斯基\")\n",
    "hidden = rnn.init_hidden(batch_size=1)\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e82b8c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, loss = 3.9328794479370117\n",
      "epoch 0, batch 10, loss = 3.537919521331787\n",
      "epoch 0, batch 20, loss = 3.2228903770446777\n",
      "epoch 0, batch 30, loss = 3.178758382797241\n",
      "epoch 0, batch 40, loss = 3.1477208137512207\n",
      "epoch 0, batch 50, loss = 3.12373948097229\n",
      "epoch 0, batch 60, loss = 3.138552188873291\n",
      "epoch 0, batch 70, loss = 3.149634838104248\n",
      "epoch 0, batch 80, loss = 3.134317398071289\n",
      "epoch 0, batch 90, loss = 3.1014957427978516\n",
      "epoch 0, batch 100, loss = 3.089360237121582\n",
      "epoch 0, batch 110, loss = 3.09610915184021\n",
      "epoch 0, batch 120, loss = 3.074462652206421\n",
      "epoch 0, batch 130, loss = 3.0096940994262695\n",
      "epoch 0, batch 140, loss = 3.0294103622436523\n",
      "epoch 0, batch 150, loss = 3.0045087337493896\n",
      "epoch 0, batch 160, loss = 3.027930974960327\n",
      "epoch 0, batch 170, loss = 3.004671573638916\n",
      "epoch 0, batch 180, loss = 2.9816555976867676\n",
      "epoch 0, batch 190, loss = 2.985799789428711\n",
      "epoch 0, batch 200, loss = 2.9343924522399902\n",
      "epoch 0, batch 210, loss = 2.935732364654541\n",
      "epoch 0, batch 220, loss = 2.993732452392578\n",
      "epoch 0, batch 230, loss = 2.948269844055176\n",
      "epoch 0, batch 240, loss = 2.96951961517334\n",
      "epoch 0, batch 250, loss = 2.9601287841796875\n",
      "epoch 0, batch 260, loss = 2.952899932861328\n",
      "epoch 0, batch 270, loss = 2.918787717819214\n",
      "epoch 0, batch 280, loss = 2.9072446823120117\n",
      "epoch 1, batch 0, loss = 2.9066872596740723\n",
      "epoch 1, batch 10, loss = 2.9431591033935547\n",
      "epoch 1, batch 20, loss = 2.9389150142669678\n",
      "epoch 1, batch 30, loss = 2.883023738861084\n",
      "epoch 1, batch 40, loss = 2.91510009765625\n",
      "epoch 1, batch 50, loss = 2.8801960945129395\n",
      "epoch 1, batch 60, loss = 2.902470111846924\n",
      "epoch 1, batch 70, loss = 2.9162583351135254\n",
      "epoch 1, batch 80, loss = 2.9270167350769043\n",
      "epoch 1, batch 90, loss = 2.8500280380249023\n",
      "epoch 1, batch 100, loss = 2.9029645919799805\n",
      "epoch 1, batch 110, loss = 2.8576292991638184\n",
      "epoch 1, batch 120, loss = 2.8742313385009766\n",
      "epoch 1, batch 130, loss = 2.863461971282959\n",
      "epoch 1, batch 140, loss = 2.8599917888641357\n",
      "epoch 1, batch 150, loss = 2.8520560264587402\n",
      "epoch 1, batch 160, loss = 2.8611278533935547\n",
      "epoch 1, batch 170, loss = 2.860109806060791\n",
      "epoch 1, batch 180, loss = 2.876408100128174\n",
      "epoch 1, batch 190, loss = 2.881429672241211\n",
      "epoch 1, batch 200, loss = 2.921617269515991\n",
      "epoch 1, batch 210, loss = 2.840096950531006\n",
      "epoch 1, batch 220, loss = 2.9181137084960938\n",
      "epoch 1, batch 230, loss = 2.8457932472229004\n",
      "epoch 1, batch 240, loss = 2.858825206756592\n",
      "epoch 1, batch 250, loss = 2.8908259868621826\n",
      "epoch 1, batch 260, loss = 2.8857736587524414\n",
      "epoch 1, batch 270, loss = 2.8754220008850098\n",
      "epoch 1, batch 280, loss = 2.8573122024536133\n",
      "epoch 2, batch 0, loss = 2.9123270511627197\n",
      "epoch 2, batch 10, loss = 2.7879695892333984\n",
      "epoch 2, batch 20, loss = 2.859323740005493\n",
      "epoch 2, batch 30, loss = 2.8693337440490723\n",
      "epoch 2, batch 40, loss = 2.876002788543701\n",
      "epoch 2, batch 50, loss = 2.858137607574463\n",
      "epoch 2, batch 60, loss = 2.8438222408294678\n",
      "epoch 2, batch 70, loss = 2.860538959503174\n",
      "epoch 2, batch 80, loss = 2.8622212409973145\n",
      "epoch 2, batch 90, loss = 2.807215452194214\n",
      "epoch 2, batch 100, loss = 2.842590808868408\n",
      "epoch 2, batch 110, loss = 2.8720030784606934\n",
      "epoch 2, batch 120, loss = 2.816673755645752\n",
      "epoch 2, batch 130, loss = 2.850104808807373\n",
      "epoch 2, batch 140, loss = 2.8204903602600098\n",
      "epoch 2, batch 150, loss = 2.8212640285491943\n",
      "epoch 2, batch 160, loss = 2.868457317352295\n",
      "epoch 2, batch 170, loss = 2.803950786590576\n",
      "epoch 2, batch 180, loss = 2.795680522918701\n",
      "epoch 2, batch 190, loss = 2.822167158126831\n",
      "epoch 2, batch 200, loss = 2.817966938018799\n",
      "epoch 2, batch 210, loss = 2.7987630367279053\n",
      "epoch 2, batch 220, loss = 2.854539394378662\n",
      "epoch 2, batch 230, loss = 2.852881908416748\n",
      "epoch 2, batch 240, loss = 2.874544143676758\n",
      "epoch 2, batch 250, loss = 2.8421630859375\n",
      "epoch 2, batch 260, loss = 2.861987590789795\n",
      "epoch 2, batch 270, loss = 2.8186357021331787\n",
      "epoch 2, batch 280, loss = 2.8522119522094727\n",
      "epoch 3, batch 0, loss = 2.805481195449829\n",
      "epoch 3, batch 10, loss = 2.838590145111084\n",
      "epoch 3, batch 20, loss = 2.8512158393859863\n",
      "epoch 3, batch 30, loss = 2.8438925743103027\n",
      "epoch 3, batch 40, loss = 2.807993173599243\n",
      "epoch 3, batch 50, loss = 2.8548505306243896\n",
      "epoch 3, batch 60, loss = 2.8100624084472656\n",
      "epoch 3, batch 70, loss = 2.8161661624908447\n",
      "epoch 3, batch 80, loss = 2.844452381134033\n",
      "epoch 3, batch 90, loss = 2.869629144668579\n",
      "epoch 3, batch 100, loss = 2.7563679218292236\n",
      "epoch 3, batch 110, loss = 2.906320571899414\n",
      "epoch 3, batch 120, loss = 2.830812931060791\n",
      "epoch 3, batch 130, loss = 2.8174071311950684\n",
      "epoch 3, batch 140, loss = 2.8603100776672363\n",
      "epoch 3, batch 150, loss = 2.827303886413574\n",
      "epoch 3, batch 160, loss = 2.8402085304260254\n",
      "epoch 3, batch 170, loss = 2.803427219390869\n",
      "epoch 3, batch 180, loss = 2.796319007873535\n",
      "epoch 3, batch 190, loss = 2.7951269149780273\n",
      "epoch 3, batch 200, loss = 2.7763185501098633\n",
      "epoch 3, batch 210, loss = 2.852426528930664\n",
      "epoch 3, batch 220, loss = 2.857004165649414\n",
      "epoch 3, batch 230, loss = 2.828885078430176\n",
      "epoch 3, batch 240, loss = 2.813349723815918\n",
      "epoch 3, batch 250, loss = 2.8405890464782715\n",
      "epoch 3, batch 260, loss = 2.8215956687927246\n",
      "epoch 3, batch 270, loss = 2.8559927940368652\n",
      "epoch 3, batch 280, loss = 2.8311994075775146\n",
      "epoch 4, batch 0, loss = 2.7970452308654785\n",
      "epoch 4, batch 10, loss = 2.753025531768799\n",
      "epoch 4, batch 20, loss = 2.8255348205566406\n",
      "epoch 4, batch 30, loss = 2.8665480613708496\n",
      "epoch 4, batch 40, loss = 2.838010787963867\n",
      "epoch 4, batch 50, loss = 2.790487289428711\n",
      "epoch 4, batch 60, loss = 2.786926507949829\n",
      "epoch 4, batch 70, loss = 2.833184242248535\n",
      "epoch 4, batch 80, loss = 2.796205997467041\n",
      "epoch 4, batch 90, loss = 2.7774553298950195\n",
      "epoch 4, batch 100, loss = 2.7817630767822266\n",
      "epoch 4, batch 110, loss = 2.846447706222534\n",
      "epoch 4, batch 120, loss = 2.802816390991211\n",
      "epoch 4, batch 130, loss = 2.8132898807525635\n",
      "epoch 4, batch 140, loss = 2.800992012023926\n",
      "epoch 4, batch 150, loss = 2.8213696479797363\n",
      "epoch 4, batch 160, loss = 2.8691210746765137\n",
      "epoch 4, batch 170, loss = 2.7926785945892334\n",
      "epoch 4, batch 180, loss = 2.813833713531494\n",
      "epoch 4, batch 190, loss = 2.781276226043701\n",
      "epoch 4, batch 200, loss = 2.789229393005371\n",
      "epoch 4, batch 210, loss = 2.79520320892334\n",
      "epoch 4, batch 220, loss = 2.840244770050049\n",
      "epoch 4, batch 230, loss = 2.7937846183776855\n",
      "epoch 4, batch 240, loss = 2.7860467433929443\n",
      "epoch 4, batch 250, loss = 2.803335189819336\n",
      "epoch 4, batch 260, loss = 2.8113749027252197\n",
      "epoch 4, batch 270, loss = 2.785529613494873\n",
      "epoch 4, batch 280, loss = 2.795909881591797\n",
      "epoch 5, batch 0, loss = 2.8463497161865234\n",
      "epoch 5, batch 10, loss = 2.7782692909240723\n",
      "epoch 5, batch 20, loss = 2.777529239654541\n",
      "epoch 5, batch 30, loss = 2.791799306869507\n",
      "epoch 5, batch 40, loss = 2.7895846366882324\n",
      "epoch 5, batch 50, loss = 2.7711269855499268\n",
      "epoch 5, batch 60, loss = 2.7929179668426514\n",
      "epoch 5, batch 70, loss = 2.8360798358917236\n",
      "epoch 5, batch 80, loss = 2.7468271255493164\n",
      "epoch 5, batch 90, loss = 2.7720589637756348\n",
      "epoch 5, batch 100, loss = 2.7690911293029785\n",
      "epoch 5, batch 110, loss = 2.7867417335510254\n",
      "epoch 5, batch 120, loss = 2.754140853881836\n",
      "epoch 5, batch 130, loss = 2.7721920013427734\n",
      "epoch 5, batch 140, loss = 2.8124067783355713\n",
      "epoch 5, batch 150, loss = 2.7982916831970215\n",
      "epoch 5, batch 160, loss = 2.852566719055176\n",
      "epoch 5, batch 170, loss = 2.7483503818511963\n",
      "epoch 5, batch 180, loss = 2.7840633392333984\n",
      "epoch 5, batch 190, loss = 2.815178871154785\n",
      "epoch 5, batch 200, loss = 2.8337626457214355\n",
      "epoch 5, batch 210, loss = 2.739523410797119\n",
      "epoch 5, batch 220, loss = 2.7717363834381104\n",
      "epoch 5, batch 230, loss = 2.8192059993743896\n",
      "epoch 5, batch 240, loss = 2.820096969604492\n",
      "epoch 5, batch 250, loss = 2.781071662902832\n",
      "epoch 5, batch 260, loss = 2.7891993522644043\n",
      "epoch 5, batch 270, loss = 2.851255416870117\n",
      "epoch 5, batch 280, loss = 2.820404052734375\n",
      "epoch 6, batch 0, loss = 2.8159098625183105\n",
      "epoch 6, batch 10, loss = 2.8016860485076904\n",
      "epoch 6, batch 20, loss = 2.771806001663208\n",
      "epoch 6, batch 30, loss = 2.7989296913146973\n",
      "epoch 6, batch 40, loss = 2.7905220985412598\n",
      "epoch 6, batch 50, loss = 2.754446506500244\n",
      "epoch 6, batch 60, loss = 2.7840142250061035\n",
      "epoch 6, batch 70, loss = 2.7656750679016113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, batch 80, loss = 2.7369813919067383\n",
      "epoch 6, batch 90, loss = 2.8137803077697754\n",
      "epoch 6, batch 100, loss = 2.7927467823028564\n",
      "epoch 6, batch 110, loss = 2.7195167541503906\n",
      "epoch 6, batch 120, loss = 2.800140142440796\n",
      "epoch 6, batch 130, loss = 2.7990827560424805\n",
      "epoch 6, batch 140, loss = 2.7827084064483643\n",
      "epoch 6, batch 150, loss = 2.8155226707458496\n",
      "epoch 6, batch 160, loss = 2.812436580657959\n",
      "epoch 6, batch 170, loss = 2.8359124660491943\n",
      "epoch 6, batch 180, loss = 2.754267692565918\n",
      "epoch 6, batch 190, loss = 2.7674026489257812\n",
      "epoch 6, batch 200, loss = 2.815617561340332\n",
      "epoch 6, batch 210, loss = 2.871051073074341\n",
      "epoch 6, batch 220, loss = 2.7906219959259033\n",
      "epoch 6, batch 230, loss = 2.814743757247925\n",
      "epoch 6, batch 240, loss = 2.7548346519470215\n",
      "epoch 6, batch 250, loss = 2.77679443359375\n",
      "epoch 6, batch 260, loss = 2.8081612586975098\n",
      "epoch 6, batch 270, loss = 2.791797399520874\n",
      "epoch 6, batch 280, loss = 2.7720754146575928\n",
      "epoch 7, batch 0, loss = 2.8001465797424316\n",
      "epoch 7, batch 10, loss = 2.7666945457458496\n",
      "epoch 7, batch 20, loss = 2.7469730377197266\n",
      "epoch 7, batch 30, loss = 2.7538418769836426\n",
      "epoch 7, batch 40, loss = 2.7831978797912598\n",
      "epoch 7, batch 50, loss = 2.737204074859619\n",
      "epoch 7, batch 60, loss = 2.75363826751709\n",
      "epoch 7, batch 70, loss = 2.7307653427124023\n",
      "epoch 7, batch 80, loss = 2.8237195014953613\n",
      "epoch 7, batch 90, loss = 2.7584474086761475\n",
      "epoch 7, batch 100, loss = 2.7828855514526367\n",
      "epoch 7, batch 110, loss = 2.7916531562805176\n",
      "epoch 7, batch 120, loss = 2.8035969734191895\n",
      "epoch 7, batch 130, loss = 2.795279026031494\n",
      "epoch 7, batch 140, loss = 2.7531321048736572\n",
      "epoch 7, batch 150, loss = 2.796718120574951\n",
      "epoch 7, batch 160, loss = 2.809976100921631\n",
      "epoch 7, batch 170, loss = 2.7450039386749268\n",
      "epoch 7, batch 180, loss = 2.7678914070129395\n",
      "epoch 7, batch 190, loss = 2.7633421421051025\n",
      "epoch 7, batch 200, loss = 2.7621660232543945\n",
      "epoch 7, batch 210, loss = 2.8245849609375\n",
      "epoch 7, batch 220, loss = 2.7581186294555664\n",
      "epoch 7, batch 230, loss = 2.849355936050415\n",
      "epoch 7, batch 240, loss = 2.802920341491699\n",
      "epoch 7, batch 250, loss = 2.7437663078308105\n",
      "epoch 7, batch 260, loss = 2.7443337440490723\n",
      "epoch 7, batch 270, loss = 2.7896385192871094\n",
      "epoch 7, batch 280, loss = 2.8193130493164062\n",
      "epoch 8, batch 0, loss = 2.82346773147583\n",
      "epoch 8, batch 10, loss = 2.772850513458252\n",
      "epoch 8, batch 20, loss = 2.7994585037231445\n",
      "epoch 8, batch 30, loss = 2.7645978927612305\n",
      "epoch 8, batch 40, loss = 2.7715067863464355\n",
      "epoch 8, batch 50, loss = 2.7346649169921875\n",
      "epoch 8, batch 60, loss = 2.800973415374756\n",
      "epoch 8, batch 70, loss = 2.7485623359680176\n",
      "epoch 8, batch 80, loss = 2.726900815963745\n",
      "epoch 8, batch 90, loss = 2.761429786682129\n",
      "epoch 8, batch 100, loss = 2.7644267082214355\n",
      "epoch 8, batch 110, loss = 2.7607908248901367\n",
      "epoch 8, batch 120, loss = 2.754849910736084\n",
      "epoch 8, batch 130, loss = 2.7492690086364746\n",
      "epoch 8, batch 140, loss = 2.8147857189178467\n",
      "epoch 8, batch 150, loss = 2.794189453125\n",
      "epoch 8, batch 160, loss = 2.8275563716888428\n",
      "epoch 8, batch 170, loss = 2.812235116958618\n",
      "epoch 8, batch 180, loss = 2.771533966064453\n",
      "epoch 8, batch 190, loss = 2.7745838165283203\n",
      "epoch 8, batch 200, loss = 2.787051200866699\n",
      "epoch 8, batch 210, loss = 2.765103816986084\n",
      "epoch 8, batch 220, loss = 2.8094308376312256\n",
      "epoch 8, batch 230, loss = 2.7329134941101074\n",
      "epoch 8, batch 240, loss = 2.778803586959839\n",
      "epoch 8, batch 250, loss = 2.788869857788086\n",
      "epoch 8, batch 260, loss = 2.769434690475464\n",
      "epoch 8, batch 270, loss = 2.7115182876586914\n",
      "epoch 8, batch 280, loss = 2.7902517318725586\n",
      "epoch 9, batch 0, loss = 2.812652111053467\n",
      "epoch 9, batch 10, loss = 2.755312442779541\n",
      "epoch 9, batch 20, loss = 2.724343776702881\n",
      "epoch 9, batch 30, loss = 2.73884654045105\n",
      "epoch 9, batch 40, loss = 2.7875757217407227\n",
      "epoch 9, batch 50, loss = 2.7837202548980713\n",
      "epoch 9, batch 60, loss = 2.7321741580963135\n",
      "epoch 9, batch 70, loss = 2.7146177291870117\n",
      "epoch 9, batch 80, loss = 2.7193644046783447\n",
      "epoch 9, batch 90, loss = 2.8024749755859375\n",
      "epoch 9, batch 100, loss = 2.771468162536621\n",
      "epoch 9, batch 110, loss = 2.7535171508789062\n",
      "epoch 9, batch 120, loss = 2.730185031890869\n",
      "epoch 9, batch 130, loss = 2.766104221343994\n",
      "epoch 9, batch 140, loss = 2.7281482219696045\n",
      "epoch 9, batch 150, loss = 2.835596799850464\n",
      "epoch 9, batch 160, loss = 2.775552988052368\n",
      "epoch 9, batch 170, loss = 2.7449769973754883\n",
      "epoch 9, batch 180, loss = 2.7348432540893555\n",
      "epoch 9, batch 190, loss = 2.762807607650757\n",
      "epoch 9, batch 200, loss = 2.7872390747070312\n",
      "epoch 9, batch 210, loss = 2.794261932373047\n",
      "epoch 9, batch 220, loss = 2.7864603996276855\n",
      "epoch 9, batch 230, loss = 2.8141260147094727\n",
      "epoch 9, batch 240, loss = 2.684168815612793\n",
      "epoch 9, batch 250, loss = 2.7639975547790527\n",
      "epoch 9, batch 260, loss = 2.7949166297912598\n",
      "epoch 9, batch 270, loss = 2.758274793624878\n",
      "epoch 9, batch 280, loss = 2.770984649658203\n",
      "epoch 10, batch 0, loss = 2.7768173217773438\n",
      "epoch 10, batch 10, loss = 2.7349400520324707\n",
      "epoch 10, batch 20, loss = 2.728135824203491\n",
      "epoch 10, batch 30, loss = 2.736027717590332\n",
      "epoch 10, batch 40, loss = 2.7136058807373047\n",
      "epoch 10, batch 50, loss = 2.7031397819519043\n",
      "epoch 10, batch 60, loss = 2.7356157302856445\n",
      "epoch 10, batch 70, loss = 2.716370105743408\n",
      "epoch 10, batch 80, loss = 2.6991701126098633\n",
      "epoch 10, batch 90, loss = 2.800231456756592\n",
      "epoch 10, batch 100, loss = 2.797609567642212\n",
      "epoch 10, batch 110, loss = 2.730886459350586\n",
      "epoch 10, batch 120, loss = 2.799351930618286\n",
      "epoch 10, batch 130, loss = 2.7581465244293213\n",
      "epoch 10, batch 140, loss = 2.741955280303955\n",
      "epoch 10, batch 150, loss = 2.775266408920288\n",
      "epoch 10, batch 160, loss = 2.7575783729553223\n",
      "epoch 10, batch 170, loss = 2.8015642166137695\n",
      "epoch 10, batch 180, loss = 2.7378525733947754\n",
      "epoch 10, batch 190, loss = 2.7455668449401855\n",
      "epoch 10, batch 200, loss = 2.761519432067871\n",
      "epoch 10, batch 210, loss = 2.7711191177368164\n",
      "epoch 10, batch 220, loss = 2.738877296447754\n",
      "epoch 10, batch 230, loss = 2.7412338256835938\n",
      "epoch 10, batch 240, loss = 2.790827989578247\n",
      "epoch 10, batch 250, loss = 2.778024673461914\n",
      "epoch 10, batch 260, loss = 2.7648537158966064\n",
      "epoch 10, batch 270, loss = 2.7396414279937744\n",
      "epoch 10, batch 280, loss = 2.804831027984619\n",
      "epoch 11, batch 0, loss = 2.7369401454925537\n",
      "epoch 11, batch 10, loss = 2.7215051651000977\n",
      "epoch 11, batch 20, loss = 2.8045456409454346\n",
      "epoch 11, batch 30, loss = 2.7610130310058594\n",
      "epoch 11, batch 40, loss = 2.795584201812744\n",
      "epoch 11, batch 50, loss = 2.719284772872925\n",
      "epoch 11, batch 60, loss = 2.7177908420562744\n",
      "epoch 11, batch 70, loss = 2.7511630058288574\n",
      "epoch 11, batch 80, loss = 2.806663990020752\n",
      "epoch 11, batch 90, loss = 2.7774040699005127\n",
      "epoch 11, batch 100, loss = 2.722738742828369\n",
      "epoch 11, batch 110, loss = 2.762429714202881\n",
      "epoch 11, batch 120, loss = 2.7445006370544434\n",
      "epoch 11, batch 130, loss = 2.761475086212158\n",
      "epoch 11, batch 140, loss = 2.7632508277893066\n",
      "epoch 11, batch 150, loss = 2.755582809448242\n",
      "epoch 11, batch 160, loss = 2.7364211082458496\n",
      "epoch 11, batch 170, loss = 2.683210611343384\n",
      "epoch 11, batch 180, loss = 2.7462058067321777\n",
      "epoch 11, batch 190, loss = 2.678750991821289\n",
      "epoch 11, batch 200, loss = 2.7050187587738037\n",
      "epoch 11, batch 210, loss = 2.7585818767547607\n",
      "epoch 11, batch 220, loss = 2.787872076034546\n",
      "epoch 11, batch 230, loss = 2.732482433319092\n",
      "epoch 11, batch 240, loss = 2.7749452590942383\n",
      "epoch 11, batch 250, loss = 2.721181869506836\n",
      "epoch 11, batch 260, loss = 2.754788398742676\n",
      "epoch 11, batch 270, loss = 2.6952810287475586\n",
      "epoch 11, batch 280, loss = 2.73429274559021\n",
      "epoch 12, batch 0, loss = 2.7248480319976807\n",
      "epoch 12, batch 10, loss = 2.697512626647949\n",
      "epoch 12, batch 20, loss = 2.7298600673675537\n",
      "epoch 12, batch 30, loss = 2.7445907592773438\n",
      "epoch 12, batch 40, loss = 2.744631767272949\n",
      "epoch 12, batch 50, loss = 2.770138740539551\n",
      "epoch 12, batch 60, loss = 2.72047758102417\n",
      "epoch 12, batch 70, loss = 2.7837915420532227\n",
      "epoch 12, batch 80, loss = 2.7810781002044678\n",
      "epoch 12, batch 90, loss = 2.7545719146728516\n",
      "epoch 12, batch 100, loss = 2.7037854194641113\n",
      "epoch 12, batch 110, loss = 2.736069679260254\n",
      "epoch 12, batch 120, loss = 2.7193455696105957\n",
      "epoch 12, batch 130, loss = 2.767024278640747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, batch 140, loss = 2.7972207069396973\n",
      "epoch 12, batch 150, loss = 2.7739524841308594\n",
      "epoch 12, batch 160, loss = 2.74686336517334\n",
      "epoch 12, batch 170, loss = 2.785212993621826\n",
      "epoch 12, batch 180, loss = 2.7305870056152344\n",
      "epoch 12, batch 190, loss = 2.7801623344421387\n",
      "epoch 12, batch 200, loss = 2.7597057819366455\n",
      "epoch 12, batch 210, loss = 2.7491650581359863\n",
      "epoch 12, batch 220, loss = 2.741611957550049\n",
      "epoch 12, batch 230, loss = 2.774434804916382\n",
      "epoch 12, batch 240, loss = 2.7018940448760986\n",
      "epoch 12, batch 250, loss = 2.722454071044922\n",
      "epoch 12, batch 260, loss = 2.75022029876709\n",
      "epoch 12, batch 270, loss = 2.738976001739502\n",
      "epoch 12, batch 280, loss = 2.76480770111084\n",
      "epoch 13, batch 0, loss = 2.724917411804199\n",
      "epoch 13, batch 10, loss = 2.6741912364959717\n",
      "epoch 13, batch 20, loss = 2.72467041015625\n",
      "epoch 13, batch 30, loss = 2.7443814277648926\n",
      "epoch 13, batch 40, loss = 2.7301759719848633\n",
      "epoch 13, batch 50, loss = 2.725569009780884\n",
      "epoch 13, batch 60, loss = 2.7339606285095215\n",
      "epoch 13, batch 70, loss = 2.7155849933624268\n",
      "epoch 13, batch 80, loss = 2.747175693511963\n",
      "epoch 13, batch 90, loss = 2.6999447345733643\n",
      "epoch 13, batch 100, loss = 2.728956699371338\n",
      "epoch 13, batch 110, loss = 2.7482728958129883\n",
      "epoch 13, batch 120, loss = 2.735102653503418\n",
      "epoch 13, batch 130, loss = 2.775485038757324\n",
      "epoch 13, batch 140, loss = 2.789869785308838\n",
      "epoch 13, batch 150, loss = 2.7663497924804688\n",
      "epoch 13, batch 160, loss = 2.7333011627197266\n",
      "epoch 13, batch 170, loss = 2.777985095977783\n",
      "epoch 13, batch 180, loss = 2.745051622390747\n",
      "epoch 13, batch 190, loss = 2.7470250129699707\n",
      "epoch 13, batch 200, loss = 2.754878044128418\n",
      "epoch 13, batch 210, loss = 2.7301082611083984\n",
      "epoch 13, batch 220, loss = 2.73930025100708\n",
      "epoch 13, batch 230, loss = 2.732847213745117\n",
      "epoch 13, batch 240, loss = 2.7433857917785645\n",
      "epoch 13, batch 250, loss = 2.7497992515563965\n",
      "epoch 13, batch 260, loss = 2.732913017272949\n",
      "epoch 13, batch 270, loss = 2.7723495960235596\n",
      "epoch 13, batch 280, loss = 2.818246841430664\n",
      "epoch 14, batch 0, loss = 2.7189717292785645\n",
      "epoch 14, batch 10, loss = 2.703779697418213\n",
      "epoch 14, batch 20, loss = 2.803164482116699\n",
      "epoch 14, batch 30, loss = 2.7393057346343994\n",
      "epoch 14, batch 40, loss = 2.7385735511779785\n",
      "epoch 14, batch 50, loss = 2.759943723678589\n",
      "epoch 14, batch 60, loss = 2.760775566101074\n",
      "epoch 14, batch 70, loss = 2.7352027893066406\n",
      "epoch 14, batch 80, loss = 2.750422954559326\n",
      "epoch 14, batch 90, loss = 2.713204860687256\n",
      "epoch 14, batch 100, loss = 2.772353172302246\n",
      "epoch 14, batch 110, loss = 2.757880687713623\n",
      "epoch 14, batch 120, loss = 2.7312111854553223\n",
      "epoch 14, batch 130, loss = 2.7241263389587402\n",
      "epoch 14, batch 140, loss = 2.7438573837280273\n",
      "epoch 14, batch 150, loss = 2.7006633281707764\n",
      "epoch 14, batch 160, loss = 2.679152250289917\n",
      "epoch 14, batch 170, loss = 2.758632183074951\n",
      "epoch 14, batch 180, loss = 2.7774579524993896\n",
      "epoch 14, batch 190, loss = 2.7417821884155273\n",
      "epoch 14, batch 200, loss = 2.7485527992248535\n",
      "epoch 14, batch 210, loss = 2.7683968544006348\n",
      "epoch 14, batch 220, loss = 2.7139360904693604\n",
      "epoch 14, batch 230, loss = 2.74545955657959\n",
      "epoch 14, batch 240, loss = 2.7305686473846436\n",
      "epoch 14, batch 250, loss = 2.731186866760254\n",
      "epoch 14, batch 260, loss = 2.7210822105407715\n",
      "epoch 14, batch 270, loss = 2.8032937049865723\n",
      "epoch 14, batch 280, loss = 2.7435364723205566\n",
      "epoch 15, batch 0, loss = 2.737306594848633\n",
      "epoch 15, batch 10, loss = 2.7239513397216797\n",
      "epoch 15, batch 20, loss = 2.7577037811279297\n",
      "epoch 15, batch 30, loss = 2.755373477935791\n",
      "epoch 15, batch 40, loss = 2.687775135040283\n",
      "epoch 15, batch 50, loss = 2.740145206451416\n",
      "epoch 15, batch 60, loss = 2.6856508255004883\n",
      "epoch 15, batch 70, loss = 2.745431661605835\n",
      "epoch 15, batch 80, loss = 2.7717478275299072\n",
      "epoch 15, batch 90, loss = 2.7317495346069336\n",
      "epoch 15, batch 100, loss = 2.718820333480835\n",
      "epoch 15, batch 110, loss = 2.6794309616088867\n",
      "epoch 15, batch 120, loss = 2.8059487342834473\n",
      "epoch 15, batch 130, loss = 2.7105941772460938\n",
      "epoch 15, batch 140, loss = 2.7396187782287598\n",
      "epoch 15, batch 150, loss = 2.684689998626709\n",
      "epoch 15, batch 160, loss = 2.6932504177093506\n",
      "epoch 15, batch 170, loss = 2.7582285404205322\n",
      "epoch 15, batch 180, loss = 2.755019426345825\n",
      "epoch 15, batch 190, loss = 2.688162326812744\n",
      "epoch 15, batch 200, loss = 2.7714478969573975\n",
      "epoch 15, batch 210, loss = 2.756348133087158\n",
      "epoch 15, batch 220, loss = 2.8064517974853516\n",
      "epoch 15, batch 230, loss = 2.7515878677368164\n",
      "epoch 15, batch 240, loss = 2.73702073097229\n",
      "epoch 15, batch 250, loss = 2.6856062412261963\n",
      "epoch 15, batch 260, loss = 2.7207729816436768\n",
      "epoch 15, batch 270, loss = 2.7724266052246094\n",
      "epoch 15, batch 280, loss = 2.7678208351135254\n",
      "epoch 16, batch 0, loss = 2.7012557983398438\n",
      "epoch 16, batch 10, loss = 2.6989660263061523\n",
      "epoch 16, batch 20, loss = 2.7002463340759277\n",
      "epoch 16, batch 30, loss = 2.753872871398926\n",
      "epoch 16, batch 40, loss = 2.717153549194336\n",
      "epoch 16, batch 50, loss = 2.7204504013061523\n",
      "epoch 16, batch 60, loss = 2.7663888931274414\n",
      "epoch 16, batch 70, loss = 2.782679796218872\n",
      "epoch 16, batch 80, loss = 2.7253847122192383\n",
      "epoch 16, batch 90, loss = 2.7399749755859375\n",
      "epoch 16, batch 100, loss = 2.741677761077881\n",
      "epoch 16, batch 110, loss = 2.7547948360443115\n",
      "epoch 16, batch 120, loss = 2.7838191986083984\n",
      "epoch 16, batch 130, loss = 2.7401440143585205\n",
      "epoch 16, batch 140, loss = 2.7558095455169678\n",
      "epoch 16, batch 150, loss = 2.732079267501831\n",
      "epoch 16, batch 160, loss = 2.707137107849121\n",
      "epoch 16, batch 170, loss = 2.8110928535461426\n",
      "epoch 16, batch 180, loss = 2.735891342163086\n",
      "epoch 16, batch 190, loss = 2.7180066108703613\n",
      "epoch 16, batch 200, loss = 2.739872694015503\n",
      "epoch 16, batch 210, loss = 2.7288084030151367\n",
      "epoch 16, batch 220, loss = 2.725261688232422\n",
      "epoch 16, batch 230, loss = 2.765120029449463\n",
      "epoch 16, batch 240, loss = 2.7569196224212646\n",
      "epoch 16, batch 250, loss = 2.711928367614746\n",
      "epoch 16, batch 260, loss = 2.7475833892822266\n",
      "epoch 16, batch 270, loss = 2.7029356956481934\n",
      "epoch 16, batch 280, loss = 2.7087960243225098\n",
      "epoch 17, batch 0, loss = 2.71415376663208\n",
      "epoch 17, batch 10, loss = 2.7200074195861816\n",
      "epoch 17, batch 20, loss = 2.6880807876586914\n",
      "epoch 17, batch 30, loss = 2.7800514698028564\n",
      "epoch 17, batch 40, loss = 2.6994619369506836\n",
      "epoch 17, batch 50, loss = 2.713240146636963\n",
      "epoch 17, batch 60, loss = 2.6947898864746094\n",
      "epoch 17, batch 70, loss = 2.690617084503174\n",
      "epoch 17, batch 80, loss = 2.765855550765991\n",
      "epoch 17, batch 90, loss = 2.73588228225708\n",
      "epoch 17, batch 100, loss = 2.6788671016693115\n",
      "epoch 17, batch 110, loss = 2.7773032188415527\n",
      "epoch 17, batch 120, loss = 2.710444688796997\n",
      "epoch 17, batch 130, loss = 2.788630962371826\n",
      "epoch 17, batch 140, loss = 2.7176201343536377\n",
      "epoch 17, batch 150, loss = 2.6749401092529297\n",
      "epoch 17, batch 160, loss = 2.7611680030822754\n",
      "epoch 17, batch 170, loss = 2.749483108520508\n",
      "epoch 17, batch 180, loss = 2.6807379722595215\n",
      "epoch 17, batch 190, loss = 2.7150683403015137\n",
      "epoch 17, batch 200, loss = 2.7103633880615234\n",
      "epoch 17, batch 210, loss = 2.7451696395874023\n",
      "epoch 17, batch 220, loss = 2.727715015411377\n",
      "epoch 17, batch 230, loss = 2.6875503063201904\n",
      "epoch 17, batch 240, loss = 2.6902427673339844\n",
      "epoch 17, batch 250, loss = 2.732736349105835\n",
      "epoch 17, batch 260, loss = 2.748939037322998\n",
      "epoch 17, batch 270, loss = 2.797914981842041\n",
      "epoch 17, batch 280, loss = 2.7137503623962402\n",
      "epoch 18, batch 0, loss = 2.7172160148620605\n",
      "epoch 18, batch 10, loss = 2.7781641483306885\n",
      "epoch 18, batch 20, loss = 2.770852565765381\n",
      "epoch 18, batch 30, loss = 2.762155055999756\n",
      "epoch 18, batch 40, loss = 2.704211473464966\n",
      "epoch 18, batch 50, loss = 2.699763059616089\n",
      "epoch 18, batch 60, loss = 2.762113571166992\n",
      "epoch 18, batch 70, loss = 2.7441442012786865\n",
      "epoch 18, batch 80, loss = 2.688796043395996\n",
      "epoch 18, batch 90, loss = 2.7072482109069824\n",
      "epoch 18, batch 100, loss = 2.7847158908843994\n",
      "epoch 18, batch 110, loss = 2.6730148792266846\n",
      "epoch 18, batch 120, loss = 2.7626335620880127\n",
      "epoch 18, batch 130, loss = 2.6933584213256836\n",
      "epoch 18, batch 140, loss = 2.746595859527588\n",
      "epoch 18, batch 150, loss = 2.7690320014953613\n",
      "epoch 18, batch 160, loss = 2.6882705688476562\n",
      "epoch 18, batch 170, loss = 2.690607786178589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, batch 180, loss = 2.7480926513671875\n",
      "epoch 18, batch 190, loss = 2.723600387573242\n",
      "epoch 18, batch 200, loss = 2.753852367401123\n",
      "epoch 18, batch 210, loss = 2.7232367992401123\n",
      "epoch 18, batch 220, loss = 2.7316009998321533\n",
      "epoch 18, batch 230, loss = 2.7850632667541504\n",
      "epoch 18, batch 240, loss = 2.789623737335205\n",
      "epoch 18, batch 250, loss = 2.7171683311462402\n",
      "epoch 18, batch 260, loss = 2.716533660888672\n",
      "epoch 18, batch 270, loss = 2.737255573272705\n",
      "epoch 18, batch 280, loss = 2.70350980758667\n",
      "epoch 19, batch 0, loss = 2.7614638805389404\n",
      "epoch 19, batch 10, loss = 2.695120334625244\n",
      "epoch 19, batch 20, loss = 2.6845240592956543\n",
      "epoch 19, batch 30, loss = 2.708112955093384\n",
      "epoch 19, batch 40, loss = 2.7215185165405273\n",
      "epoch 19, batch 50, loss = 2.695143699645996\n",
      "epoch 19, batch 60, loss = 2.7312116622924805\n",
      "epoch 19, batch 70, loss = 2.739257335662842\n",
      "epoch 19, batch 80, loss = 2.7039599418640137\n",
      "epoch 19, batch 90, loss = 2.745323657989502\n",
      "epoch 19, batch 100, loss = 2.694930076599121\n",
      "epoch 19, batch 110, loss = 2.7286810874938965\n",
      "epoch 19, batch 120, loss = 2.7116036415100098\n",
      "epoch 19, batch 130, loss = 2.697295665740967\n",
      "epoch 19, batch 140, loss = 2.6772427558898926\n",
      "epoch 19, batch 150, loss = 2.7182023525238037\n",
      "epoch 19, batch 160, loss = 2.7002804279327393\n",
      "epoch 19, batch 170, loss = 2.7288694381713867\n",
      "epoch 19, batch 180, loss = 2.684706211090088\n",
      "epoch 19, batch 190, loss = 2.708061695098877\n",
      "epoch 19, batch 200, loss = 2.7862324714660645\n",
      "epoch 19, batch 210, loss = 2.7045955657958984\n",
      "epoch 19, batch 220, loss = 2.752532958984375\n",
      "epoch 19, batch 230, loss = 2.6957335472106934\n",
      "epoch 19, batch 240, loss = 2.751729965209961\n",
      "epoch 19, batch 250, loss = 2.6629395484924316\n",
      "epoch 19, batch 260, loss = 2.740321159362793\n",
      "epoch 19, batch 270, loss = 2.726591110229492\n",
      "epoch 19, batch 280, loss = 2.6491971015930176\n",
      "epoch 20, batch 0, loss = 2.7711634635925293\n",
      "epoch 20, batch 10, loss = 2.7153496742248535\n",
      "epoch 20, batch 20, loss = 2.6766302585601807\n",
      "epoch 20, batch 30, loss = 2.715771198272705\n",
      "epoch 20, batch 40, loss = 2.700514316558838\n",
      "epoch 20, batch 50, loss = 2.7158117294311523\n",
      "epoch 20, batch 60, loss = 2.68645977973938\n",
      "epoch 20, batch 70, loss = 2.6825757026672363\n",
      "epoch 20, batch 80, loss = 2.712871551513672\n",
      "epoch 20, batch 90, loss = 2.734912157058716\n",
      "epoch 20, batch 100, loss = 2.730988025665283\n",
      "epoch 20, batch 110, loss = 2.7818825244903564\n",
      "epoch 20, batch 120, loss = 2.7332592010498047\n",
      "epoch 20, batch 130, loss = 2.7135119438171387\n",
      "epoch 20, batch 140, loss = 2.680837631225586\n",
      "epoch 20, batch 150, loss = 2.742554187774658\n",
      "epoch 20, batch 160, loss = 2.675523281097412\n",
      "epoch 20, batch 170, loss = 2.716035842895508\n",
      "epoch 20, batch 180, loss = 2.745943307876587\n",
      "epoch 20, batch 190, loss = 2.756373882293701\n",
      "epoch 20, batch 200, loss = 2.6702136993408203\n",
      "epoch 20, batch 210, loss = 2.782160758972168\n",
      "epoch 20, batch 220, loss = 2.7100958824157715\n",
      "epoch 20, batch 230, loss = 2.6898293495178223\n",
      "epoch 20, batch 240, loss = 2.7360520362854004\n",
      "epoch 20, batch 250, loss = 2.7988991737365723\n",
      "epoch 20, batch 260, loss = 2.674600839614868\n",
      "epoch 20, batch 270, loss = 2.7279646396636963\n",
      "epoch 20, batch 280, loss = 2.702014923095703\n",
      "epoch 21, batch 0, loss = 2.6521072387695312\n",
      "epoch 21, batch 10, loss = 2.7288196086883545\n",
      "epoch 21, batch 20, loss = 2.7219698429107666\n",
      "epoch 21, batch 30, loss = 2.634530544281006\n",
      "epoch 21, batch 40, loss = 2.7411766052246094\n",
      "epoch 21, batch 50, loss = 2.6979241371154785\n",
      "epoch 21, batch 60, loss = 2.6535990238189697\n",
      "epoch 21, batch 70, loss = 2.669666290283203\n",
      "epoch 21, batch 80, loss = 2.708261013031006\n",
      "epoch 21, batch 90, loss = 2.6900861263275146\n",
      "epoch 21, batch 100, loss = 2.683260202407837\n",
      "epoch 21, batch 110, loss = 2.67447566986084\n",
      "epoch 21, batch 120, loss = 2.6895930767059326\n",
      "epoch 21, batch 130, loss = 2.7083334922790527\n",
      "epoch 21, batch 140, loss = 2.6919164657592773\n",
      "epoch 21, batch 150, loss = 2.7405896186828613\n",
      "epoch 21, batch 160, loss = 2.693972587585449\n",
      "epoch 21, batch 170, loss = 2.676413059234619\n",
      "epoch 21, batch 180, loss = 2.7028908729553223\n",
      "epoch 21, batch 190, loss = 2.6977334022521973\n",
      "epoch 21, batch 200, loss = 2.7760143280029297\n",
      "epoch 21, batch 210, loss = 2.713352918624878\n",
      "epoch 21, batch 220, loss = 2.721771240234375\n",
      "epoch 21, batch 230, loss = 2.724315643310547\n",
      "epoch 21, batch 240, loss = 2.7356104850769043\n",
      "epoch 21, batch 250, loss = 2.7357497215270996\n",
      "epoch 21, batch 260, loss = 2.761629104614258\n",
      "epoch 21, batch 270, loss = 2.684356689453125\n",
      "epoch 21, batch 280, loss = 2.781287670135498\n",
      "epoch 22, batch 0, loss = 2.713655471801758\n",
      "epoch 22, batch 10, loss = 2.7296602725982666\n",
      "epoch 22, batch 20, loss = 2.725348711013794\n",
      "epoch 22, batch 30, loss = 2.6948442459106445\n",
      "epoch 22, batch 40, loss = 2.7118024826049805\n",
      "epoch 22, batch 50, loss = 2.6784403324127197\n",
      "epoch 22, batch 60, loss = 2.6952602863311768\n",
      "epoch 22, batch 70, loss = 2.672689437866211\n",
      "epoch 22, batch 80, loss = 2.7385501861572266\n",
      "epoch 22, batch 90, loss = 2.7587318420410156\n",
      "epoch 22, batch 100, loss = 2.738037586212158\n",
      "epoch 22, batch 110, loss = 2.7443933486938477\n",
      "epoch 22, batch 120, loss = 2.6859853267669678\n",
      "epoch 22, batch 130, loss = 2.6505908966064453\n",
      "epoch 22, batch 140, loss = 2.70660662651062\n",
      "epoch 22, batch 150, loss = 2.725900173187256\n",
      "epoch 22, batch 160, loss = 2.693246364593506\n",
      "epoch 22, batch 170, loss = 2.7086610794067383\n",
      "epoch 22, batch 180, loss = 2.7150309085845947\n",
      "epoch 22, batch 190, loss = 2.6973679065704346\n",
      "epoch 22, batch 200, loss = 2.652042865753174\n",
      "epoch 22, batch 210, loss = 2.7457568645477295\n",
      "epoch 22, batch 220, loss = 2.7049708366394043\n",
      "epoch 22, batch 230, loss = 2.7251455783843994\n",
      "epoch 22, batch 240, loss = 2.726417064666748\n",
      "epoch 22, batch 250, loss = 2.7613470554351807\n",
      "epoch 22, batch 260, loss = 2.7277581691741943\n",
      "epoch 22, batch 270, loss = 2.7522480487823486\n",
      "epoch 22, batch 280, loss = 2.639416217803955\n",
      "epoch 23, batch 0, loss = 2.6461334228515625\n",
      "epoch 23, batch 10, loss = 2.7602005004882812\n",
      "epoch 23, batch 20, loss = 2.722790479660034\n",
      "epoch 23, batch 30, loss = 2.6747069358825684\n",
      "epoch 23, batch 40, loss = 2.7127685546875\n",
      "epoch 23, batch 50, loss = 2.649331569671631\n",
      "epoch 23, batch 60, loss = 2.677967071533203\n",
      "epoch 23, batch 70, loss = 2.6934123039245605\n",
      "epoch 23, batch 80, loss = 2.704493999481201\n",
      "epoch 23, batch 90, loss = 2.650665044784546\n",
      "epoch 23, batch 100, loss = 2.654926300048828\n",
      "epoch 23, batch 110, loss = 2.6881613731384277\n",
      "epoch 23, batch 120, loss = 2.736844778060913\n",
      "epoch 23, batch 130, loss = 2.6952250003814697\n",
      "epoch 23, batch 140, loss = 2.663440704345703\n",
      "epoch 23, batch 150, loss = 2.6981024742126465\n",
      "epoch 23, batch 160, loss = 2.7421655654907227\n",
      "epoch 23, batch 170, loss = 2.715773820877075\n",
      "epoch 23, batch 180, loss = 2.7155604362487793\n",
      "epoch 23, batch 190, loss = 2.6837940216064453\n",
      "epoch 23, batch 200, loss = 2.712373971939087\n",
      "epoch 23, batch 210, loss = 2.739744186401367\n",
      "epoch 23, batch 220, loss = 2.6905479431152344\n",
      "epoch 23, batch 230, loss = 2.7669832706451416\n",
      "epoch 23, batch 240, loss = 2.6809444427490234\n",
      "epoch 23, batch 250, loss = 2.734835147857666\n",
      "epoch 23, batch 260, loss = 2.672191619873047\n",
      "epoch 23, batch 270, loss = 2.7204954624176025\n",
      "epoch 23, batch 280, loss = 2.7158703804016113\n",
      "epoch 24, batch 0, loss = 2.6851909160614014\n",
      "epoch 24, batch 10, loss = 2.763922929763794\n",
      "epoch 24, batch 20, loss = 2.6747775077819824\n",
      "epoch 24, batch 30, loss = 2.72467303276062\n",
      "epoch 24, batch 40, loss = 2.7619924545288086\n",
      "epoch 24, batch 50, loss = 2.7146201133728027\n",
      "epoch 24, batch 60, loss = 2.7155234813690186\n",
      "epoch 24, batch 70, loss = 2.6988677978515625\n",
      "epoch 24, batch 80, loss = 2.7067012786865234\n",
      "epoch 24, batch 90, loss = 2.6578314304351807\n",
      "epoch 24, batch 100, loss = 2.7018251419067383\n",
      "epoch 24, batch 110, loss = 2.715388774871826\n",
      "epoch 24, batch 120, loss = 2.693606376647949\n",
      "epoch 24, batch 130, loss = 2.714284896850586\n",
      "epoch 24, batch 140, loss = 2.7566516399383545\n",
      "epoch 24, batch 150, loss = 2.717242479324341\n",
      "epoch 24, batch 160, loss = 2.728208065032959\n",
      "epoch 24, batch 170, loss = 2.7481958866119385\n",
      "epoch 24, batch 180, loss = 2.69126033782959\n",
      "epoch 24, batch 190, loss = 2.7341156005859375\n",
      "epoch 24, batch 200, loss = 2.7005293369293213\n",
      "epoch 24, batch 210, loss = 2.6261720657348633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, batch 220, loss = 2.7113983631134033\n",
      "epoch 24, batch 230, loss = 2.7188918590545654\n",
      "epoch 24, batch 240, loss = 2.657975196838379\n",
      "epoch 24, batch 250, loss = 2.7097601890563965\n",
      "epoch 24, batch 260, loss = 2.7349071502685547\n",
      "epoch 24, batch 270, loss = 2.7033472061157227\n",
      "epoch 24, batch 280, loss = 2.6796092987060547\n",
      "epoch 25, batch 0, loss = 2.698425054550171\n",
      "epoch 25, batch 10, loss = 2.6938722133636475\n",
      "epoch 25, batch 20, loss = 2.7110228538513184\n",
      "epoch 25, batch 30, loss = 2.7136070728302\n",
      "epoch 25, batch 40, loss = 2.690182685852051\n",
      "epoch 25, batch 50, loss = 2.685260057449341\n",
      "epoch 25, batch 60, loss = 2.6539573669433594\n",
      "epoch 25, batch 70, loss = 2.673510789871216\n",
      "epoch 25, batch 80, loss = 2.7387423515319824\n",
      "epoch 25, batch 90, loss = 2.739482879638672\n",
      "epoch 25, batch 100, loss = 2.701543092727661\n",
      "epoch 25, batch 110, loss = 2.6887338161468506\n",
      "epoch 25, batch 120, loss = 2.6862292289733887\n",
      "epoch 25, batch 130, loss = 2.67356014251709\n",
      "epoch 25, batch 140, loss = 2.7533955574035645\n",
      "epoch 25, batch 150, loss = 2.7387537956237793\n",
      "epoch 25, batch 160, loss = 2.701505184173584\n",
      "epoch 25, batch 170, loss = 2.683926820755005\n",
      "epoch 25, batch 180, loss = 2.6598246097564697\n",
      "epoch 25, batch 190, loss = 2.7354421615600586\n",
      "epoch 25, batch 200, loss = 2.696263074874878\n",
      "epoch 25, batch 210, loss = 2.686022996902466\n",
      "epoch 25, batch 220, loss = 2.676490068435669\n",
      "epoch 25, batch 230, loss = 2.6754794120788574\n",
      "epoch 25, batch 240, loss = 2.696106433868408\n",
      "epoch 25, batch 250, loss = 2.693906784057617\n",
      "epoch 25, batch 260, loss = 2.7076914310455322\n",
      "epoch 25, batch 270, loss = 2.7605724334716797\n",
      "epoch 25, batch 280, loss = 2.6797242164611816\n",
      "epoch 26, batch 0, loss = 2.673464298248291\n",
      "epoch 26, batch 10, loss = 2.6644771099090576\n",
      "epoch 26, batch 20, loss = 2.6779394149780273\n",
      "epoch 26, batch 30, loss = 2.6657791137695312\n",
      "epoch 26, batch 40, loss = 2.670814275741577\n",
      "epoch 26, batch 50, loss = 2.699509859085083\n",
      "epoch 26, batch 60, loss = 2.7300467491149902\n",
      "epoch 26, batch 70, loss = 2.666438341140747\n",
      "epoch 26, batch 80, loss = 2.678281784057617\n",
      "epoch 26, batch 90, loss = 2.7142443656921387\n",
      "epoch 26, batch 100, loss = 2.6457390785217285\n",
      "epoch 26, batch 110, loss = 2.6526060104370117\n",
      "epoch 26, batch 120, loss = 2.645094871520996\n",
      "epoch 26, batch 130, loss = 2.7007248401641846\n",
      "epoch 26, batch 140, loss = 2.696166515350342\n",
      "epoch 26, batch 150, loss = 2.691800594329834\n",
      "epoch 26, batch 160, loss = 2.7156972885131836\n",
      "epoch 26, batch 170, loss = 2.6722664833068848\n",
      "epoch 26, batch 180, loss = 2.642268657684326\n",
      "epoch 26, batch 190, loss = 2.7177515029907227\n",
      "epoch 26, batch 200, loss = 2.74114990234375\n",
      "epoch 26, batch 210, loss = 2.721519708633423\n",
      "epoch 26, batch 220, loss = 2.708646535873413\n",
      "epoch 26, batch 230, loss = 2.676848888397217\n",
      "epoch 26, batch 240, loss = 2.700300693511963\n",
      "epoch 26, batch 250, loss = 2.676046848297119\n",
      "epoch 26, batch 260, loss = 2.715574264526367\n",
      "epoch 26, batch 270, loss = 2.6720170974731445\n",
      "epoch 26, batch 280, loss = 2.758753776550293\n",
      "epoch 27, batch 0, loss = 2.6347339153289795\n",
      "epoch 27, batch 10, loss = 2.708895206451416\n",
      "epoch 27, batch 20, loss = 2.6819329261779785\n",
      "epoch 27, batch 30, loss = 2.6764025688171387\n",
      "epoch 27, batch 40, loss = 2.675276756286621\n",
      "epoch 27, batch 50, loss = 2.693347215652466\n",
      "epoch 27, batch 60, loss = 2.7039825916290283\n",
      "epoch 27, batch 70, loss = 2.6593804359436035\n",
      "epoch 27, batch 80, loss = 2.697406530380249\n",
      "epoch 27, batch 90, loss = 2.750242233276367\n",
      "epoch 27, batch 100, loss = 2.638153553009033\n",
      "epoch 27, batch 110, loss = 2.695115089416504\n",
      "epoch 27, batch 120, loss = 2.6952414512634277\n",
      "epoch 27, batch 130, loss = 2.6658520698547363\n",
      "epoch 27, batch 140, loss = 2.678616523742676\n",
      "epoch 27, batch 150, loss = 2.6794683933258057\n",
      "epoch 27, batch 160, loss = 2.668610095977783\n",
      "epoch 27, batch 170, loss = 2.747506618499756\n",
      "epoch 27, batch 180, loss = 2.738018035888672\n",
      "epoch 27, batch 190, loss = 2.7289628982543945\n",
      "epoch 27, batch 200, loss = 2.6611530780792236\n",
      "epoch 27, batch 210, loss = 2.6660492420196533\n",
      "epoch 27, batch 220, loss = 2.690276622772217\n",
      "epoch 27, batch 230, loss = 2.6899940967559814\n",
      "epoch 27, batch 240, loss = 2.7328014373779297\n",
      "epoch 27, batch 250, loss = 2.7098312377929688\n",
      "epoch 27, batch 260, loss = 2.719254970550537\n",
      "epoch 27, batch 270, loss = 2.732250213623047\n",
      "epoch 27, batch 280, loss = 2.6759209632873535\n",
      "epoch 28, batch 0, loss = 2.637545108795166\n",
      "epoch 28, batch 10, loss = 2.743624687194824\n",
      "epoch 28, batch 20, loss = 2.6636648178100586\n",
      "epoch 28, batch 30, loss = 2.6877403259277344\n",
      "epoch 28, batch 40, loss = 2.634939432144165\n",
      "epoch 28, batch 50, loss = 2.6652684211730957\n",
      "epoch 28, batch 60, loss = 2.6546339988708496\n",
      "epoch 28, batch 70, loss = 2.6511034965515137\n",
      "epoch 28, batch 80, loss = 2.712151050567627\n",
      "epoch 28, batch 90, loss = 2.6811962127685547\n",
      "epoch 28, batch 100, loss = 2.7260985374450684\n",
      "epoch 28, batch 110, loss = 2.6870903968811035\n",
      "epoch 28, batch 120, loss = 2.6978960037231445\n",
      "epoch 28, batch 130, loss = 2.7100443840026855\n",
      "epoch 28, batch 140, loss = 2.6647732257843018\n",
      "epoch 28, batch 150, loss = 2.666957378387451\n",
      "epoch 28, batch 160, loss = 2.667402744293213\n",
      "epoch 28, batch 170, loss = 2.682284355163574\n",
      "epoch 28, batch 180, loss = 2.701408624649048\n",
      "epoch 28, batch 190, loss = 2.693854331970215\n",
      "epoch 28, batch 200, loss = 2.6883392333984375\n",
      "epoch 28, batch 210, loss = 2.6866703033447266\n",
      "epoch 28, batch 220, loss = 2.715681552886963\n",
      "epoch 28, batch 230, loss = 2.7172794342041016\n",
      "epoch 28, batch 240, loss = 2.7022790908813477\n",
      "epoch 28, batch 250, loss = 2.746633291244507\n",
      "epoch 28, batch 260, loss = 2.6552467346191406\n",
      "epoch 28, batch 270, loss = 2.7151083946228027\n",
      "epoch 28, batch 280, loss = 2.7337331771850586\n",
      "epoch 29, batch 0, loss = 2.7317161560058594\n",
      "epoch 29, batch 10, loss = 2.72946834564209\n",
      "epoch 29, batch 20, loss = 2.6766810417175293\n",
      "epoch 29, batch 30, loss = 2.714904308319092\n",
      "epoch 29, batch 40, loss = 2.649122476577759\n",
      "epoch 29, batch 50, loss = 2.708754539489746\n",
      "epoch 29, batch 60, loss = 2.686781883239746\n",
      "epoch 29, batch 70, loss = 2.6969423294067383\n",
      "epoch 29, batch 80, loss = 2.682187080383301\n",
      "epoch 29, batch 90, loss = 2.6585922241210938\n",
      "epoch 29, batch 100, loss = 2.7215688228607178\n",
      "epoch 29, batch 110, loss = 2.686696767807007\n",
      "epoch 29, batch 120, loss = 2.6414270401000977\n",
      "epoch 29, batch 130, loss = 2.6725997924804688\n",
      "epoch 29, batch 140, loss = 2.706618309020996\n",
      "epoch 29, batch 150, loss = 2.653229236602783\n",
      "epoch 29, batch 160, loss = 2.715996265411377\n",
      "epoch 29, batch 170, loss = 2.6405084133148193\n",
      "epoch 29, batch 180, loss = 2.6748361587524414\n",
      "epoch 29, batch 190, loss = 2.6513671875\n",
      "epoch 29, batch 200, loss = 2.680581569671631\n",
      "epoch 29, batch 210, loss = 2.685190200805664\n",
      "epoch 29, batch 220, loss = 2.6888585090637207\n",
      "epoch 29, batch 230, loss = 2.745654344558716\n",
      "epoch 29, batch 240, loss = 2.7036428451538086\n",
      "epoch 29, batch 250, loss = 2.6917264461517334\n",
      "epoch 29, batch 260, loss = 2.710704803466797\n",
      "epoch 29, batch 270, loss = 2.664175033569336\n",
      "epoch 29, batch 280, loss = 2.6545634269714355\n",
      "epoch 30, batch 0, loss = 2.6440069675445557\n",
      "epoch 30, batch 10, loss = 2.6623406410217285\n",
      "epoch 30, batch 20, loss = 2.6400437355041504\n",
      "epoch 30, batch 30, loss = 2.6970272064208984\n",
      "epoch 30, batch 40, loss = 2.6743764877319336\n",
      "epoch 30, batch 50, loss = 2.6426522731781006\n",
      "epoch 30, batch 60, loss = 2.6167449951171875\n",
      "epoch 30, batch 70, loss = 2.664637565612793\n",
      "epoch 30, batch 80, loss = 2.675118923187256\n",
      "epoch 30, batch 90, loss = 2.6735680103302\n",
      "epoch 30, batch 100, loss = 2.6766979694366455\n",
      "epoch 30, batch 110, loss = 2.691962480545044\n",
      "epoch 30, batch 120, loss = 2.6975769996643066\n",
      "epoch 30, batch 130, loss = 2.6334447860717773\n",
      "epoch 30, batch 140, loss = 2.6624245643615723\n",
      "epoch 30, batch 150, loss = 2.7330312728881836\n",
      "epoch 30, batch 160, loss = 2.6156466007232666\n",
      "epoch 30, batch 170, loss = 2.667722702026367\n",
      "epoch 30, batch 180, loss = 2.6076111793518066\n",
      "epoch 30, batch 190, loss = 2.720755100250244\n",
      "epoch 30, batch 200, loss = 2.640437126159668\n",
      "epoch 30, batch 210, loss = 2.669668436050415\n",
      "epoch 30, batch 220, loss = 2.6751885414123535\n",
      "epoch 30, batch 230, loss = 2.666703939437866\n",
      "epoch 30, batch 240, loss = 2.7252821922302246\n",
      "epoch 30, batch 250, loss = 2.7220945358276367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, batch 260, loss = 2.6763904094696045\n",
      "epoch 30, batch 270, loss = 2.6720972061157227\n",
      "epoch 30, batch 280, loss = 2.698326826095581\n",
      "epoch 31, batch 0, loss = 2.644132614135742\n",
      "epoch 31, batch 10, loss = 2.70188570022583\n",
      "epoch 31, batch 20, loss = 2.6432437896728516\n",
      "epoch 31, batch 30, loss = 2.678601026535034\n",
      "epoch 31, batch 40, loss = 2.6643874645233154\n",
      "epoch 31, batch 50, loss = 2.6753225326538086\n",
      "epoch 31, batch 60, loss = 2.699669122695923\n",
      "epoch 31, batch 70, loss = 2.7036943435668945\n",
      "epoch 31, batch 80, loss = 2.71893310546875\n",
      "epoch 31, batch 90, loss = 2.705899477005005\n",
      "epoch 31, batch 100, loss = 2.684706687927246\n",
      "epoch 31, batch 110, loss = 2.699069023132324\n",
      "epoch 31, batch 120, loss = 2.766448736190796\n",
      "epoch 31, batch 130, loss = 2.711073637008667\n",
      "epoch 31, batch 140, loss = 2.6798813343048096\n",
      "epoch 31, batch 150, loss = 2.6906793117523193\n",
      "epoch 31, batch 160, loss = 2.697939872741699\n",
      "epoch 31, batch 170, loss = 2.6719377040863037\n",
      "epoch 31, batch 180, loss = 2.7106499671936035\n",
      "epoch 31, batch 190, loss = 2.6824660301208496\n",
      "epoch 31, batch 200, loss = 2.6920056343078613\n",
      "epoch 31, batch 210, loss = 2.701711654663086\n",
      "epoch 31, batch 220, loss = 2.713413715362549\n",
      "epoch 31, batch 230, loss = 2.702518939971924\n",
      "epoch 31, batch 240, loss = 2.714386463165283\n",
      "epoch 31, batch 250, loss = 2.716939926147461\n",
      "epoch 31, batch 260, loss = 2.693169116973877\n",
      "epoch 31, batch 270, loss = 2.695356845855713\n",
      "epoch 31, batch 280, loss = 2.6451334953308105\n",
      "epoch 32, batch 0, loss = 2.675980806350708\n",
      "epoch 32, batch 10, loss = 2.6469156742095947\n",
      "epoch 32, batch 20, loss = 2.6483891010284424\n",
      "epoch 32, batch 30, loss = 2.6890501976013184\n",
      "epoch 32, batch 40, loss = 2.6330819129943848\n",
      "epoch 32, batch 50, loss = 2.6953134536743164\n",
      "epoch 32, batch 60, loss = 2.7181363105773926\n",
      "epoch 32, batch 70, loss = 2.6689727306365967\n",
      "epoch 32, batch 80, loss = 2.7194015979766846\n",
      "epoch 32, batch 90, loss = 2.6715617179870605\n",
      "epoch 32, batch 100, loss = 2.6433701515197754\n",
      "epoch 32, batch 110, loss = 2.661083221435547\n",
      "epoch 32, batch 120, loss = 2.6790285110473633\n",
      "epoch 32, batch 130, loss = 2.6943960189819336\n",
      "epoch 32, batch 140, loss = 2.6915767192840576\n",
      "epoch 32, batch 150, loss = 2.734098434448242\n",
      "epoch 32, batch 160, loss = 2.713484525680542\n",
      "epoch 32, batch 170, loss = 2.659613609313965\n",
      "epoch 32, batch 180, loss = 2.7145018577575684\n",
      "epoch 32, batch 190, loss = 2.6610124111175537\n",
      "epoch 32, batch 200, loss = 2.659461259841919\n",
      "epoch 32, batch 210, loss = 2.687286853790283\n",
      "epoch 32, batch 220, loss = 2.7046473026275635\n",
      "epoch 32, batch 230, loss = 2.6676902770996094\n",
      "epoch 32, batch 240, loss = 2.656433582305908\n",
      "epoch 32, batch 250, loss = 2.610827922821045\n",
      "epoch 32, batch 260, loss = 2.6499133110046387\n",
      "epoch 32, batch 270, loss = 2.6598944664001465\n",
      "epoch 32, batch 280, loss = 2.625304937362671\n",
      "epoch 33, batch 0, loss = 2.645521879196167\n",
      "epoch 33, batch 10, loss = 2.612159252166748\n",
      "epoch 33, batch 20, loss = 2.6004438400268555\n",
      "epoch 33, batch 30, loss = 2.6884512901306152\n",
      "epoch 33, batch 40, loss = 2.6863932609558105\n",
      "epoch 33, batch 50, loss = 2.657820701599121\n",
      "epoch 33, batch 60, loss = 2.6498146057128906\n",
      "epoch 33, batch 70, loss = 2.6559910774230957\n",
      "epoch 33, batch 80, loss = 2.722050666809082\n",
      "epoch 33, batch 90, loss = 2.6937010288238525\n",
      "epoch 33, batch 100, loss = 2.6624820232391357\n",
      "epoch 33, batch 110, loss = 2.6587541103363037\n",
      "epoch 33, batch 120, loss = 2.721281051635742\n",
      "epoch 33, batch 130, loss = 2.630927801132202\n",
      "epoch 33, batch 140, loss = 2.6666436195373535\n",
      "epoch 33, batch 150, loss = 2.699676752090454\n",
      "epoch 33, batch 160, loss = 2.6864206790924072\n",
      "epoch 33, batch 170, loss = 2.728508710861206\n",
      "epoch 33, batch 180, loss = 2.7171120643615723\n",
      "epoch 33, batch 190, loss = 2.6515774726867676\n",
      "epoch 33, batch 200, loss = 2.6581995487213135\n",
      "epoch 33, batch 210, loss = 2.7192349433898926\n",
      "epoch 33, batch 220, loss = 2.7089803218841553\n",
      "epoch 33, batch 230, loss = 2.6594512462615967\n",
      "epoch 33, batch 240, loss = 2.6416664123535156\n",
      "epoch 33, batch 250, loss = 2.673893928527832\n",
      "epoch 33, batch 260, loss = 2.7075600624084473\n",
      "epoch 33, batch 270, loss = 2.6536734104156494\n",
      "epoch 33, batch 280, loss = 2.693547487258911\n",
      "epoch 34, batch 0, loss = 2.6223490238189697\n",
      "epoch 34, batch 10, loss = 2.6677300930023193\n",
      "epoch 34, batch 20, loss = 2.6727874279022217\n",
      "epoch 34, batch 30, loss = 2.653566360473633\n",
      "epoch 34, batch 40, loss = 2.6861019134521484\n",
      "epoch 34, batch 50, loss = 2.6778130531311035\n",
      "epoch 34, batch 60, loss = 2.69789457321167\n",
      "epoch 34, batch 70, loss = 2.693263530731201\n",
      "epoch 34, batch 80, loss = 2.673558473587036\n",
      "epoch 34, batch 90, loss = 2.6500253677368164\n",
      "epoch 34, batch 100, loss = 2.6691246032714844\n",
      "epoch 34, batch 110, loss = 2.643843173980713\n",
      "epoch 34, batch 120, loss = 2.6691415309906006\n",
      "epoch 34, batch 130, loss = 2.6556100845336914\n",
      "epoch 34, batch 140, loss = 2.6933956146240234\n",
      "epoch 34, batch 150, loss = 2.643125057220459\n",
      "epoch 34, batch 160, loss = 2.676421880722046\n",
      "epoch 34, batch 170, loss = 2.7261672019958496\n",
      "epoch 34, batch 180, loss = 2.703009843826294\n",
      "epoch 34, batch 190, loss = 2.702115058898926\n",
      "epoch 34, batch 200, loss = 2.6704604625701904\n",
      "epoch 34, batch 210, loss = 2.682940721511841\n",
      "epoch 34, batch 220, loss = 2.645387649536133\n",
      "epoch 34, batch 230, loss = 2.6778900623321533\n",
      "epoch 34, batch 240, loss = 2.682274341583252\n",
      "epoch 34, batch 250, loss = 2.6993939876556396\n",
      "epoch 34, batch 260, loss = 2.7068967819213867\n",
      "epoch 34, batch 270, loss = 2.6952905654907227\n",
      "epoch 34, batch 280, loss = 2.7363786697387695\n",
      "epoch 35, batch 0, loss = 2.6235244274139404\n",
      "epoch 35, batch 10, loss = 2.7071585655212402\n",
      "epoch 35, batch 20, loss = 2.6276206970214844\n",
      "epoch 35, batch 30, loss = 2.6948890686035156\n",
      "epoch 35, batch 40, loss = 2.65732479095459\n",
      "epoch 35, batch 50, loss = 2.6415343284606934\n",
      "epoch 35, batch 60, loss = 2.6902682781219482\n",
      "epoch 35, batch 70, loss = 2.6178746223449707\n",
      "epoch 35, batch 80, loss = 2.627812385559082\n",
      "epoch 35, batch 90, loss = 2.611833095550537\n",
      "epoch 35, batch 100, loss = 2.655236005783081\n",
      "epoch 35, batch 110, loss = 2.6382558345794678\n",
      "epoch 35, batch 120, loss = 2.674797534942627\n",
      "epoch 35, batch 130, loss = 2.6357245445251465\n",
      "epoch 35, batch 140, loss = 2.685053825378418\n",
      "epoch 35, batch 150, loss = 2.6799349784851074\n",
      "epoch 35, batch 160, loss = 2.6242568492889404\n",
      "epoch 35, batch 170, loss = 2.687847852706909\n",
      "epoch 35, batch 180, loss = 2.6841788291931152\n",
      "epoch 35, batch 190, loss = 2.6643896102905273\n",
      "epoch 35, batch 200, loss = 2.6793880462646484\n",
      "epoch 35, batch 210, loss = 2.6211938858032227\n",
      "epoch 35, batch 220, loss = 2.6322247982025146\n",
      "epoch 35, batch 230, loss = 2.7229318618774414\n",
      "epoch 35, batch 240, loss = 2.712714672088623\n",
      "epoch 35, batch 250, loss = 2.6687097549438477\n",
      "epoch 35, batch 260, loss = 2.707667350769043\n",
      "epoch 35, batch 270, loss = 2.686068058013916\n",
      "epoch 35, batch 280, loss = 2.67490291595459\n",
      "epoch 36, batch 0, loss = 2.6094212532043457\n",
      "epoch 36, batch 10, loss = 2.646531343460083\n",
      "epoch 36, batch 20, loss = 2.6387951374053955\n",
      "epoch 36, batch 30, loss = 2.67006516456604\n",
      "epoch 36, batch 40, loss = 2.696488857269287\n",
      "epoch 36, batch 50, loss = 2.7262895107269287\n",
      "epoch 36, batch 60, loss = 2.6815671920776367\n",
      "epoch 36, batch 70, loss = 2.5949440002441406\n",
      "epoch 36, batch 80, loss = 2.708751678466797\n",
      "epoch 36, batch 90, loss = 2.645287275314331\n",
      "epoch 36, batch 100, loss = 2.6032071113586426\n",
      "epoch 36, batch 110, loss = 2.71604061126709\n",
      "epoch 36, batch 120, loss = 2.7214131355285645\n",
      "epoch 36, batch 130, loss = 2.676886796951294\n",
      "epoch 36, batch 140, loss = 2.6469221115112305\n",
      "epoch 36, batch 150, loss = 2.689189910888672\n",
      "epoch 36, batch 160, loss = 2.6386489868164062\n",
      "epoch 36, batch 170, loss = 2.6771795749664307\n",
      "epoch 36, batch 180, loss = 2.640698194503784\n",
      "epoch 36, batch 190, loss = 2.6727182865142822\n",
      "epoch 36, batch 200, loss = 2.63458514213562\n",
      "epoch 36, batch 210, loss = 2.7255773544311523\n",
      "epoch 36, batch 220, loss = 2.6611857414245605\n",
      "epoch 36, batch 230, loss = 2.690052032470703\n",
      "epoch 36, batch 240, loss = 2.675830364227295\n",
      "epoch 36, batch 250, loss = 2.6476693153381348\n",
      "epoch 36, batch 260, loss = 2.6687979698181152\n",
      "epoch 36, batch 270, loss = 2.671675682067871\n",
      "epoch 36, batch 280, loss = 2.6734108924865723\n",
      "epoch 37, batch 0, loss = 2.6811156272888184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, batch 10, loss = 2.6304686069488525\n",
      "epoch 37, batch 20, loss = 2.5988481044769287\n",
      "epoch 37, batch 30, loss = 2.634349822998047\n",
      "epoch 37, batch 40, loss = 2.6439127922058105\n",
      "epoch 37, batch 50, loss = 2.649951457977295\n",
      "epoch 37, batch 60, loss = 2.654613494873047\n",
      "epoch 37, batch 70, loss = 2.672102928161621\n",
      "epoch 37, batch 80, loss = 2.6809167861938477\n",
      "epoch 37, batch 90, loss = 2.6461551189422607\n",
      "epoch 37, batch 100, loss = 2.7385711669921875\n",
      "epoch 37, batch 110, loss = 2.606367588043213\n",
      "epoch 37, batch 120, loss = 2.721500873565674\n",
      "epoch 37, batch 130, loss = 2.666260242462158\n",
      "epoch 37, batch 140, loss = 2.6714365482330322\n",
      "epoch 37, batch 150, loss = 2.6855647563934326\n",
      "epoch 37, batch 160, loss = 2.688079357147217\n",
      "epoch 37, batch 170, loss = 2.654271125793457\n",
      "epoch 37, batch 180, loss = 2.6439356803894043\n",
      "epoch 37, batch 190, loss = 2.6579465866088867\n",
      "epoch 37, batch 200, loss = 2.7026515007019043\n",
      "epoch 37, batch 210, loss = 2.706042528152466\n",
      "epoch 37, batch 220, loss = 2.6604790687561035\n",
      "epoch 37, batch 230, loss = 2.6978769302368164\n",
      "epoch 37, batch 240, loss = 2.6589839458465576\n",
      "epoch 37, batch 250, loss = 2.6747453212738037\n",
      "epoch 37, batch 260, loss = 2.6826343536376953\n",
      "epoch 37, batch 270, loss = 2.691708564758301\n",
      "epoch 37, batch 280, loss = 2.643968105316162\n",
      "epoch 38, batch 0, loss = 2.64825701713562\n",
      "epoch 38, batch 10, loss = 2.6277847290039062\n",
      "epoch 38, batch 20, loss = 2.6452319622039795\n",
      "epoch 38, batch 30, loss = 2.671090602874756\n",
      "epoch 38, batch 40, loss = 2.6755242347717285\n",
      "epoch 38, batch 50, loss = 2.63647723197937\n",
      "epoch 38, batch 60, loss = 2.6418991088867188\n",
      "epoch 38, batch 70, loss = 2.608999729156494\n",
      "epoch 38, batch 80, loss = 2.6021347045898438\n",
      "epoch 38, batch 90, loss = 2.6578009128570557\n",
      "epoch 38, batch 100, loss = 2.6542627811431885\n",
      "epoch 38, batch 110, loss = 2.689396858215332\n",
      "epoch 38, batch 120, loss = 2.6657357215881348\n",
      "epoch 38, batch 130, loss = 2.667804718017578\n",
      "epoch 38, batch 140, loss = 2.7195847034454346\n",
      "epoch 38, batch 150, loss = 2.6188864707946777\n",
      "epoch 38, batch 160, loss = 2.6569347381591797\n",
      "epoch 38, batch 170, loss = 2.6840853691101074\n",
      "epoch 38, batch 180, loss = 2.6430482864379883\n",
      "epoch 38, batch 190, loss = 2.6938233375549316\n",
      "epoch 38, batch 200, loss = 2.677645206451416\n",
      "epoch 38, batch 210, loss = 2.6706509590148926\n",
      "epoch 38, batch 220, loss = 2.6090564727783203\n",
      "epoch 38, batch 230, loss = 2.6805992126464844\n",
      "epoch 38, batch 240, loss = 2.619534492492676\n",
      "epoch 38, batch 250, loss = 2.6086559295654297\n",
      "epoch 38, batch 260, loss = 2.7038683891296387\n",
      "epoch 38, batch 270, loss = 2.672001361846924\n",
      "epoch 38, batch 280, loss = 2.602932929992676\n",
      "epoch 39, batch 0, loss = 2.6356117725372314\n",
      "epoch 39, batch 10, loss = 2.600334405899048\n",
      "epoch 39, batch 20, loss = 2.649779796600342\n",
      "epoch 39, batch 30, loss = 2.7235007286071777\n",
      "epoch 39, batch 40, loss = 2.6232409477233887\n",
      "epoch 39, batch 50, loss = 2.6172451972961426\n",
      "epoch 39, batch 60, loss = 2.7151451110839844\n",
      "epoch 39, batch 70, loss = 2.6612586975097656\n",
      "epoch 39, batch 80, loss = 2.6599555015563965\n",
      "epoch 39, batch 90, loss = 2.6771392822265625\n",
      "epoch 39, batch 100, loss = 2.6463561058044434\n",
      "epoch 39, batch 110, loss = 2.621166706085205\n",
      "epoch 39, batch 120, loss = 2.649994373321533\n",
      "epoch 39, batch 130, loss = 2.6690688133239746\n",
      "epoch 39, batch 140, loss = 2.6252529621124268\n",
      "epoch 39, batch 150, loss = 2.6383190155029297\n",
      "epoch 39, batch 160, loss = 2.6646151542663574\n",
      "epoch 39, batch 170, loss = 2.6445975303649902\n",
      "epoch 39, batch 180, loss = 2.697794198989868\n",
      "epoch 39, batch 190, loss = 2.633269786834717\n",
      "epoch 39, batch 200, loss = 2.6625797748565674\n",
      "epoch 39, batch 210, loss = 2.6959948539733887\n",
      "epoch 39, batch 220, loss = 2.6231606006622314\n",
      "epoch 39, batch 230, loss = 2.6536498069763184\n",
      "epoch 39, batch 240, loss = 2.647226333618164\n",
      "epoch 39, batch 250, loss = 2.645472288131714\n",
      "epoch 39, batch 260, loss = 2.625147819519043\n",
      "epoch 39, batch 270, loss = 2.642066240310669\n",
      "epoch 39, batch 280, loss = 2.710948944091797\n",
      "epoch 40, batch 0, loss = 2.5841751098632812\n",
      "epoch 40, batch 10, loss = 2.6457009315490723\n",
      "epoch 40, batch 20, loss = 2.6448607444763184\n",
      "epoch 40, batch 30, loss = 2.686722755432129\n",
      "epoch 40, batch 40, loss = 2.617860794067383\n",
      "epoch 40, batch 50, loss = 2.6391654014587402\n",
      "epoch 40, batch 60, loss = 2.663668155670166\n",
      "epoch 40, batch 70, loss = 2.6811065673828125\n",
      "epoch 40, batch 80, loss = 2.6260294914245605\n",
      "epoch 40, batch 90, loss = 2.6407272815704346\n",
      "epoch 40, batch 100, loss = 2.632810592651367\n",
      "epoch 40, batch 110, loss = 2.6236743927001953\n",
      "epoch 40, batch 120, loss = 2.706747531890869\n",
      "epoch 40, batch 130, loss = 2.6892714500427246\n",
      "epoch 40, batch 140, loss = 2.6386351585388184\n",
      "epoch 40, batch 150, loss = 2.6718955039978027\n",
      "epoch 40, batch 160, loss = 2.64608097076416\n",
      "epoch 40, batch 170, loss = 2.6241064071655273\n",
      "epoch 40, batch 180, loss = 2.6314830780029297\n",
      "epoch 40, batch 190, loss = 2.673165798187256\n",
      "epoch 40, batch 200, loss = 2.6593170166015625\n",
      "epoch 40, batch 210, loss = 2.7406795024871826\n",
      "epoch 40, batch 220, loss = 2.6719579696655273\n",
      "epoch 40, batch 230, loss = 2.680166244506836\n",
      "epoch 40, batch 240, loss = 2.660966396331787\n",
      "epoch 40, batch 250, loss = 2.6733360290527344\n",
      "epoch 40, batch 260, loss = 2.6657798290252686\n",
      "epoch 40, batch 270, loss = 2.682473659515381\n",
      "epoch 40, batch 280, loss = 2.6408770084381104\n",
      "epoch 41, batch 0, loss = 2.650111675262451\n",
      "epoch 41, batch 10, loss = 2.6745688915252686\n",
      "epoch 41, batch 20, loss = 2.654022693634033\n",
      "epoch 41, batch 30, loss = 2.617462635040283\n",
      "epoch 41, batch 40, loss = 2.6603589057922363\n",
      "epoch 41, batch 50, loss = 2.6352553367614746\n",
      "epoch 41, batch 60, loss = 2.6746559143066406\n",
      "epoch 41, batch 70, loss = 2.6348214149475098\n",
      "epoch 41, batch 80, loss = 2.668914794921875\n",
      "epoch 41, batch 90, loss = 2.668302297592163\n",
      "epoch 41, batch 100, loss = 2.629835367202759\n",
      "epoch 41, batch 110, loss = 2.701317548751831\n",
      "epoch 41, batch 120, loss = 2.613982677459717\n",
      "epoch 41, batch 130, loss = 2.71669340133667\n",
      "epoch 41, batch 140, loss = 2.642017126083374\n",
      "epoch 41, batch 150, loss = 2.6446869373321533\n",
      "epoch 41, batch 160, loss = 2.6427345275878906\n",
      "epoch 41, batch 170, loss = 2.661952257156372\n",
      "epoch 41, batch 180, loss = 2.6486659049987793\n",
      "epoch 41, batch 190, loss = 2.6890318393707275\n",
      "epoch 41, batch 200, loss = 2.61922025680542\n",
      "epoch 41, batch 210, loss = 2.632577419281006\n",
      "epoch 41, batch 220, loss = 2.668994903564453\n",
      "epoch 41, batch 230, loss = 2.657160997390747\n",
      "epoch 41, batch 240, loss = 2.641618251800537\n",
      "epoch 41, batch 250, loss = 2.667168140411377\n",
      "epoch 41, batch 260, loss = 2.6324098110198975\n",
      "epoch 41, batch 270, loss = 2.6860971450805664\n",
      "epoch 41, batch 280, loss = 2.668084144592285\n",
      "epoch 42, batch 0, loss = 2.5909476280212402\n",
      "epoch 42, batch 10, loss = 2.5962281227111816\n",
      "epoch 42, batch 20, loss = 2.7204413414001465\n",
      "epoch 42, batch 30, loss = 2.617870807647705\n",
      "epoch 42, batch 40, loss = 2.604778289794922\n",
      "epoch 42, batch 50, loss = 2.6795873641967773\n",
      "epoch 42, batch 60, loss = 2.6281578540802\n",
      "epoch 42, batch 70, loss = 2.6104941368103027\n",
      "epoch 42, batch 80, loss = 2.64227294921875\n",
      "epoch 42, batch 90, loss = 2.595219850540161\n",
      "epoch 42, batch 100, loss = 2.6721010208129883\n",
      "epoch 42, batch 110, loss = 2.6909666061401367\n",
      "epoch 42, batch 120, loss = 2.681851863861084\n",
      "epoch 42, batch 130, loss = 2.6792843341827393\n",
      "epoch 42, batch 140, loss = 2.601313829421997\n",
      "epoch 42, batch 150, loss = 2.6714844703674316\n",
      "epoch 42, batch 160, loss = 2.618330955505371\n",
      "epoch 42, batch 170, loss = 2.681218147277832\n",
      "epoch 42, batch 180, loss = 2.6476314067840576\n",
      "epoch 42, batch 190, loss = 2.637413501739502\n",
      "epoch 42, batch 200, loss = 2.585002899169922\n",
      "epoch 42, batch 210, loss = 2.6458792686462402\n",
      "epoch 42, batch 220, loss = 2.6628355979919434\n",
      "epoch 42, batch 230, loss = 2.679342746734619\n",
      "epoch 42, batch 240, loss = 2.6821022033691406\n",
      "epoch 42, batch 250, loss = 2.6732137203216553\n",
      "epoch 42, batch 260, loss = 2.6426913738250732\n",
      "epoch 42, batch 270, loss = 2.613619327545166\n",
      "epoch 42, batch 280, loss = 2.676198720932007\n",
      "epoch 43, batch 0, loss = 2.6516757011413574\n",
      "epoch 43, batch 10, loss = 2.651676893234253\n",
      "epoch 43, batch 20, loss = 2.597804069519043\n",
      "epoch 43, batch 30, loss = 2.6092536449432373\n",
      "epoch 43, batch 40, loss = 2.6821670532226562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, batch 50, loss = 2.617619752883911\n",
      "epoch 43, batch 60, loss = 2.6732892990112305\n",
      "epoch 43, batch 70, loss = 2.6667332649230957\n",
      "epoch 43, batch 80, loss = 2.6714248657226562\n",
      "epoch 43, batch 90, loss = 2.582911491394043\n",
      "epoch 43, batch 100, loss = 2.6016368865966797\n",
      "epoch 43, batch 110, loss = 2.686519145965576\n",
      "epoch 43, batch 120, loss = 2.6707141399383545\n",
      "epoch 43, batch 130, loss = 2.6458940505981445\n",
      "epoch 43, batch 140, loss = 2.6745386123657227\n",
      "epoch 43, batch 150, loss = 2.6498632431030273\n",
      "epoch 43, batch 160, loss = 2.6638269424438477\n",
      "epoch 43, batch 170, loss = 2.679373025894165\n",
      "epoch 43, batch 180, loss = 2.6831064224243164\n",
      "epoch 43, batch 190, loss = 2.6261980533599854\n",
      "epoch 43, batch 200, loss = 2.659148931503296\n",
      "epoch 43, batch 210, loss = 2.670079469680786\n",
      "epoch 43, batch 220, loss = 2.7297470569610596\n",
      "epoch 43, batch 230, loss = 2.6851930618286133\n",
      "epoch 43, batch 240, loss = 2.714975357055664\n",
      "epoch 43, batch 250, loss = 2.6126222610473633\n",
      "epoch 43, batch 260, loss = 2.6277036666870117\n",
      "epoch 43, batch 270, loss = 2.68340802192688\n",
      "epoch 43, batch 280, loss = 2.6567816734313965\n",
      "epoch 44, batch 0, loss = 2.6158287525177\n",
      "epoch 44, batch 10, loss = 2.6198363304138184\n",
      "epoch 44, batch 20, loss = 2.6211986541748047\n",
      "epoch 44, batch 30, loss = 2.627002239227295\n",
      "epoch 44, batch 40, loss = 2.573758125305176\n",
      "epoch 44, batch 50, loss = 2.696485996246338\n",
      "epoch 44, batch 60, loss = 2.6005563735961914\n",
      "epoch 44, batch 70, loss = 2.657060146331787\n",
      "epoch 44, batch 80, loss = 2.6363282203674316\n",
      "epoch 44, batch 90, loss = 2.6238858699798584\n",
      "epoch 44, batch 100, loss = 2.681046724319458\n",
      "epoch 44, batch 110, loss = 2.6225907802581787\n",
      "epoch 44, batch 120, loss = 2.6474852561950684\n",
      "epoch 44, batch 130, loss = 2.6068172454833984\n",
      "epoch 44, batch 140, loss = 2.648561477661133\n",
      "epoch 44, batch 150, loss = 2.6496119499206543\n",
      "epoch 44, batch 160, loss = 2.6312990188598633\n",
      "epoch 44, batch 170, loss = 2.645010232925415\n",
      "epoch 44, batch 180, loss = 2.6584348678588867\n",
      "epoch 44, batch 190, loss = 2.702531337738037\n",
      "epoch 44, batch 200, loss = 2.671384334564209\n",
      "epoch 44, batch 210, loss = 2.6405930519104004\n",
      "epoch 44, batch 220, loss = 2.6736490726470947\n",
      "epoch 44, batch 230, loss = 2.645669460296631\n",
      "epoch 44, batch 240, loss = 2.6515533924102783\n",
      "epoch 44, batch 250, loss = 2.5972352027893066\n",
      "epoch 44, batch 260, loss = 2.6388540267944336\n",
      "epoch 44, batch 270, loss = 2.6572635173797607\n",
      "epoch 44, batch 280, loss = 2.646500587463379\n",
      "epoch 45, batch 0, loss = 2.6044576168060303\n",
      "epoch 45, batch 10, loss = 2.571521759033203\n",
      "epoch 45, batch 20, loss = 2.636146068572998\n",
      "epoch 45, batch 30, loss = 2.6878154277801514\n",
      "epoch 45, batch 40, loss = 2.6652841567993164\n",
      "epoch 45, batch 50, loss = 2.6257827281951904\n",
      "epoch 45, batch 60, loss = 2.6141715049743652\n",
      "epoch 45, batch 70, loss = 2.701103687286377\n",
      "epoch 45, batch 80, loss = 2.624760627746582\n",
      "epoch 45, batch 90, loss = 2.677241802215576\n",
      "epoch 45, batch 100, loss = 2.6260147094726562\n",
      "epoch 45, batch 110, loss = 2.671416759490967\n",
      "epoch 45, batch 120, loss = 2.644394636154175\n",
      "epoch 45, batch 130, loss = 2.695594549179077\n",
      "epoch 45, batch 140, loss = 2.6631696224212646\n",
      "epoch 45, batch 150, loss = 2.636965751647949\n",
      "epoch 45, batch 160, loss = 2.6641921997070312\n",
      "epoch 45, batch 170, loss = 2.69209623336792\n",
      "epoch 45, batch 180, loss = 2.6494452953338623\n",
      "epoch 45, batch 190, loss = 2.6355721950531006\n",
      "epoch 45, batch 200, loss = 2.6580793857574463\n",
      "epoch 45, batch 210, loss = 2.6788039207458496\n",
      "epoch 45, batch 220, loss = 2.654249668121338\n",
      "epoch 45, batch 230, loss = 2.67010235786438\n",
      "epoch 45, batch 240, loss = 2.6430890560150146\n",
      "epoch 45, batch 250, loss = 2.641557455062866\n",
      "epoch 45, batch 260, loss = 2.6343822479248047\n",
      "epoch 45, batch 270, loss = 2.691549777984619\n",
      "epoch 45, batch 280, loss = 2.6590232849121094\n",
      "epoch 46, batch 0, loss = 2.607308864593506\n",
      "epoch 46, batch 10, loss = 2.67120361328125\n",
      "epoch 46, batch 20, loss = 2.662691116333008\n",
      "epoch 46, batch 30, loss = 2.577211380004883\n",
      "epoch 46, batch 40, loss = 2.683602809906006\n",
      "epoch 46, batch 50, loss = 2.6166508197784424\n",
      "epoch 46, batch 60, loss = 2.6177544593811035\n",
      "epoch 46, batch 70, loss = 2.7086048126220703\n",
      "epoch 46, batch 80, loss = 2.6368162631988525\n",
      "epoch 46, batch 90, loss = 2.6409108638763428\n",
      "epoch 46, batch 100, loss = 2.6687283515930176\n",
      "epoch 46, batch 110, loss = 2.7101261615753174\n",
      "epoch 46, batch 120, loss = 2.6038148403167725\n",
      "epoch 46, batch 130, loss = 2.6370885372161865\n",
      "epoch 46, batch 140, loss = 2.6209049224853516\n",
      "epoch 46, batch 150, loss = 2.628915309906006\n",
      "epoch 46, batch 160, loss = 2.6227734088897705\n",
      "epoch 46, batch 170, loss = 2.6584086418151855\n",
      "epoch 46, batch 180, loss = 2.6737937927246094\n",
      "epoch 46, batch 190, loss = 2.6659960746765137\n",
      "epoch 46, batch 200, loss = 2.5941405296325684\n",
      "epoch 46, batch 210, loss = 2.6424264907836914\n",
      "epoch 46, batch 220, loss = 2.606874942779541\n",
      "epoch 46, batch 230, loss = 2.6613268852233887\n",
      "epoch 46, batch 240, loss = 2.669053077697754\n",
      "epoch 46, batch 250, loss = 2.699749708175659\n",
      "epoch 46, batch 260, loss = 2.653158664703369\n",
      "epoch 46, batch 270, loss = 2.704792022705078\n",
      "epoch 46, batch 280, loss = 2.654344320297241\n",
      "epoch 47, batch 0, loss = 2.641287326812744\n",
      "epoch 47, batch 10, loss = 2.675515651702881\n",
      "epoch 47, batch 20, loss = 2.616631507873535\n",
      "epoch 47, batch 30, loss = 2.615962028503418\n",
      "epoch 47, batch 40, loss = 2.5960848331451416\n",
      "epoch 47, batch 50, loss = 2.596958875656128\n",
      "epoch 47, batch 60, loss = 2.6743268966674805\n",
      "epoch 47, batch 70, loss = 2.5964713096618652\n",
      "epoch 47, batch 80, loss = 2.6610307693481445\n",
      "epoch 47, batch 90, loss = 2.6525630950927734\n",
      "epoch 47, batch 100, loss = 2.6332664489746094\n",
      "epoch 47, batch 110, loss = 2.637040138244629\n",
      "epoch 47, batch 120, loss = 2.658374309539795\n",
      "epoch 47, batch 130, loss = 2.590463638305664\n",
      "epoch 47, batch 140, loss = 2.6367812156677246\n",
      "epoch 47, batch 150, loss = 2.6896181106567383\n",
      "epoch 47, batch 160, loss = 2.670496702194214\n",
      "epoch 47, batch 170, loss = 2.6499671936035156\n",
      "epoch 47, batch 180, loss = 2.671525716781616\n",
      "epoch 47, batch 190, loss = 2.686826229095459\n",
      "epoch 47, batch 200, loss = 2.6015753746032715\n",
      "epoch 47, batch 210, loss = 2.622692108154297\n",
      "epoch 47, batch 220, loss = 2.653082847595215\n",
      "epoch 47, batch 230, loss = 2.6084702014923096\n",
      "epoch 47, batch 240, loss = 2.6643548011779785\n",
      "epoch 47, batch 250, loss = 2.631702423095703\n",
      "epoch 47, batch 260, loss = 2.6320741176605225\n",
      "epoch 47, batch 270, loss = 2.640584945678711\n",
      "epoch 47, batch 280, loss = 2.7194597721099854\n",
      "epoch 48, batch 0, loss = 2.6129708290100098\n",
      "epoch 48, batch 10, loss = 2.5829415321350098\n",
      "epoch 48, batch 20, loss = 2.6926984786987305\n",
      "epoch 48, batch 30, loss = 2.6256752014160156\n",
      "epoch 48, batch 40, loss = 2.6357460021972656\n",
      "epoch 48, batch 50, loss = 2.628244161605835\n",
      "epoch 48, batch 60, loss = 2.6432156562805176\n",
      "epoch 48, batch 70, loss = 2.653609275817871\n",
      "epoch 48, batch 80, loss = 2.6632561683654785\n",
      "epoch 48, batch 90, loss = 2.624622344970703\n",
      "epoch 48, batch 100, loss = 2.6530323028564453\n",
      "epoch 48, batch 110, loss = 2.6104929447174072\n",
      "epoch 48, batch 120, loss = 2.7335383892059326\n",
      "epoch 48, batch 130, loss = 2.617741584777832\n",
      "epoch 48, batch 140, loss = 2.6147594451904297\n",
      "epoch 48, batch 150, loss = 2.657907485961914\n",
      "epoch 48, batch 160, loss = 2.5828099250793457\n",
      "epoch 48, batch 170, loss = 2.617050886154175\n",
      "epoch 48, batch 180, loss = 2.6773219108581543\n",
      "epoch 48, batch 190, loss = 2.6717846393585205\n",
      "epoch 48, batch 200, loss = 2.659708023071289\n",
      "epoch 48, batch 210, loss = 2.6435344219207764\n",
      "epoch 48, batch 220, loss = 2.6487503051757812\n",
      "epoch 48, batch 230, loss = 2.69453763961792\n",
      "epoch 48, batch 240, loss = 2.633833169937134\n",
      "epoch 48, batch 250, loss = 2.6939404010772705\n",
      "epoch 48, batch 260, loss = 2.6335864067077637\n",
      "epoch 48, batch 270, loss = 2.6205661296844482\n",
      "epoch 48, batch 280, loss = 2.669052839279175\n",
      "epoch 49, batch 0, loss = 2.5851056575775146\n",
      "epoch 49, batch 10, loss = 2.5563266277313232\n",
      "epoch 49, batch 20, loss = 2.6211636066436768\n",
      "epoch 49, batch 30, loss = 2.6828713417053223\n",
      "epoch 49, batch 40, loss = 2.6101298332214355\n",
      "epoch 49, batch 50, loss = 2.6391243934631348\n",
      "epoch 49, batch 60, loss = 2.7181782722473145\n",
      "epoch 49, batch 70, loss = 2.6826701164245605\n",
      "epoch 49, batch 80, loss = 2.625957727432251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, batch 90, loss = 2.6778724193573\n",
      "epoch 49, batch 100, loss = 2.662787914276123\n",
      "epoch 49, batch 110, loss = 2.6274619102478027\n",
      "epoch 49, batch 120, loss = 2.6271114349365234\n",
      "epoch 49, batch 130, loss = 2.6812620162963867\n",
      "epoch 49, batch 140, loss = 2.6520252227783203\n",
      "epoch 49, batch 150, loss = 2.630413293838501\n",
      "epoch 49, batch 160, loss = 2.6454315185546875\n",
      "epoch 49, batch 170, loss = 2.677338123321533\n",
      "epoch 49, batch 180, loss = 2.6869921684265137\n",
      "epoch 49, batch 190, loss = 2.6586198806762695\n",
      "epoch 49, batch 200, loss = 2.667084217071533\n",
      "epoch 49, batch 210, loss = 2.658641815185547\n",
      "epoch 49, batch 220, loss = 2.6651530265808105\n",
      "epoch 49, batch 230, loss = 2.6425557136535645\n",
      "epoch 49, batch 240, loss = 2.60209321975708\n",
      "epoch 49, batch 250, loss = 2.6813621520996094\n",
      "epoch 49, batch 260, loss = 2.701512098312378\n",
      "epoch 49, batch 270, loss = 2.637747287750244\n",
      "epoch 49, batch 280, loss = 2.6903929710388184\n",
      "epoch 50, batch 0, loss = 2.6270859241485596\n",
      "epoch 50, batch 10, loss = 2.6709232330322266\n",
      "epoch 50, batch 20, loss = 2.596524477005005\n",
      "epoch 50, batch 30, loss = 2.61171293258667\n",
      "epoch 50, batch 40, loss = 2.629763126373291\n",
      "epoch 50, batch 50, loss = 2.6128227710723877\n",
      "epoch 50, batch 60, loss = 2.6556472778320312\n",
      "epoch 50, batch 70, loss = 2.591817855834961\n",
      "epoch 50, batch 80, loss = 2.5969700813293457\n",
      "epoch 50, batch 90, loss = 2.6419763565063477\n",
      "epoch 50, batch 100, loss = 2.603621482849121\n",
      "epoch 50, batch 110, loss = 2.5866920948028564\n",
      "epoch 50, batch 120, loss = 2.645420789718628\n",
      "epoch 50, batch 130, loss = 2.570100784301758\n",
      "epoch 50, batch 140, loss = 2.605905055999756\n",
      "epoch 50, batch 150, loss = 2.665748119354248\n",
      "epoch 50, batch 160, loss = 2.6318163871765137\n",
      "epoch 50, batch 170, loss = 2.6369757652282715\n",
      "epoch 50, batch 180, loss = 2.664473533630371\n",
      "epoch 50, batch 190, loss = 2.661060094833374\n",
      "epoch 50, batch 200, loss = 2.580012798309326\n",
      "epoch 50, batch 210, loss = 2.5963494777679443\n",
      "epoch 50, batch 220, loss = 2.621575355529785\n",
      "epoch 50, batch 230, loss = 2.6524884700775146\n",
      "epoch 50, batch 240, loss = 2.6217079162597656\n",
      "epoch 50, batch 250, loss = 2.659773588180542\n",
      "epoch 50, batch 260, loss = 2.6462960243225098\n",
      "epoch 50, batch 270, loss = 2.6663925647735596\n",
      "epoch 50, batch 280, loss = 2.6390347480773926\n",
      "epoch 51, batch 0, loss = 2.6384825706481934\n",
      "epoch 51, batch 10, loss = 2.5943262577056885\n",
      "epoch 51, batch 20, loss = 2.6272945404052734\n",
      "epoch 51, batch 30, loss = 2.6227216720581055\n",
      "epoch 51, batch 40, loss = 2.627981185913086\n",
      "epoch 51, batch 50, loss = 2.64210844039917\n",
      "epoch 51, batch 60, loss = 2.6369450092315674\n",
      "epoch 51, batch 70, loss = 2.622734546661377\n",
      "epoch 51, batch 80, loss = 2.6215806007385254\n",
      "epoch 51, batch 90, loss = 2.697303056716919\n",
      "epoch 51, batch 100, loss = 2.624544382095337\n",
      "epoch 51, batch 110, loss = 2.6144351959228516\n",
      "epoch 51, batch 120, loss = 2.611006259918213\n",
      "epoch 51, batch 130, loss = 2.685896635055542\n",
      "epoch 51, batch 140, loss = 2.659623622894287\n",
      "epoch 51, batch 150, loss = 2.6570019721984863\n",
      "epoch 51, batch 160, loss = 2.6496684551239014\n",
      "epoch 51, batch 170, loss = 2.662433624267578\n",
      "epoch 51, batch 180, loss = 2.5682461261749268\n",
      "epoch 51, batch 190, loss = 2.6323251724243164\n",
      "epoch 51, batch 200, loss = 2.6348581314086914\n",
      "epoch 51, batch 210, loss = 2.624570608139038\n",
      "epoch 51, batch 220, loss = 2.652235507965088\n",
      "epoch 51, batch 230, loss = 2.6785147190093994\n",
      "epoch 51, batch 240, loss = 2.679687738418579\n",
      "epoch 51, batch 250, loss = 2.651491641998291\n",
      "epoch 51, batch 260, loss = 2.688131332397461\n",
      "epoch 51, batch 270, loss = 2.6561903953552246\n",
      "epoch 51, batch 280, loss = 2.6703224182128906\n",
      "epoch 52, batch 0, loss = 2.6206448078155518\n",
      "epoch 52, batch 10, loss = 2.565481185913086\n",
      "epoch 52, batch 20, loss = 2.590475559234619\n",
      "epoch 52, batch 30, loss = 2.624614715576172\n",
      "epoch 52, batch 40, loss = 2.626800537109375\n",
      "epoch 52, batch 50, loss = 2.6253833770751953\n",
      "epoch 52, batch 60, loss = 2.618467330932617\n",
      "epoch 52, batch 70, loss = 2.614149570465088\n",
      "epoch 52, batch 80, loss = 2.616433620452881\n",
      "epoch 52, batch 90, loss = 2.6068997383117676\n",
      "epoch 52, batch 100, loss = 2.623608350753784\n",
      "epoch 52, batch 110, loss = 2.677579641342163\n",
      "epoch 52, batch 120, loss = 2.601762294769287\n",
      "epoch 52, batch 130, loss = 2.6127541065216064\n",
      "epoch 52, batch 140, loss = 2.653074264526367\n",
      "epoch 52, batch 150, loss = 2.683997631072998\n",
      "epoch 52, batch 160, loss = 2.58463716506958\n",
      "epoch 52, batch 170, loss = 2.647063732147217\n",
      "epoch 52, batch 180, loss = 2.6713242530822754\n",
      "epoch 52, batch 190, loss = 2.70112681388855\n",
      "epoch 52, batch 200, loss = 2.653765916824341\n",
      "epoch 52, batch 210, loss = 2.6469740867614746\n",
      "epoch 52, batch 220, loss = 2.6538872718811035\n",
      "epoch 52, batch 230, loss = 2.6326096057891846\n",
      "epoch 52, batch 240, loss = 2.6501259803771973\n",
      "epoch 52, batch 250, loss = 2.625979423522949\n",
      "epoch 52, batch 260, loss = 2.63847017288208\n",
      "epoch 52, batch 270, loss = 2.6105332374572754\n",
      "epoch 52, batch 280, loss = 2.667919635772705\n",
      "epoch 53, batch 0, loss = 2.639085054397583\n",
      "epoch 53, batch 10, loss = 2.601456642150879\n",
      "epoch 53, batch 20, loss = 2.6219096183776855\n",
      "epoch 53, batch 30, loss = 2.6163368225097656\n",
      "epoch 53, batch 40, loss = 2.6734232902526855\n",
      "epoch 53, batch 50, loss = 2.654383659362793\n",
      "epoch 53, batch 60, loss = 2.6164352893829346\n",
      "epoch 53, batch 70, loss = 2.6104867458343506\n",
      "epoch 53, batch 80, loss = 2.627781391143799\n",
      "epoch 53, batch 90, loss = 2.6041347980499268\n",
      "epoch 53, batch 100, loss = 2.665648937225342\n",
      "epoch 53, batch 110, loss = 2.6187310218811035\n",
      "epoch 53, batch 120, loss = 2.6490564346313477\n",
      "epoch 53, batch 130, loss = 2.6112895011901855\n",
      "epoch 53, batch 140, loss = 2.626885414123535\n",
      "epoch 53, batch 150, loss = 2.676598310470581\n",
      "epoch 53, batch 160, loss = 2.630629301071167\n",
      "epoch 53, batch 170, loss = 2.6017489433288574\n",
      "epoch 53, batch 180, loss = 2.656831979751587\n",
      "epoch 53, batch 190, loss = 2.700000047683716\n",
      "epoch 53, batch 200, loss = 2.5966315269470215\n",
      "epoch 53, batch 210, loss = 2.637816905975342\n",
      "epoch 53, batch 220, loss = 2.622716188430786\n",
      "epoch 53, batch 230, loss = 2.5994606018066406\n",
      "epoch 53, batch 240, loss = 2.6416537761688232\n",
      "epoch 53, batch 250, loss = 2.611776351928711\n",
      "epoch 53, batch 260, loss = 2.6211938858032227\n",
      "epoch 53, batch 270, loss = 2.649501323699951\n",
      "epoch 53, batch 280, loss = 2.6472835540771484\n",
      "epoch 54, batch 0, loss = 2.6010994911193848\n",
      "epoch 54, batch 10, loss = 2.594581127166748\n",
      "epoch 54, batch 20, loss = 2.607010841369629\n",
      "epoch 54, batch 30, loss = 2.6464431285858154\n",
      "epoch 54, batch 40, loss = 2.6436662673950195\n",
      "epoch 54, batch 50, loss = 2.641146659851074\n",
      "epoch 54, batch 60, loss = 2.556053638458252\n",
      "epoch 54, batch 70, loss = 2.642721652984619\n",
      "epoch 54, batch 80, loss = 2.539923667907715\n",
      "epoch 54, batch 90, loss = 2.635561466217041\n",
      "epoch 54, batch 100, loss = 2.591825008392334\n",
      "epoch 54, batch 110, loss = 2.6752278804779053\n",
      "epoch 54, batch 120, loss = 2.6557493209838867\n",
      "epoch 54, batch 130, loss = 2.6077959537506104\n",
      "epoch 54, batch 140, loss = 2.6609716415405273\n",
      "epoch 54, batch 150, loss = 2.6090664863586426\n",
      "epoch 54, batch 160, loss = 2.644320487976074\n",
      "epoch 54, batch 170, loss = 2.6470727920532227\n",
      "epoch 54, batch 180, loss = 2.6510305404663086\n",
      "epoch 54, batch 190, loss = 2.670628786087036\n",
      "epoch 54, batch 200, loss = 2.6223232746124268\n",
      "epoch 54, batch 210, loss = 2.5916976928710938\n",
      "epoch 54, batch 220, loss = 2.7067489624023438\n",
      "epoch 54, batch 230, loss = 2.645817518234253\n",
      "epoch 54, batch 240, loss = 2.632570505142212\n",
      "epoch 54, batch 250, loss = 2.6286423206329346\n",
      "epoch 54, batch 260, loss = 2.626023292541504\n",
      "epoch 54, batch 270, loss = 2.601444959640503\n",
      "epoch 54, batch 280, loss = 2.626377582550049\n",
      "epoch 55, batch 0, loss = 2.601102352142334\n",
      "epoch 55, batch 10, loss = 2.6050033569335938\n",
      "epoch 55, batch 20, loss = 2.591024398803711\n",
      "epoch 55, batch 30, loss = 2.6325063705444336\n",
      "epoch 55, batch 40, loss = 2.6121816635131836\n",
      "epoch 55, batch 50, loss = 2.651482343673706\n",
      "epoch 55, batch 60, loss = 2.6149303913116455\n",
      "epoch 55, batch 70, loss = 2.5912208557128906\n",
      "epoch 55, batch 80, loss = 2.6173768043518066\n",
      "epoch 55, batch 90, loss = 2.6822285652160645\n",
      "epoch 55, batch 100, loss = 2.6236841678619385\n",
      "epoch 55, batch 110, loss = 2.649221897125244\n",
      "epoch 55, batch 120, loss = 2.6635518074035645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, batch 130, loss = 2.633399486541748\n",
      "epoch 55, batch 140, loss = 2.6352198123931885\n",
      "epoch 55, batch 150, loss = 2.6322145462036133\n",
      "epoch 55, batch 160, loss = 2.63820219039917\n",
      "epoch 55, batch 170, loss = 2.627930164337158\n",
      "epoch 55, batch 180, loss = 2.5845580101013184\n",
      "epoch 55, batch 190, loss = 2.618638277053833\n",
      "epoch 55, batch 200, loss = 2.5885426998138428\n",
      "epoch 55, batch 210, loss = 2.5793678760528564\n",
      "epoch 55, batch 220, loss = 2.6750149726867676\n",
      "epoch 55, batch 230, loss = 2.59545636177063\n",
      "epoch 55, batch 240, loss = 2.612649917602539\n",
      "epoch 55, batch 250, loss = 2.6173295974731445\n",
      "epoch 55, batch 260, loss = 2.6315579414367676\n",
      "epoch 55, batch 270, loss = 2.6552090644836426\n",
      "epoch 55, batch 280, loss = 2.6013236045837402\n",
      "epoch 56, batch 0, loss = 2.59818172454834\n",
      "epoch 56, batch 10, loss = 2.6844143867492676\n",
      "epoch 56, batch 20, loss = 2.607532024383545\n",
      "epoch 56, batch 30, loss = 2.5524234771728516\n",
      "epoch 56, batch 40, loss = 2.5955557823181152\n",
      "epoch 56, batch 50, loss = 2.609927177429199\n",
      "epoch 56, batch 60, loss = 2.6630022525787354\n",
      "epoch 56, batch 70, loss = 2.6650147438049316\n",
      "epoch 56, batch 80, loss = 2.641463041305542\n",
      "epoch 56, batch 90, loss = 2.5442771911621094\n",
      "epoch 56, batch 100, loss = 2.69319748878479\n",
      "epoch 56, batch 110, loss = 2.597677230834961\n",
      "epoch 56, batch 120, loss = 2.651951313018799\n",
      "epoch 56, batch 130, loss = 2.6689515113830566\n",
      "epoch 56, batch 140, loss = 2.653676986694336\n",
      "epoch 56, batch 150, loss = 2.597135543823242\n",
      "epoch 56, batch 160, loss = 2.5591259002685547\n",
      "epoch 56, batch 170, loss = 2.599308490753174\n",
      "epoch 56, batch 180, loss = 2.6494688987731934\n",
      "epoch 56, batch 190, loss = 2.5945372581481934\n",
      "epoch 56, batch 200, loss = 2.59637451171875\n",
      "epoch 56, batch 210, loss = 2.6040995121002197\n",
      "epoch 56, batch 220, loss = 2.6367833614349365\n",
      "epoch 56, batch 230, loss = 2.650221347808838\n",
      "epoch 56, batch 240, loss = 2.657655715942383\n",
      "epoch 56, batch 250, loss = 2.638138771057129\n",
      "epoch 56, batch 260, loss = 2.6107187271118164\n",
      "epoch 56, batch 270, loss = 2.643669605255127\n",
      "epoch 56, batch 280, loss = 2.6188225746154785\n",
      "epoch 57, batch 0, loss = 2.64878511428833\n",
      "epoch 57, batch 10, loss = 2.5941357612609863\n",
      "epoch 57, batch 20, loss = 2.637936592102051\n",
      "epoch 57, batch 30, loss = 2.5895280838012695\n",
      "epoch 57, batch 40, loss = 2.6351230144500732\n",
      "epoch 57, batch 50, loss = 2.5606348514556885\n",
      "epoch 57, batch 60, loss = 2.6494369506835938\n",
      "epoch 57, batch 70, loss = 2.596557855606079\n",
      "epoch 57, batch 80, loss = 2.612804889678955\n",
      "epoch 57, batch 90, loss = 2.6124038696289062\n",
      "epoch 57, batch 100, loss = 2.640040874481201\n",
      "epoch 57, batch 110, loss = 2.6018505096435547\n",
      "epoch 57, batch 120, loss = 2.6812169551849365\n",
      "epoch 57, batch 130, loss = 2.6409482955932617\n",
      "epoch 57, batch 140, loss = 2.6092629432678223\n",
      "epoch 57, batch 150, loss = 2.6014575958251953\n",
      "epoch 57, batch 160, loss = 2.642455577850342\n",
      "epoch 57, batch 170, loss = 2.6370487213134766\n",
      "epoch 57, batch 180, loss = 2.6392414569854736\n",
      "epoch 57, batch 190, loss = 2.6270174980163574\n",
      "epoch 57, batch 200, loss = 2.6222379207611084\n",
      "epoch 57, batch 210, loss = 2.594670057296753\n",
      "epoch 57, batch 220, loss = 2.6291701793670654\n",
      "epoch 57, batch 230, loss = 2.618105888366699\n",
      "epoch 57, batch 240, loss = 2.6511991024017334\n",
      "epoch 57, batch 250, loss = 2.603707790374756\n",
      "epoch 57, batch 260, loss = 2.6426310539245605\n",
      "epoch 57, batch 270, loss = 2.7035348415374756\n",
      "epoch 57, batch 280, loss = 2.559731960296631\n",
      "epoch 58, batch 0, loss = 2.6316232681274414\n",
      "epoch 58, batch 10, loss = 2.560594320297241\n",
      "epoch 58, batch 20, loss = 2.6039323806762695\n",
      "epoch 58, batch 30, loss = 2.6318323612213135\n",
      "epoch 58, batch 40, loss = 2.564701557159424\n",
      "epoch 58, batch 50, loss = 2.612795114517212\n",
      "epoch 58, batch 60, loss = 2.6347739696502686\n",
      "epoch 58, batch 70, loss = 2.5989155769348145\n",
      "epoch 58, batch 80, loss = 2.6561946868896484\n",
      "epoch 58, batch 90, loss = 2.6415393352508545\n",
      "epoch 58, batch 100, loss = 2.6331787109375\n",
      "epoch 58, batch 110, loss = 2.5581562519073486\n",
      "epoch 58, batch 120, loss = 2.627340793609619\n",
      "epoch 58, batch 130, loss = 2.677769660949707\n",
      "epoch 58, batch 140, loss = 2.6233999729156494\n",
      "epoch 58, batch 150, loss = 2.6699178218841553\n",
      "epoch 58, batch 160, loss = 2.644329071044922\n",
      "epoch 58, batch 170, loss = 2.684070587158203\n",
      "epoch 58, batch 180, loss = 2.6985535621643066\n",
      "epoch 58, batch 190, loss = 2.7022502422332764\n",
      "epoch 58, batch 200, loss = 2.5838420391082764\n",
      "epoch 58, batch 210, loss = 2.6132924556732178\n",
      "epoch 58, batch 220, loss = 2.609739303588867\n",
      "epoch 58, batch 230, loss = 2.615443706512451\n",
      "epoch 58, batch 240, loss = 2.6037516593933105\n",
      "epoch 58, batch 250, loss = 2.5675952434539795\n",
      "epoch 58, batch 260, loss = 2.6218364238739014\n",
      "epoch 58, batch 270, loss = 2.710520029067993\n",
      "epoch 58, batch 280, loss = 2.662724018096924\n",
      "epoch 59, batch 0, loss = 2.6055123805999756\n",
      "epoch 59, batch 10, loss = 2.6230993270874023\n",
      "epoch 59, batch 20, loss = 2.6227803230285645\n",
      "epoch 59, batch 30, loss = 2.5841150283813477\n",
      "epoch 59, batch 40, loss = 2.6216259002685547\n",
      "epoch 59, batch 50, loss = 2.607929229736328\n",
      "epoch 59, batch 60, loss = 2.62030291557312\n",
      "epoch 59, batch 70, loss = 2.618934154510498\n",
      "epoch 59, batch 80, loss = 2.642866849899292\n",
      "epoch 59, batch 90, loss = 2.5846714973449707\n",
      "epoch 59, batch 100, loss = 2.6362876892089844\n",
      "epoch 59, batch 110, loss = 2.613412380218506\n",
      "epoch 59, batch 120, loss = 2.6364529132843018\n",
      "epoch 59, batch 130, loss = 2.6190009117126465\n",
      "epoch 59, batch 140, loss = 2.6506500244140625\n",
      "epoch 59, batch 150, loss = 2.6518218517303467\n",
      "epoch 59, batch 160, loss = 2.659642219543457\n",
      "epoch 59, batch 170, loss = 2.636897087097168\n",
      "epoch 59, batch 180, loss = 2.603933334350586\n",
      "epoch 59, batch 190, loss = 2.618027687072754\n",
      "epoch 59, batch 200, loss = 2.709289073944092\n",
      "epoch 59, batch 210, loss = 2.6369242668151855\n",
      "epoch 59, batch 220, loss = 2.5664563179016113\n",
      "epoch 59, batch 230, loss = 2.5868289470672607\n",
      "epoch 59, batch 240, loss = 2.6865074634552\n",
      "epoch 59, batch 250, loss = 2.6193859577178955\n",
      "epoch 59, batch 260, loss = 2.645549774169922\n",
      "epoch 59, batch 270, loss = 2.646308183670044\n",
      "epoch 59, batch 280, loss = 2.625537395477295\n",
      "epoch 60, batch 0, loss = 2.5587897300720215\n",
      "epoch 60, batch 10, loss = 2.6049351692199707\n",
      "epoch 60, batch 20, loss = 2.6338610649108887\n",
      "epoch 60, batch 30, loss = 2.620650291442871\n",
      "epoch 60, batch 40, loss = 2.620920419692993\n",
      "epoch 60, batch 50, loss = 2.626945734024048\n",
      "epoch 60, batch 60, loss = 2.6039299964904785\n",
      "epoch 60, batch 70, loss = 2.53653621673584\n",
      "epoch 60, batch 80, loss = 2.63187837600708\n",
      "epoch 60, batch 90, loss = 2.654120922088623\n",
      "epoch 60, batch 100, loss = 2.6110329627990723\n",
      "epoch 60, batch 110, loss = 2.5757579803466797\n",
      "epoch 60, batch 120, loss = 2.6138081550598145\n",
      "epoch 60, batch 130, loss = 2.5965514183044434\n",
      "epoch 60, batch 140, loss = 2.594703435897827\n",
      "epoch 60, batch 150, loss = 2.6596357822418213\n",
      "epoch 60, batch 160, loss = 2.6598007678985596\n",
      "epoch 60, batch 170, loss = 2.6249094009399414\n",
      "epoch 60, batch 180, loss = 2.636017322540283\n",
      "epoch 60, batch 190, loss = 2.642338752746582\n",
      "epoch 60, batch 200, loss = 2.6251769065856934\n",
      "epoch 60, batch 210, loss = 2.5625932216644287\n",
      "epoch 60, batch 220, loss = 2.6132516860961914\n",
      "epoch 60, batch 230, loss = 2.6375181674957275\n",
      "epoch 60, batch 240, loss = 2.6099658012390137\n",
      "epoch 60, batch 250, loss = 2.6107234954833984\n",
      "epoch 60, batch 260, loss = 2.6492412090301514\n",
      "epoch 60, batch 270, loss = 2.6512222290039062\n",
      "epoch 60, batch 280, loss = 2.6243653297424316\n",
      "epoch 61, batch 0, loss = 2.625814914703369\n",
      "epoch 61, batch 10, loss = 2.586040496826172\n",
      "epoch 61, batch 20, loss = 2.6628904342651367\n",
      "epoch 61, batch 30, loss = 2.6349472999572754\n",
      "epoch 61, batch 40, loss = 2.614859104156494\n",
      "epoch 61, batch 50, loss = 2.540440082550049\n",
      "epoch 61, batch 60, loss = 2.6701319217681885\n",
      "epoch 61, batch 70, loss = 2.5244803428649902\n",
      "epoch 61, batch 80, loss = 2.5864572525024414\n",
      "epoch 61, batch 90, loss = 2.5819449424743652\n",
      "epoch 61, batch 100, loss = 2.655341148376465\n",
      "epoch 61, batch 110, loss = 2.615107297897339\n",
      "epoch 61, batch 120, loss = 2.5943870544433594\n",
      "epoch 61, batch 130, loss = 2.665570020675659\n",
      "epoch 61, batch 140, loss = 2.6234941482543945\n",
      "epoch 61, batch 150, loss = 2.59458589553833\n",
      "epoch 61, batch 160, loss = 2.5565571784973145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, batch 170, loss = 2.597409725189209\n",
      "epoch 61, batch 180, loss = 2.6466546058654785\n",
      "epoch 61, batch 190, loss = 2.6272425651550293\n",
      "epoch 61, batch 200, loss = 2.6566250324249268\n",
      "epoch 61, batch 210, loss = 2.645073175430298\n",
      "epoch 61, batch 220, loss = 2.629546642303467\n",
      "epoch 61, batch 230, loss = 2.64880108833313\n",
      "epoch 61, batch 240, loss = 2.6505348682403564\n",
      "epoch 61, batch 250, loss = 2.609429359436035\n",
      "epoch 61, batch 260, loss = 2.5754780769348145\n",
      "epoch 61, batch 270, loss = 2.6433138847351074\n",
      "epoch 61, batch 280, loss = 2.603105306625366\n",
      "epoch 62, batch 0, loss = 2.58305025100708\n",
      "epoch 62, batch 10, loss = 2.594888687133789\n",
      "epoch 62, batch 20, loss = 2.599020481109619\n",
      "epoch 62, batch 30, loss = 2.6328182220458984\n",
      "epoch 62, batch 40, loss = 2.604985237121582\n",
      "epoch 62, batch 50, loss = 2.5794005393981934\n",
      "epoch 62, batch 60, loss = 2.5963215827941895\n",
      "epoch 62, batch 70, loss = 2.6031298637390137\n",
      "epoch 62, batch 80, loss = 2.624791383743286\n",
      "epoch 62, batch 90, loss = 2.592183828353882\n",
      "epoch 62, batch 100, loss = 2.6668906211853027\n",
      "epoch 62, batch 110, loss = 2.6320390701293945\n",
      "epoch 62, batch 120, loss = 2.6230833530426025\n",
      "epoch 62, batch 130, loss = 2.6326382160186768\n",
      "epoch 62, batch 140, loss = 2.653824806213379\n",
      "epoch 62, batch 150, loss = 2.584774971008301\n",
      "epoch 62, batch 160, loss = 2.6309266090393066\n",
      "epoch 62, batch 170, loss = 2.5821173191070557\n",
      "epoch 62, batch 180, loss = 2.647045850753784\n",
      "epoch 62, batch 190, loss = 2.6634202003479004\n",
      "epoch 62, batch 200, loss = 2.609158992767334\n",
      "epoch 62, batch 210, loss = 2.6239678859710693\n",
      "epoch 62, batch 220, loss = 2.6597065925598145\n",
      "epoch 62, batch 230, loss = 2.627169609069824\n",
      "epoch 62, batch 240, loss = 2.602658987045288\n",
      "epoch 62, batch 250, loss = 2.620687484741211\n",
      "epoch 62, batch 260, loss = 2.6127688884735107\n",
      "epoch 62, batch 270, loss = 2.571664571762085\n",
      "epoch 62, batch 280, loss = 2.60381817817688\n",
      "epoch 63, batch 0, loss = 2.586111068725586\n",
      "epoch 63, batch 10, loss = 2.5599770545959473\n",
      "epoch 63, batch 20, loss = 2.5133719444274902\n",
      "epoch 63, batch 30, loss = 2.635754346847534\n",
      "epoch 63, batch 40, loss = 2.553874969482422\n",
      "epoch 63, batch 50, loss = 2.570824146270752\n",
      "epoch 63, batch 60, loss = 2.6296844482421875\n",
      "epoch 63, batch 70, loss = 2.673112154006958\n",
      "epoch 63, batch 80, loss = 2.587554454803467\n",
      "epoch 63, batch 90, loss = 2.6250159740448\n",
      "epoch 63, batch 100, loss = 2.5854506492614746\n",
      "epoch 63, batch 110, loss = 2.620819091796875\n",
      "epoch 63, batch 120, loss = 2.6048331260681152\n",
      "epoch 63, batch 130, loss = 2.5860369205474854\n",
      "epoch 63, batch 140, loss = 2.649549961090088\n",
      "epoch 63, batch 150, loss = 2.602968692779541\n",
      "epoch 63, batch 160, loss = 2.6134824752807617\n",
      "epoch 63, batch 170, loss = 2.6162095069885254\n",
      "epoch 63, batch 180, loss = 2.612884759902954\n",
      "epoch 63, batch 190, loss = 2.6422393321990967\n",
      "epoch 63, batch 200, loss = 2.6177573204040527\n",
      "epoch 63, batch 210, loss = 2.633028507232666\n",
      "epoch 63, batch 220, loss = 2.6963038444519043\n",
      "epoch 63, batch 230, loss = 2.5453500747680664\n",
      "epoch 63, batch 240, loss = 2.6171960830688477\n",
      "epoch 63, batch 250, loss = 2.6061763763427734\n",
      "epoch 63, batch 260, loss = 2.6590585708618164\n",
      "epoch 63, batch 270, loss = 2.579150676727295\n",
      "epoch 63, batch 280, loss = 2.5961899757385254\n",
      "epoch 64, batch 0, loss = 2.5376639366149902\n",
      "epoch 64, batch 10, loss = 2.612010955810547\n",
      "epoch 64, batch 20, loss = 2.5406689643859863\n",
      "epoch 64, batch 30, loss = 2.590689182281494\n",
      "epoch 64, batch 40, loss = 2.589465618133545\n",
      "epoch 64, batch 50, loss = 2.5725135803222656\n",
      "epoch 64, batch 60, loss = 2.5812454223632812\n",
      "epoch 64, batch 70, loss = 2.6470236778259277\n",
      "epoch 64, batch 80, loss = 2.591153144836426\n",
      "epoch 64, batch 90, loss = 2.612070322036743\n",
      "epoch 64, batch 100, loss = 2.59694766998291\n",
      "epoch 64, batch 110, loss = 2.636136531829834\n",
      "epoch 64, batch 120, loss = 2.612417221069336\n",
      "epoch 64, batch 130, loss = 2.592284679412842\n",
      "epoch 64, batch 140, loss = 2.6406354904174805\n",
      "epoch 64, batch 150, loss = 2.655677318572998\n",
      "epoch 64, batch 160, loss = 2.5922741889953613\n",
      "epoch 64, batch 170, loss = 2.6221494674682617\n",
      "epoch 64, batch 180, loss = 2.593064785003662\n",
      "epoch 64, batch 190, loss = 2.659348726272583\n",
      "epoch 64, batch 200, loss = 2.6101269721984863\n",
      "epoch 64, batch 210, loss = 2.605229377746582\n",
      "epoch 64, batch 220, loss = 2.5866646766662598\n",
      "epoch 64, batch 230, loss = 2.64998197555542\n",
      "epoch 64, batch 240, loss = 2.6184768676757812\n",
      "epoch 64, batch 250, loss = 2.672581195831299\n",
      "epoch 64, batch 260, loss = 2.6100265979766846\n",
      "epoch 64, batch 270, loss = 2.6502511501312256\n",
      "epoch 64, batch 280, loss = 2.6601929664611816\n",
      "epoch 65, batch 0, loss = 2.637744665145874\n",
      "epoch 65, batch 10, loss = 2.638302803039551\n",
      "epoch 65, batch 20, loss = 2.6228737831115723\n",
      "epoch 65, batch 30, loss = 2.653681993484497\n",
      "epoch 65, batch 40, loss = 2.596003532409668\n",
      "epoch 65, batch 50, loss = 2.618725061416626\n",
      "epoch 65, batch 60, loss = 2.607921600341797\n",
      "epoch 65, batch 70, loss = 2.6159467697143555\n",
      "epoch 65, batch 80, loss = 2.6157023906707764\n",
      "epoch 65, batch 90, loss = 2.627175807952881\n",
      "epoch 65, batch 100, loss = 2.6016364097595215\n",
      "epoch 65, batch 110, loss = 2.602966070175171\n",
      "epoch 65, batch 120, loss = 2.564517021179199\n",
      "epoch 65, batch 130, loss = 2.660743236541748\n",
      "epoch 65, batch 140, loss = 2.6769533157348633\n",
      "epoch 65, batch 150, loss = 2.6126649379730225\n",
      "epoch 65, batch 160, loss = 2.6254963874816895\n",
      "epoch 65, batch 170, loss = 2.622312545776367\n",
      "epoch 65, batch 180, loss = 2.634429454803467\n",
      "epoch 65, batch 190, loss = 2.6661489009857178\n",
      "epoch 65, batch 200, loss = 2.5860674381256104\n",
      "epoch 65, batch 210, loss = 2.6203105449676514\n",
      "epoch 65, batch 220, loss = 2.592693328857422\n",
      "epoch 65, batch 230, loss = 2.6417765617370605\n",
      "epoch 65, batch 240, loss = 2.5422873497009277\n",
      "epoch 65, batch 250, loss = 2.659877300262451\n",
      "epoch 65, batch 260, loss = 2.6434807777404785\n",
      "epoch 65, batch 270, loss = 2.6233949661254883\n",
      "epoch 65, batch 280, loss = 2.6398680210113525\n",
      "epoch 66, batch 0, loss = 2.548621416091919\n",
      "epoch 66, batch 10, loss = 2.613286256790161\n",
      "epoch 66, batch 20, loss = 2.577396869659424\n",
      "epoch 66, batch 30, loss = 2.6335020065307617\n",
      "epoch 66, batch 40, loss = 2.5833933353424072\n",
      "epoch 66, batch 50, loss = 2.661064863204956\n",
      "epoch 66, batch 60, loss = 2.5829949378967285\n",
      "epoch 66, batch 70, loss = 2.6252317428588867\n",
      "epoch 66, batch 80, loss = 2.640407085418701\n",
      "epoch 66, batch 90, loss = 2.6056694984436035\n",
      "epoch 66, batch 100, loss = 2.5791640281677246\n",
      "epoch 66, batch 110, loss = 2.579993724822998\n",
      "epoch 66, batch 120, loss = 2.5635290145874023\n",
      "epoch 66, batch 130, loss = 2.66147518157959\n",
      "epoch 66, batch 140, loss = 2.5853819847106934\n",
      "epoch 66, batch 150, loss = 2.6526293754577637\n",
      "epoch 66, batch 160, loss = 2.6255581378936768\n",
      "epoch 66, batch 170, loss = 2.6195948123931885\n",
      "epoch 66, batch 180, loss = 2.6580100059509277\n",
      "epoch 66, batch 190, loss = 2.6206953525543213\n",
      "epoch 66, batch 200, loss = 2.6467509269714355\n",
      "epoch 66, batch 210, loss = 2.600806474685669\n",
      "epoch 66, batch 220, loss = 2.6351168155670166\n",
      "epoch 66, batch 230, loss = 2.6207268238067627\n",
      "epoch 66, batch 240, loss = 2.644902229309082\n",
      "epoch 66, batch 250, loss = 2.6257169246673584\n",
      "epoch 66, batch 260, loss = 2.590486526489258\n",
      "epoch 66, batch 270, loss = 2.598897933959961\n",
      "epoch 66, batch 280, loss = 2.6535589694976807\n",
      "epoch 67, batch 0, loss = 2.626284122467041\n",
      "epoch 67, batch 10, loss = 2.641944169998169\n",
      "epoch 67, batch 20, loss = 2.634951591491699\n",
      "epoch 67, batch 30, loss = 2.6128454208374023\n",
      "epoch 67, batch 40, loss = 2.62965726852417\n",
      "epoch 67, batch 50, loss = 2.58229923248291\n",
      "epoch 67, batch 60, loss = 2.6562178134918213\n",
      "epoch 67, batch 70, loss = 2.5782008171081543\n",
      "epoch 67, batch 80, loss = 2.6590182781219482\n",
      "epoch 67, batch 90, loss = 2.6009111404418945\n",
      "epoch 67, batch 100, loss = 2.6282246112823486\n",
      "epoch 67, batch 110, loss = 2.608668565750122\n",
      "epoch 67, batch 120, loss = 2.593527317047119\n",
      "epoch 67, batch 130, loss = 2.6040494441986084\n",
      "epoch 67, batch 140, loss = 2.593186616897583\n",
      "epoch 67, batch 150, loss = 2.635683298110962\n",
      "epoch 67, batch 160, loss = 2.606779098510742\n",
      "epoch 67, batch 170, loss = 2.594660997390747\n",
      "epoch 67, batch 180, loss = 2.623922348022461\n",
      "epoch 67, batch 190, loss = 2.6758456230163574\n",
      "epoch 67, batch 200, loss = 2.6038942337036133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, batch 210, loss = 2.575788974761963\n",
      "epoch 67, batch 220, loss = 2.6002461910247803\n",
      "epoch 67, batch 230, loss = 2.612118721008301\n",
      "epoch 67, batch 240, loss = 2.639622688293457\n",
      "epoch 67, batch 250, loss = 2.6256051063537598\n",
      "epoch 67, batch 260, loss = 2.6217329502105713\n",
      "epoch 67, batch 270, loss = 2.616360664367676\n",
      "epoch 67, batch 280, loss = 2.6667351722717285\n",
      "epoch 68, batch 0, loss = 2.5559730529785156\n",
      "epoch 68, batch 10, loss = 2.575460433959961\n",
      "epoch 68, batch 20, loss = 2.5783238410949707\n",
      "epoch 68, batch 30, loss = 2.559950351715088\n",
      "epoch 68, batch 40, loss = 2.636035919189453\n",
      "epoch 68, batch 50, loss = 2.6266794204711914\n",
      "epoch 68, batch 60, loss = 2.596083641052246\n",
      "epoch 68, batch 70, loss = 2.577479839324951\n",
      "epoch 68, batch 80, loss = 2.5950422286987305\n",
      "epoch 68, batch 90, loss = 2.6158242225646973\n",
      "epoch 68, batch 100, loss = 2.616316795349121\n",
      "epoch 68, batch 110, loss = 2.596784830093384\n",
      "epoch 68, batch 120, loss = 2.5488505363464355\n",
      "epoch 68, batch 130, loss = 2.6234984397888184\n",
      "epoch 68, batch 140, loss = 2.638601303100586\n",
      "epoch 68, batch 150, loss = 2.57454252243042\n",
      "epoch 68, batch 160, loss = 2.5967516899108887\n",
      "epoch 68, batch 170, loss = 2.657808780670166\n",
      "epoch 68, batch 180, loss = 2.6036548614501953\n",
      "epoch 68, batch 190, loss = 2.6284589767456055\n",
      "epoch 68, batch 200, loss = 2.629397392272949\n",
      "epoch 68, batch 210, loss = 2.607009172439575\n",
      "epoch 68, batch 220, loss = 2.5688133239746094\n",
      "epoch 68, batch 230, loss = 2.6256871223449707\n",
      "epoch 68, batch 240, loss = 2.6219851970672607\n",
      "epoch 68, batch 250, loss = 2.6321091651916504\n",
      "epoch 68, batch 260, loss = 2.590549945831299\n",
      "epoch 68, batch 270, loss = 2.6018288135528564\n",
      "epoch 68, batch 280, loss = 2.6746182441711426\n",
      "epoch 69, batch 0, loss = 2.5861029624938965\n",
      "epoch 69, batch 10, loss = 2.58919620513916\n",
      "epoch 69, batch 20, loss = 2.5517921447753906\n",
      "epoch 69, batch 30, loss = 2.617032527923584\n",
      "epoch 69, batch 40, loss = 2.621615409851074\n",
      "epoch 69, batch 50, loss = 2.591475248336792\n",
      "epoch 69, batch 60, loss = 2.552931785583496\n",
      "epoch 69, batch 70, loss = 2.6104395389556885\n",
      "epoch 69, batch 80, loss = 2.59903883934021\n",
      "epoch 69, batch 90, loss = 2.5654220581054688\n",
      "epoch 69, batch 100, loss = 2.5730483531951904\n",
      "epoch 69, batch 110, loss = 2.614917755126953\n",
      "epoch 69, batch 120, loss = 2.6126718521118164\n",
      "epoch 69, batch 130, loss = 2.6290743350982666\n",
      "epoch 69, batch 140, loss = 2.6031839847564697\n",
      "epoch 69, batch 150, loss = 2.5600433349609375\n",
      "epoch 69, batch 160, loss = 2.5969085693359375\n",
      "epoch 69, batch 170, loss = 2.637667417526245\n",
      "epoch 69, batch 180, loss = 2.6495554447174072\n",
      "epoch 69, batch 190, loss = 2.613276958465576\n",
      "epoch 69, batch 200, loss = 2.5407979488372803\n",
      "epoch 69, batch 210, loss = 2.639072895050049\n",
      "epoch 69, batch 220, loss = 2.5980398654937744\n",
      "epoch 69, batch 230, loss = 2.594205379486084\n",
      "epoch 69, batch 240, loss = 2.677488327026367\n",
      "epoch 69, batch 250, loss = 2.6486732959747314\n",
      "epoch 69, batch 260, loss = 2.648000717163086\n",
      "epoch 69, batch 270, loss = 2.6005196571350098\n",
      "epoch 69, batch 280, loss = 2.59816312789917\n",
      "epoch 70, batch 0, loss = 2.5981485843658447\n",
      "epoch 70, batch 10, loss = 2.581127882003784\n",
      "epoch 70, batch 20, loss = 2.6262848377227783\n",
      "epoch 70, batch 30, loss = 2.5844616889953613\n",
      "epoch 70, batch 40, loss = 2.578958511352539\n",
      "epoch 70, batch 50, loss = 2.582657814025879\n",
      "epoch 70, batch 60, loss = 2.639949321746826\n",
      "epoch 70, batch 70, loss = 2.590015172958374\n",
      "epoch 70, batch 80, loss = 2.6198158264160156\n",
      "epoch 70, batch 90, loss = 2.619248628616333\n",
      "epoch 70, batch 100, loss = 2.6018495559692383\n",
      "epoch 70, batch 110, loss = 2.6392874717712402\n",
      "epoch 70, batch 120, loss = 2.594116687774658\n",
      "epoch 70, batch 130, loss = 2.5813088417053223\n",
      "epoch 70, batch 140, loss = 2.569939136505127\n",
      "epoch 70, batch 150, loss = 2.644857406616211\n",
      "epoch 70, batch 160, loss = 2.5851540565490723\n",
      "epoch 70, batch 170, loss = 2.5728800296783447\n",
      "epoch 70, batch 180, loss = 2.6069023609161377\n",
      "epoch 70, batch 190, loss = 2.6275486946105957\n",
      "epoch 70, batch 200, loss = 2.5558464527130127\n",
      "epoch 70, batch 210, loss = 2.638172149658203\n",
      "epoch 70, batch 220, loss = 2.6180150508880615\n",
      "epoch 70, batch 230, loss = 2.6051154136657715\n",
      "epoch 70, batch 240, loss = 2.621090888977051\n",
      "epoch 70, batch 250, loss = 2.647364616394043\n",
      "epoch 70, batch 260, loss = 2.687147617340088\n",
      "epoch 70, batch 270, loss = 2.632138252258301\n",
      "epoch 70, batch 280, loss = 2.5834732055664062\n",
      "epoch 71, batch 0, loss = 2.5931363105773926\n",
      "epoch 71, batch 10, loss = 2.579725980758667\n",
      "epoch 71, batch 20, loss = 2.6355342864990234\n",
      "epoch 71, batch 30, loss = 2.5809969902038574\n",
      "epoch 71, batch 40, loss = 2.627075672149658\n",
      "epoch 71, batch 50, loss = 2.5922188758850098\n",
      "epoch 71, batch 60, loss = 2.623746395111084\n",
      "epoch 71, batch 70, loss = 2.578122615814209\n",
      "epoch 71, batch 80, loss = 2.6011111736297607\n",
      "epoch 71, batch 90, loss = 2.6349687576293945\n",
      "epoch 71, batch 100, loss = 2.595801830291748\n",
      "epoch 71, batch 110, loss = 2.588289976119995\n",
      "epoch 71, batch 120, loss = 2.6038570404052734\n",
      "epoch 71, batch 130, loss = 2.5821850299835205\n",
      "epoch 71, batch 140, loss = 2.595381021499634\n",
      "epoch 71, batch 150, loss = 2.6318726539611816\n",
      "epoch 71, batch 160, loss = 2.6603827476501465\n",
      "epoch 71, batch 170, loss = 2.6436848640441895\n",
      "epoch 71, batch 180, loss = 2.6120684146881104\n",
      "epoch 71, batch 190, loss = 2.5948705673217773\n",
      "epoch 71, batch 200, loss = 2.637507915496826\n",
      "epoch 71, batch 210, loss = 2.6551504135131836\n",
      "epoch 71, batch 220, loss = 2.633042097091675\n",
      "epoch 71, batch 230, loss = 2.5888609886169434\n",
      "epoch 71, batch 240, loss = 2.6296725273132324\n",
      "epoch 71, batch 250, loss = 2.598010540008545\n",
      "epoch 71, batch 260, loss = 2.613065719604492\n",
      "epoch 71, batch 270, loss = 2.6358165740966797\n",
      "epoch 71, batch 280, loss = 2.661635160446167\n",
      "epoch 72, batch 0, loss = 2.5512001514434814\n",
      "epoch 72, batch 10, loss = 2.562150478363037\n",
      "epoch 72, batch 20, loss = 2.6090660095214844\n",
      "epoch 72, batch 30, loss = 2.622727870941162\n",
      "epoch 72, batch 40, loss = 2.565626859664917\n",
      "epoch 72, batch 50, loss = 2.5868215560913086\n",
      "epoch 72, batch 60, loss = 2.60739803314209\n",
      "epoch 72, batch 70, loss = 2.531442880630493\n",
      "epoch 72, batch 80, loss = 2.673790454864502\n",
      "epoch 72, batch 90, loss = 2.5689964294433594\n",
      "epoch 72, batch 100, loss = 2.576350212097168\n",
      "epoch 72, batch 110, loss = 2.5806641578674316\n",
      "epoch 72, batch 120, loss = 2.5712296962738037\n",
      "epoch 72, batch 130, loss = 2.629105806350708\n",
      "epoch 72, batch 140, loss = 2.6605160236358643\n",
      "epoch 72, batch 150, loss = 2.5963096618652344\n",
      "epoch 72, batch 160, loss = 2.658482551574707\n",
      "epoch 72, batch 170, loss = 2.6283950805664062\n",
      "epoch 72, batch 180, loss = 2.551476001739502\n",
      "epoch 72, batch 190, loss = 2.6159048080444336\n",
      "epoch 72, batch 200, loss = 2.650045394897461\n",
      "epoch 72, batch 210, loss = 2.6555471420288086\n",
      "epoch 72, batch 220, loss = 2.6181201934814453\n",
      "epoch 72, batch 230, loss = 2.637406587600708\n",
      "epoch 72, batch 240, loss = 2.6288442611694336\n",
      "epoch 72, batch 250, loss = 2.5765345096588135\n",
      "epoch 72, batch 260, loss = 2.622573137283325\n",
      "epoch 72, batch 270, loss = 2.587952136993408\n",
      "epoch 72, batch 280, loss = 2.642974376678467\n",
      "epoch 73, batch 0, loss = 2.5603153705596924\n",
      "epoch 73, batch 10, loss = 2.6298916339874268\n",
      "epoch 73, batch 20, loss = 2.591053009033203\n",
      "epoch 73, batch 30, loss = 2.5941970348358154\n",
      "epoch 73, batch 40, loss = 2.618603467941284\n",
      "epoch 73, batch 50, loss = 2.624441623687744\n",
      "epoch 73, batch 60, loss = 2.6076388359069824\n",
      "epoch 73, batch 70, loss = 2.607544422149658\n",
      "epoch 73, batch 80, loss = 2.588876962661743\n",
      "epoch 73, batch 90, loss = 2.6005825996398926\n",
      "epoch 73, batch 100, loss = 2.594844341278076\n",
      "epoch 73, batch 110, loss = 2.5909018516540527\n",
      "epoch 73, batch 120, loss = 2.61594557762146\n",
      "epoch 73, batch 130, loss = 2.6452817916870117\n",
      "epoch 73, batch 140, loss = 2.616591453552246\n",
      "epoch 73, batch 150, loss = 2.6026782989501953\n",
      "epoch 73, batch 160, loss = 2.57661771774292\n",
      "epoch 73, batch 170, loss = 2.6017203330993652\n",
      "epoch 73, batch 180, loss = 2.584285259246826\n",
      "epoch 73, batch 190, loss = 2.605346918106079\n",
      "epoch 73, batch 200, loss = 2.563368797302246\n",
      "epoch 73, batch 210, loss = 2.598116636276245\n",
      "epoch 73, batch 220, loss = 2.59729266166687\n",
      "epoch 73, batch 230, loss = 2.641113758087158\n",
      "epoch 73, batch 240, loss = 2.6079673767089844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, batch 250, loss = 2.6157541275024414\n",
      "epoch 73, batch 260, loss = 2.587563991546631\n",
      "epoch 73, batch 270, loss = 2.573687791824341\n",
      "epoch 73, batch 280, loss = 2.5896780490875244\n",
      "epoch 74, batch 0, loss = 2.6044416427612305\n",
      "epoch 74, batch 10, loss = 2.6132054328918457\n",
      "epoch 74, batch 20, loss = 2.571786880493164\n",
      "epoch 74, batch 30, loss = 2.55155086517334\n",
      "epoch 74, batch 40, loss = 2.6119771003723145\n",
      "epoch 74, batch 50, loss = 2.589992046356201\n",
      "epoch 74, batch 60, loss = 2.561224937438965\n",
      "epoch 74, batch 70, loss = 2.6103906631469727\n",
      "epoch 74, batch 80, loss = 2.6057443618774414\n",
      "epoch 74, batch 90, loss = 2.6300885677337646\n",
      "epoch 74, batch 100, loss = 2.5709755420684814\n",
      "epoch 74, batch 110, loss = 2.644111156463623\n",
      "epoch 74, batch 120, loss = 2.629045248031616\n",
      "epoch 74, batch 130, loss = 2.570223331451416\n",
      "epoch 74, batch 140, loss = 2.6039175987243652\n",
      "epoch 74, batch 150, loss = 2.579272747039795\n",
      "epoch 74, batch 160, loss = 2.572274923324585\n",
      "epoch 74, batch 170, loss = 2.5900115966796875\n",
      "epoch 74, batch 180, loss = 2.5827410221099854\n",
      "epoch 74, batch 190, loss = 2.66217303276062\n",
      "epoch 74, batch 200, loss = 2.6541004180908203\n",
      "epoch 74, batch 210, loss = 2.6295998096466064\n",
      "epoch 74, batch 220, loss = 2.6107027530670166\n",
      "epoch 74, batch 230, loss = 2.6304428577423096\n",
      "epoch 74, batch 240, loss = 2.6352386474609375\n",
      "epoch 74, batch 250, loss = 2.59267520904541\n",
      "epoch 74, batch 260, loss = 2.6542112827301025\n",
      "epoch 74, batch 270, loss = 2.6090455055236816\n",
      "epoch 74, batch 280, loss = 2.6394424438476562\n",
      "epoch 75, batch 0, loss = 2.625732898712158\n",
      "epoch 75, batch 10, loss = 2.5533409118652344\n",
      "epoch 75, batch 20, loss = 2.5260541439056396\n",
      "epoch 75, batch 30, loss = 2.579847812652588\n",
      "epoch 75, batch 40, loss = 2.6044864654541016\n",
      "epoch 75, batch 50, loss = 2.5587849617004395\n",
      "epoch 75, batch 60, loss = 2.611788511276245\n",
      "epoch 75, batch 70, loss = 2.6213560104370117\n",
      "epoch 75, batch 80, loss = 2.5902328491210938\n",
      "epoch 75, batch 90, loss = 2.6431331634521484\n",
      "epoch 75, batch 100, loss = 2.602362871170044\n",
      "epoch 75, batch 110, loss = 2.5790867805480957\n",
      "epoch 75, batch 120, loss = 2.572561502456665\n",
      "epoch 75, batch 130, loss = 2.593517780303955\n",
      "epoch 75, batch 140, loss = 2.6025748252868652\n",
      "epoch 75, batch 150, loss = 2.59544038772583\n",
      "epoch 75, batch 160, loss = 2.602513551712036\n",
      "epoch 75, batch 170, loss = 2.5620570182800293\n",
      "epoch 75, batch 180, loss = 2.6349148750305176\n",
      "epoch 75, batch 190, loss = 2.5848302841186523\n",
      "epoch 75, batch 200, loss = 2.616457462310791\n",
      "epoch 75, batch 210, loss = 2.666398525238037\n",
      "epoch 75, batch 220, loss = 2.6096670627593994\n",
      "epoch 75, batch 230, loss = 2.6090924739837646\n",
      "epoch 75, batch 240, loss = 2.5597329139709473\n",
      "epoch 75, batch 250, loss = 2.6034746170043945\n",
      "epoch 75, batch 260, loss = 2.6321301460266113\n",
      "epoch 75, batch 270, loss = 2.5991406440734863\n",
      "epoch 75, batch 280, loss = 2.5968291759490967\n",
      "epoch 76, batch 0, loss = 2.6133713722229004\n",
      "epoch 76, batch 10, loss = 2.606724500656128\n",
      "epoch 76, batch 20, loss = 2.549555778503418\n",
      "epoch 76, batch 30, loss = 2.600724697113037\n",
      "epoch 76, batch 40, loss = 2.584803342819214\n",
      "epoch 76, batch 50, loss = 2.5736608505249023\n",
      "epoch 76, batch 60, loss = 2.578315258026123\n",
      "epoch 76, batch 70, loss = 2.57413387298584\n",
      "epoch 76, batch 80, loss = 2.6215100288391113\n",
      "epoch 76, batch 90, loss = 2.6157236099243164\n",
      "epoch 76, batch 100, loss = 2.6050572395324707\n",
      "epoch 76, batch 110, loss = 2.608488082885742\n",
      "epoch 76, batch 120, loss = 2.6440775394439697\n",
      "epoch 76, batch 130, loss = 2.5876824855804443\n",
      "epoch 76, batch 140, loss = 2.5855636596679688\n",
      "epoch 76, batch 150, loss = 2.6412246227264404\n",
      "epoch 76, batch 160, loss = 2.616171360015869\n",
      "epoch 76, batch 170, loss = 2.539581298828125\n",
      "epoch 76, batch 180, loss = 2.6488640308380127\n",
      "epoch 76, batch 190, loss = 2.584444522857666\n",
      "epoch 76, batch 200, loss = 2.6381428241729736\n",
      "epoch 76, batch 210, loss = 2.5614218711853027\n",
      "epoch 76, batch 220, loss = 2.614995002746582\n",
      "epoch 76, batch 230, loss = 2.581416606903076\n",
      "epoch 76, batch 240, loss = 2.6051831245422363\n",
      "epoch 76, batch 250, loss = 2.622667074203491\n",
      "epoch 76, batch 260, loss = 2.579447031021118\n",
      "epoch 76, batch 270, loss = 2.6121370792388916\n",
      "epoch 76, batch 280, loss = 2.6742560863494873\n",
      "epoch 77, batch 0, loss = 2.5645909309387207\n",
      "epoch 77, batch 10, loss = 2.6155848503112793\n",
      "epoch 77, batch 20, loss = 2.5987908840179443\n",
      "epoch 77, batch 30, loss = 2.591818332672119\n",
      "epoch 77, batch 40, loss = 2.568570375442505\n",
      "epoch 77, batch 50, loss = 2.620987892150879\n",
      "epoch 77, batch 60, loss = 2.540557384490967\n",
      "epoch 77, batch 70, loss = 2.654613971710205\n",
      "epoch 77, batch 80, loss = 2.6221096515655518\n",
      "epoch 77, batch 90, loss = 2.639491081237793\n",
      "epoch 77, batch 100, loss = 2.597992420196533\n",
      "epoch 77, batch 110, loss = 2.6097044944763184\n",
      "epoch 77, batch 120, loss = 2.6012778282165527\n",
      "epoch 77, batch 130, loss = 2.5438194274902344\n",
      "epoch 77, batch 140, loss = 2.582841396331787\n",
      "epoch 77, batch 150, loss = 2.620089530944824\n",
      "epoch 77, batch 160, loss = 2.64646577835083\n",
      "epoch 77, batch 170, loss = 2.6054511070251465\n",
      "epoch 77, batch 180, loss = 2.598083019256592\n",
      "epoch 77, batch 190, loss = 2.6018764972686768\n",
      "epoch 77, batch 200, loss = 2.6531691551208496\n",
      "epoch 77, batch 210, loss = 2.6241211891174316\n",
      "epoch 77, batch 220, loss = 2.5676352977752686\n",
      "epoch 77, batch 230, loss = 2.582240104675293\n",
      "epoch 77, batch 240, loss = 2.581932306289673\n",
      "epoch 77, batch 250, loss = 2.590116500854492\n",
      "epoch 77, batch 260, loss = 2.6145997047424316\n",
      "epoch 77, batch 270, loss = 2.5803890228271484\n",
      "epoch 77, batch 280, loss = 2.60414981842041\n",
      "epoch 78, batch 0, loss = 2.597376823425293\n",
      "epoch 78, batch 10, loss = 2.586345672607422\n",
      "epoch 78, batch 20, loss = 2.5432395935058594\n",
      "epoch 78, batch 30, loss = 2.5551531314849854\n",
      "epoch 78, batch 40, loss = 2.6117687225341797\n",
      "epoch 78, batch 50, loss = 2.535789728164673\n",
      "epoch 78, batch 60, loss = 2.5845916271209717\n",
      "epoch 78, batch 70, loss = 2.5760180950164795\n",
      "epoch 78, batch 80, loss = 2.653381109237671\n",
      "epoch 78, batch 90, loss = 2.6525630950927734\n",
      "epoch 78, batch 100, loss = 2.6171905994415283\n",
      "epoch 78, batch 110, loss = 2.5558176040649414\n",
      "epoch 78, batch 120, loss = 2.620774269104004\n",
      "epoch 78, batch 130, loss = 2.6238179206848145\n",
      "epoch 78, batch 140, loss = 2.587282657623291\n",
      "epoch 78, batch 150, loss = 2.6180920600891113\n",
      "epoch 78, batch 160, loss = 2.595303535461426\n",
      "epoch 78, batch 170, loss = 2.597970962524414\n",
      "epoch 78, batch 180, loss = 2.6131420135498047\n",
      "epoch 78, batch 190, loss = 2.6098179817199707\n",
      "epoch 78, batch 200, loss = 2.650723934173584\n",
      "epoch 78, batch 210, loss = 2.621225357055664\n",
      "epoch 78, batch 220, loss = 2.5869953632354736\n",
      "epoch 78, batch 230, loss = 2.617302656173706\n",
      "epoch 78, batch 240, loss = 2.61003041267395\n",
      "epoch 78, batch 250, loss = 2.585026264190674\n",
      "epoch 78, batch 260, loss = 2.5711522102355957\n",
      "epoch 78, batch 270, loss = 2.639071226119995\n",
      "epoch 78, batch 280, loss = 2.6181278228759766\n",
      "epoch 79, batch 0, loss = 2.582580089569092\n",
      "epoch 79, batch 10, loss = 2.6374807357788086\n",
      "epoch 79, batch 20, loss = 2.566349983215332\n",
      "epoch 79, batch 30, loss = 2.5774946212768555\n",
      "epoch 79, batch 40, loss = 2.5797393321990967\n",
      "epoch 79, batch 50, loss = 2.5908749103546143\n",
      "epoch 79, batch 60, loss = 2.581016778945923\n",
      "epoch 79, batch 70, loss = 2.6302218437194824\n",
      "epoch 79, batch 80, loss = 2.6148948669433594\n",
      "epoch 79, batch 90, loss = 2.5858869552612305\n",
      "epoch 79, batch 100, loss = 2.581836700439453\n",
      "epoch 79, batch 110, loss = 2.607100009918213\n",
      "epoch 79, batch 120, loss = 2.5951335430145264\n",
      "epoch 79, batch 130, loss = 2.6236305236816406\n",
      "epoch 79, batch 140, loss = 2.5597004890441895\n",
      "epoch 79, batch 150, loss = 2.5761466026306152\n",
      "epoch 79, batch 160, loss = 2.600823402404785\n",
      "epoch 79, batch 170, loss = 2.61599063873291\n",
      "epoch 79, batch 180, loss = 2.5881426334381104\n",
      "epoch 79, batch 190, loss = 2.629162073135376\n",
      "epoch 79, batch 200, loss = 2.604976177215576\n",
      "epoch 79, batch 210, loss = 2.5814414024353027\n",
      "epoch 79, batch 220, loss = 2.563735008239746\n",
      "epoch 79, batch 230, loss = 2.6256113052368164\n",
      "epoch 79, batch 240, loss = 2.596006393432617\n",
      "epoch 79, batch 250, loss = 2.60164737701416\n",
      "epoch 79, batch 260, loss = 2.5974066257476807\n",
      "epoch 79, batch 270, loss = 2.5415425300598145\n",
      "epoch 79, batch 280, loss = 2.5933265686035156\n",
      "epoch 80, batch 0, loss = 2.498436689376831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, batch 10, loss = 2.5749611854553223\n",
      "epoch 80, batch 20, loss = 2.6170549392700195\n",
      "epoch 80, batch 30, loss = 2.621377468109131\n",
      "epoch 80, batch 40, loss = 2.5529112815856934\n",
      "epoch 80, batch 50, loss = 2.5889315605163574\n",
      "epoch 80, batch 60, loss = 2.5326218605041504\n",
      "epoch 80, batch 70, loss = 2.6035096645355225\n",
      "epoch 80, batch 80, loss = 2.6351656913757324\n",
      "epoch 80, batch 90, loss = 2.585247755050659\n",
      "epoch 80, batch 100, loss = 2.623727798461914\n",
      "epoch 80, batch 110, loss = 2.5746917724609375\n",
      "epoch 80, batch 120, loss = 2.5714943408966064\n",
      "epoch 80, batch 130, loss = 2.5375638008117676\n",
      "epoch 80, batch 140, loss = 2.624922752380371\n",
      "epoch 80, batch 150, loss = 2.63155460357666\n",
      "epoch 80, batch 160, loss = 2.5966367721557617\n",
      "epoch 80, batch 170, loss = 2.582953691482544\n",
      "epoch 80, batch 180, loss = 2.5720772743225098\n",
      "epoch 80, batch 190, loss = 2.6280834674835205\n",
      "epoch 80, batch 200, loss = 2.6077373027801514\n",
      "epoch 80, batch 210, loss = 2.5922603607177734\n",
      "epoch 80, batch 220, loss = 2.6343798637390137\n",
      "epoch 80, batch 230, loss = 2.581629753112793\n",
      "epoch 80, batch 240, loss = 2.6024270057678223\n",
      "epoch 80, batch 250, loss = 2.6244568824768066\n",
      "epoch 80, batch 260, loss = 2.630756139755249\n",
      "epoch 80, batch 270, loss = 2.608942747116089\n",
      "epoch 80, batch 280, loss = 2.609642505645752\n",
      "epoch 81, batch 0, loss = 2.5480446815490723\n",
      "epoch 81, batch 10, loss = 2.626434803009033\n",
      "epoch 81, batch 20, loss = 2.576657295227051\n",
      "epoch 81, batch 30, loss = 2.568849563598633\n",
      "epoch 81, batch 40, loss = 2.5924673080444336\n",
      "epoch 81, batch 50, loss = 2.576106548309326\n",
      "epoch 81, batch 60, loss = 2.5949172973632812\n",
      "epoch 81, batch 70, loss = 2.5867085456848145\n",
      "epoch 81, batch 80, loss = 2.6076979637145996\n",
      "epoch 81, batch 90, loss = 2.643120527267456\n",
      "epoch 81, batch 100, loss = 2.5478503704071045\n",
      "epoch 81, batch 110, loss = 2.5956430435180664\n",
      "epoch 81, batch 120, loss = 2.5825843811035156\n",
      "epoch 81, batch 130, loss = 2.6234805583953857\n",
      "epoch 81, batch 140, loss = 2.6476478576660156\n",
      "epoch 81, batch 150, loss = 2.649479389190674\n",
      "epoch 81, batch 160, loss = 2.6286697387695312\n",
      "epoch 81, batch 170, loss = 2.6017069816589355\n",
      "epoch 81, batch 180, loss = 2.534900665283203\n",
      "epoch 81, batch 190, loss = 2.571761131286621\n",
      "epoch 81, batch 200, loss = 2.6592254638671875\n",
      "epoch 81, batch 210, loss = 2.6178507804870605\n",
      "epoch 81, batch 220, loss = 2.6255831718444824\n",
      "epoch 81, batch 230, loss = 2.639981508255005\n",
      "epoch 81, batch 240, loss = 2.640655279159546\n",
      "epoch 81, batch 250, loss = 2.579059362411499\n",
      "epoch 81, batch 260, loss = 2.600682020187378\n",
      "epoch 81, batch 270, loss = 2.6197924613952637\n",
      "epoch 81, batch 280, loss = 2.6304428577423096\n",
      "epoch 82, batch 0, loss = 2.6222004890441895\n",
      "epoch 82, batch 10, loss = 2.6020660400390625\n",
      "epoch 82, batch 20, loss = 2.5736470222473145\n",
      "epoch 82, batch 30, loss = 2.5923495292663574\n",
      "epoch 82, batch 40, loss = 2.5907511711120605\n",
      "epoch 82, batch 50, loss = 2.5927839279174805\n",
      "epoch 82, batch 60, loss = 2.5846567153930664\n",
      "epoch 82, batch 70, loss = 2.564218044281006\n",
      "epoch 82, batch 80, loss = 2.5974302291870117\n",
      "epoch 82, batch 90, loss = 2.5740060806274414\n",
      "epoch 82, batch 100, loss = 2.5763258934020996\n",
      "epoch 82, batch 110, loss = 2.5702366828918457\n",
      "epoch 82, batch 120, loss = 2.6079659461975098\n",
      "epoch 82, batch 130, loss = 2.622790813446045\n",
      "epoch 82, batch 140, loss = 2.5877697467803955\n",
      "epoch 82, batch 150, loss = 2.5325634479522705\n",
      "epoch 82, batch 160, loss = 2.5556437969207764\n",
      "epoch 82, batch 170, loss = 2.5994019508361816\n",
      "epoch 82, batch 180, loss = 2.594895839691162\n",
      "epoch 82, batch 190, loss = 2.6352016925811768\n",
      "epoch 82, batch 200, loss = 2.6235814094543457\n",
      "epoch 82, batch 210, loss = 2.562723398208618\n",
      "epoch 82, batch 220, loss = 2.6324331760406494\n",
      "epoch 82, batch 230, loss = 2.6129150390625\n",
      "epoch 82, batch 240, loss = 2.5702009201049805\n",
      "epoch 82, batch 250, loss = 2.5762667655944824\n",
      "epoch 82, batch 260, loss = 2.623507499694824\n",
      "epoch 82, batch 270, loss = 2.5776641368865967\n",
      "epoch 82, batch 280, loss = 2.634347677230835\n",
      "epoch 83, batch 0, loss = 2.593463659286499\n",
      "epoch 83, batch 10, loss = 2.5744402408599854\n",
      "epoch 83, batch 20, loss = 2.5430092811584473\n",
      "epoch 83, batch 30, loss = 2.6443467140197754\n",
      "epoch 83, batch 40, loss = 2.569988250732422\n",
      "epoch 83, batch 50, loss = 2.5688743591308594\n",
      "epoch 83, batch 60, loss = 2.578592300415039\n",
      "epoch 83, batch 70, loss = 2.5552592277526855\n",
      "epoch 83, batch 80, loss = 2.5761890411376953\n",
      "epoch 83, batch 90, loss = 2.617288589477539\n",
      "epoch 83, batch 100, loss = 2.58486008644104\n",
      "epoch 83, batch 110, loss = 2.6499829292297363\n",
      "epoch 83, batch 120, loss = 2.569222927093506\n",
      "epoch 83, batch 130, loss = 2.665940523147583\n",
      "epoch 83, batch 140, loss = 2.5482144355773926\n",
      "epoch 83, batch 150, loss = 2.575925827026367\n",
      "epoch 83, batch 160, loss = 2.5967655181884766\n",
      "epoch 83, batch 170, loss = 2.580185890197754\n",
      "epoch 83, batch 180, loss = 2.581737518310547\n",
      "epoch 83, batch 190, loss = 2.613287925720215\n",
      "epoch 83, batch 200, loss = 2.5920143127441406\n",
      "epoch 83, batch 210, loss = 2.600998878479004\n",
      "epoch 83, batch 220, loss = 2.594353675842285\n",
      "epoch 83, batch 230, loss = 2.6258230209350586\n",
      "epoch 83, batch 240, loss = 2.6117234230041504\n",
      "epoch 83, batch 250, loss = 2.6172890663146973\n",
      "epoch 83, batch 260, loss = 2.642704486846924\n",
      "epoch 83, batch 270, loss = 2.6005594730377197\n",
      "epoch 83, batch 280, loss = 2.638721466064453\n",
      "epoch 84, batch 0, loss = 2.5761289596557617\n",
      "epoch 84, batch 10, loss = 2.558128833770752\n",
      "epoch 84, batch 20, loss = 2.612882614135742\n",
      "epoch 84, batch 30, loss = 2.563176393508911\n",
      "epoch 84, batch 40, loss = 2.558865785598755\n",
      "epoch 84, batch 50, loss = 2.6017775535583496\n",
      "epoch 84, batch 60, loss = 2.610933303833008\n",
      "epoch 84, batch 70, loss = 2.5432751178741455\n",
      "epoch 84, batch 80, loss = 2.5398576259613037\n",
      "epoch 84, batch 90, loss = 2.589362144470215\n",
      "epoch 84, batch 100, loss = 2.5975654125213623\n",
      "epoch 84, batch 110, loss = 2.5590732097625732\n",
      "epoch 84, batch 120, loss = 2.5671067237854004\n",
      "epoch 84, batch 130, loss = 2.5362696647644043\n",
      "epoch 84, batch 140, loss = 2.576169729232788\n",
      "epoch 84, batch 150, loss = 2.6755220890045166\n",
      "epoch 84, batch 160, loss = 2.6699705123901367\n",
      "epoch 84, batch 170, loss = 2.5681753158569336\n",
      "epoch 84, batch 180, loss = 2.5966415405273438\n",
      "epoch 84, batch 190, loss = 2.5726845264434814\n",
      "epoch 84, batch 200, loss = 2.622986078262329\n",
      "epoch 84, batch 210, loss = 2.6239371299743652\n",
      "epoch 84, batch 220, loss = 2.599632740020752\n",
      "epoch 84, batch 230, loss = 2.583199977874756\n",
      "epoch 84, batch 240, loss = 2.602236270904541\n",
      "epoch 84, batch 250, loss = 2.619668483734131\n",
      "epoch 84, batch 260, loss = 2.591799736022949\n",
      "epoch 84, batch 270, loss = 2.5875895023345947\n",
      "epoch 84, batch 280, loss = 2.587470531463623\n",
      "epoch 85, batch 0, loss = 2.577817678451538\n",
      "epoch 85, batch 10, loss = 2.5460805892944336\n",
      "epoch 85, batch 20, loss = 2.5684871673583984\n",
      "epoch 85, batch 30, loss = 2.615581512451172\n",
      "epoch 85, batch 40, loss = 2.5823419094085693\n",
      "epoch 85, batch 50, loss = 2.5725317001342773\n",
      "epoch 85, batch 60, loss = 2.6194467544555664\n",
      "epoch 85, batch 70, loss = 2.5157887935638428\n",
      "epoch 85, batch 80, loss = 2.606548309326172\n",
      "epoch 85, batch 90, loss = 2.5666744709014893\n",
      "epoch 85, batch 100, loss = 2.574472188949585\n",
      "epoch 85, batch 110, loss = 2.5394766330718994\n",
      "epoch 85, batch 120, loss = 2.605905055999756\n",
      "epoch 85, batch 130, loss = 2.5520339012145996\n",
      "epoch 85, batch 140, loss = 2.555511236190796\n",
      "epoch 85, batch 150, loss = 2.614107131958008\n",
      "epoch 85, batch 160, loss = 2.5663509368896484\n",
      "epoch 85, batch 170, loss = 2.604691505432129\n",
      "epoch 85, batch 180, loss = 2.5751330852508545\n",
      "epoch 85, batch 190, loss = 2.550570249557495\n",
      "epoch 85, batch 200, loss = 2.6016907691955566\n",
      "epoch 85, batch 210, loss = 2.588381767272949\n",
      "epoch 85, batch 220, loss = 2.5890564918518066\n",
      "epoch 85, batch 230, loss = 2.5716304779052734\n",
      "epoch 85, batch 240, loss = 2.650132417678833\n",
      "epoch 85, batch 250, loss = 2.645066738128662\n",
      "epoch 85, batch 260, loss = 2.578281879425049\n",
      "epoch 85, batch 270, loss = 2.6167731285095215\n",
      "epoch 85, batch 280, loss = 2.6380133628845215\n",
      "epoch 86, batch 0, loss = 2.524569511413574\n",
      "epoch 86, batch 10, loss = 2.5470495223999023\n",
      "epoch 86, batch 20, loss = 2.5717883110046387\n",
      "epoch 86, batch 30, loss = 2.561995506286621\n",
      "epoch 86, batch 40, loss = 2.587852954864502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86, batch 50, loss = 2.631929874420166\n",
      "epoch 86, batch 60, loss = 2.5798871517181396\n",
      "epoch 86, batch 70, loss = 2.5635030269622803\n",
      "epoch 86, batch 80, loss = 2.6253600120544434\n",
      "epoch 86, batch 90, loss = 2.607145071029663\n",
      "epoch 86, batch 100, loss = 2.6044228076934814\n",
      "epoch 86, batch 110, loss = 2.5859761238098145\n",
      "epoch 86, batch 120, loss = 2.5702085494995117\n",
      "epoch 86, batch 130, loss = 2.5926764011383057\n",
      "epoch 86, batch 140, loss = 2.5595946311950684\n",
      "epoch 86, batch 150, loss = 2.5743308067321777\n",
      "epoch 86, batch 160, loss = 2.6143975257873535\n",
      "epoch 86, batch 170, loss = 2.5412049293518066\n",
      "epoch 86, batch 180, loss = 2.605106830596924\n",
      "epoch 86, batch 190, loss = 2.617239236831665\n",
      "epoch 86, batch 200, loss = 2.5923125743865967\n",
      "epoch 86, batch 210, loss = 2.6229655742645264\n",
      "epoch 86, batch 220, loss = 2.549927234649658\n",
      "epoch 86, batch 230, loss = 2.6535186767578125\n",
      "epoch 86, batch 240, loss = 2.5878348350524902\n",
      "epoch 86, batch 250, loss = 2.627774715423584\n",
      "epoch 86, batch 260, loss = 2.6038990020751953\n",
      "epoch 86, batch 270, loss = 2.5751357078552246\n",
      "epoch 86, batch 280, loss = 2.6109161376953125\n",
      "epoch 87, batch 0, loss = 2.6054348945617676\n",
      "epoch 87, batch 10, loss = 2.568391799926758\n",
      "epoch 87, batch 20, loss = 2.5891995429992676\n",
      "epoch 87, batch 30, loss = 2.5475077629089355\n",
      "epoch 87, batch 40, loss = 2.594005584716797\n",
      "epoch 87, batch 50, loss = 2.56662917137146\n",
      "epoch 87, batch 60, loss = 2.5809507369995117\n",
      "epoch 87, batch 70, loss = 2.628274440765381\n",
      "epoch 87, batch 80, loss = 2.5866541862487793\n",
      "epoch 87, batch 90, loss = 2.628146171569824\n",
      "epoch 87, batch 100, loss = 2.5969536304473877\n",
      "epoch 87, batch 110, loss = 2.571606159210205\n",
      "epoch 87, batch 120, loss = 2.588752031326294\n",
      "epoch 87, batch 130, loss = 2.6068954467773438\n",
      "epoch 87, batch 140, loss = 2.6178367137908936\n",
      "epoch 87, batch 150, loss = 2.613166093826294\n",
      "epoch 87, batch 160, loss = 2.5425689220428467\n",
      "epoch 87, batch 170, loss = 2.6028666496276855\n",
      "epoch 87, batch 180, loss = 2.6241512298583984\n",
      "epoch 87, batch 190, loss = 2.5826292037963867\n",
      "epoch 87, batch 200, loss = 2.599836826324463\n",
      "epoch 87, batch 210, loss = 2.582380533218384\n",
      "epoch 87, batch 220, loss = 2.585334300994873\n",
      "epoch 87, batch 230, loss = 2.653276205062866\n",
      "epoch 87, batch 240, loss = 2.623582363128662\n",
      "epoch 87, batch 250, loss = 2.614649772644043\n",
      "epoch 87, batch 260, loss = 2.6204867362976074\n",
      "epoch 87, batch 270, loss = 2.648460626602173\n",
      "epoch 87, batch 280, loss = 2.6032919883728027\n",
      "epoch 88, batch 0, loss = 2.5673511028289795\n",
      "epoch 88, batch 10, loss = 2.5674023628234863\n",
      "epoch 88, batch 20, loss = 2.5453996658325195\n",
      "epoch 88, batch 30, loss = 2.5696539878845215\n",
      "epoch 88, batch 40, loss = 2.5861191749572754\n",
      "epoch 88, batch 50, loss = 2.6144113540649414\n",
      "epoch 88, batch 60, loss = 2.5882511138916016\n",
      "epoch 88, batch 70, loss = 2.542325019836426\n",
      "epoch 88, batch 80, loss = 2.5513827800750732\n",
      "epoch 88, batch 90, loss = 2.622215509414673\n",
      "epoch 88, batch 100, loss = 2.5882091522216797\n",
      "epoch 88, batch 110, loss = 2.5744094848632812\n",
      "epoch 88, batch 120, loss = 2.607377529144287\n",
      "epoch 88, batch 130, loss = 2.5428152084350586\n",
      "epoch 88, batch 140, loss = 2.5181033611297607\n",
      "epoch 88, batch 150, loss = 2.5943846702575684\n",
      "epoch 88, batch 160, loss = 2.56528377532959\n",
      "epoch 88, batch 170, loss = 2.599435329437256\n",
      "epoch 88, batch 180, loss = 2.6125648021698\n",
      "epoch 88, batch 190, loss = 2.5733449459075928\n",
      "epoch 88, batch 200, loss = 2.5966691970825195\n",
      "epoch 88, batch 210, loss = 2.5683212280273438\n",
      "epoch 88, batch 220, loss = 2.6378583908081055\n",
      "epoch 88, batch 230, loss = 2.5919699668884277\n",
      "epoch 88, batch 240, loss = 2.654209613800049\n",
      "epoch 88, batch 250, loss = 2.6220555305480957\n",
      "epoch 88, batch 260, loss = 2.615241527557373\n",
      "epoch 88, batch 270, loss = 2.63354229927063\n",
      "epoch 88, batch 280, loss = 2.6238155364990234\n",
      "epoch 89, batch 0, loss = 2.5659594535827637\n",
      "epoch 89, batch 10, loss = 2.5624473094940186\n",
      "epoch 89, batch 20, loss = 2.588939666748047\n",
      "epoch 89, batch 30, loss = 2.6050782203674316\n",
      "epoch 89, batch 40, loss = 2.591367244720459\n",
      "epoch 89, batch 50, loss = 2.5636284351348877\n",
      "epoch 89, batch 60, loss = 2.538224220275879\n",
      "epoch 89, batch 70, loss = 2.592975378036499\n",
      "epoch 89, batch 80, loss = 2.5287117958068848\n",
      "epoch 89, batch 90, loss = 2.623701572418213\n",
      "epoch 89, batch 100, loss = 2.557140350341797\n",
      "epoch 89, batch 110, loss = 2.5639877319335938\n",
      "epoch 89, batch 120, loss = 2.6598002910614014\n",
      "epoch 89, batch 130, loss = 2.614251136779785\n",
      "epoch 89, batch 140, loss = 2.653926372528076\n",
      "epoch 89, batch 150, loss = 2.5845131874084473\n",
      "epoch 89, batch 160, loss = 2.604904890060425\n",
      "epoch 89, batch 170, loss = 2.565819501876831\n",
      "epoch 89, batch 180, loss = 2.6307387351989746\n",
      "epoch 89, batch 190, loss = 2.641066551208496\n",
      "epoch 89, batch 200, loss = 2.577385902404785\n",
      "epoch 89, batch 210, loss = 2.5815300941467285\n",
      "epoch 89, batch 220, loss = 2.646087646484375\n",
      "epoch 89, batch 230, loss = 2.578890800476074\n",
      "epoch 89, batch 240, loss = 2.5791587829589844\n",
      "epoch 89, batch 250, loss = 2.6307055950164795\n",
      "epoch 89, batch 260, loss = 2.616673469543457\n",
      "epoch 89, batch 270, loss = 2.5370664596557617\n",
      "epoch 89, batch 280, loss = 2.5864949226379395\n",
      "epoch 90, batch 0, loss = 2.566913604736328\n",
      "epoch 90, batch 10, loss = 2.5734591484069824\n",
      "epoch 90, batch 20, loss = 2.5462327003479004\n",
      "epoch 90, batch 30, loss = 2.53615665435791\n",
      "epoch 90, batch 40, loss = 2.5132522583007812\n",
      "epoch 90, batch 50, loss = 2.52531099319458\n",
      "epoch 90, batch 60, loss = 2.5876152515411377\n",
      "epoch 90, batch 70, loss = 2.6272478103637695\n",
      "epoch 90, batch 80, loss = 2.5567004680633545\n",
      "epoch 90, batch 90, loss = 2.6192541122436523\n",
      "epoch 90, batch 100, loss = 2.553009033203125\n",
      "epoch 90, batch 110, loss = 2.584526538848877\n",
      "epoch 90, batch 120, loss = 2.516068458557129\n",
      "epoch 90, batch 130, loss = 2.6235013008117676\n",
      "epoch 90, batch 140, loss = 2.6419730186462402\n",
      "epoch 90, batch 150, loss = 2.6451449394226074\n",
      "epoch 90, batch 160, loss = 2.546271324157715\n",
      "epoch 90, batch 170, loss = 2.6080164909362793\n",
      "epoch 90, batch 180, loss = 2.6283669471740723\n",
      "epoch 90, batch 190, loss = 2.515671968460083\n",
      "epoch 90, batch 200, loss = 2.58121657371521\n",
      "epoch 90, batch 210, loss = 2.6202030181884766\n",
      "epoch 90, batch 220, loss = 2.5889737606048584\n",
      "epoch 90, batch 230, loss = 2.6578636169433594\n",
      "epoch 90, batch 240, loss = 2.574903964996338\n",
      "epoch 90, batch 250, loss = 2.588348388671875\n",
      "epoch 90, batch 260, loss = 2.5792675018310547\n",
      "epoch 90, batch 270, loss = 2.587292194366455\n",
      "epoch 90, batch 280, loss = 2.6294021606445312\n",
      "epoch 91, batch 0, loss = 2.5720953941345215\n",
      "epoch 91, batch 10, loss = 2.6078310012817383\n",
      "epoch 91, batch 20, loss = 2.498321056365967\n",
      "epoch 91, batch 30, loss = 2.6260826587677\n",
      "epoch 91, batch 40, loss = 2.597855806350708\n",
      "epoch 91, batch 50, loss = 2.6262826919555664\n",
      "epoch 91, batch 60, loss = 2.5956945419311523\n",
      "epoch 91, batch 70, loss = 2.577863931655884\n",
      "epoch 91, batch 80, loss = 2.535198450088501\n",
      "epoch 91, batch 90, loss = 2.618168354034424\n",
      "epoch 91, batch 100, loss = 2.570549726486206\n",
      "epoch 91, batch 110, loss = 2.5660295486450195\n",
      "epoch 91, batch 120, loss = 2.5468978881835938\n",
      "epoch 91, batch 130, loss = 2.637712240219116\n",
      "epoch 91, batch 140, loss = 2.537383556365967\n",
      "epoch 91, batch 150, loss = 2.5751233100891113\n",
      "epoch 91, batch 160, loss = 2.5589191913604736\n",
      "epoch 91, batch 170, loss = 2.5729713439941406\n",
      "epoch 91, batch 180, loss = 2.5781006813049316\n",
      "epoch 91, batch 190, loss = 2.5910468101501465\n",
      "epoch 91, batch 200, loss = 2.548581123352051\n",
      "epoch 91, batch 210, loss = 2.5726163387298584\n",
      "epoch 91, batch 220, loss = 2.5742874145507812\n",
      "epoch 91, batch 230, loss = 2.565613269805908\n",
      "epoch 91, batch 240, loss = 2.597538471221924\n",
      "epoch 91, batch 250, loss = 2.611215591430664\n",
      "epoch 91, batch 260, loss = 2.579556941986084\n",
      "epoch 91, batch 270, loss = 2.602565288543701\n",
      "epoch 91, batch 280, loss = 2.5852928161621094\n",
      "epoch 92, batch 0, loss = 2.577075719833374\n",
      "epoch 92, batch 10, loss = 2.5102181434631348\n",
      "epoch 92, batch 20, loss = 2.5908379554748535\n",
      "epoch 92, batch 30, loss = 2.563171625137329\n",
      "epoch 92, batch 40, loss = 2.5424981117248535\n",
      "epoch 92, batch 50, loss = 2.5465283393859863\n",
      "epoch 92, batch 60, loss = 2.5656919479370117\n",
      "epoch 92, batch 70, loss = 2.541743755340576\n",
      "epoch 92, batch 80, loss = 2.614763021469116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, batch 90, loss = 2.5927858352661133\n",
      "epoch 92, batch 100, loss = 2.634700298309326\n",
      "epoch 92, batch 110, loss = 2.545477867126465\n",
      "epoch 92, batch 120, loss = 2.6214194297790527\n",
      "epoch 92, batch 130, loss = 2.6324872970581055\n",
      "epoch 92, batch 140, loss = 2.597238063812256\n",
      "epoch 92, batch 150, loss = 2.6407155990600586\n",
      "epoch 92, batch 160, loss = 2.607081413269043\n",
      "epoch 92, batch 170, loss = 2.635141372680664\n",
      "epoch 92, batch 180, loss = 2.6108622550964355\n",
      "epoch 92, batch 190, loss = 2.609954357147217\n",
      "epoch 92, batch 200, loss = 2.6074795722961426\n",
      "epoch 92, batch 210, loss = 2.6018331050872803\n",
      "epoch 92, batch 220, loss = 2.61002779006958\n",
      "epoch 92, batch 230, loss = 2.6008191108703613\n",
      "epoch 92, batch 240, loss = 2.5727522373199463\n",
      "epoch 92, batch 250, loss = 2.5842831134796143\n",
      "epoch 92, batch 260, loss = 2.5560665130615234\n",
      "epoch 92, batch 270, loss = 2.574601650238037\n",
      "epoch 92, batch 280, loss = 2.564213275909424\n",
      "epoch 93, batch 0, loss = 2.5671896934509277\n",
      "epoch 93, batch 10, loss = 2.583495616912842\n",
      "epoch 93, batch 20, loss = 2.558566093444824\n",
      "epoch 93, batch 30, loss = 2.5554184913635254\n",
      "epoch 93, batch 40, loss = 2.586268424987793\n",
      "epoch 93, batch 50, loss = 2.6265692710876465\n",
      "epoch 93, batch 60, loss = 2.5488533973693848\n",
      "epoch 93, batch 70, loss = 2.656893730163574\n",
      "epoch 93, batch 80, loss = 2.568098545074463\n",
      "epoch 93, batch 90, loss = 2.6465771198272705\n",
      "epoch 93, batch 100, loss = 2.5598044395446777\n",
      "epoch 93, batch 110, loss = 2.520833969116211\n",
      "epoch 93, batch 120, loss = 2.6570873260498047\n",
      "epoch 93, batch 130, loss = 2.6239922046661377\n",
      "epoch 93, batch 140, loss = 2.6013240814208984\n",
      "epoch 93, batch 150, loss = 2.592961311340332\n",
      "epoch 93, batch 160, loss = 2.6322109699249268\n",
      "epoch 93, batch 170, loss = 2.5781562328338623\n",
      "epoch 93, batch 180, loss = 2.5862536430358887\n",
      "epoch 93, batch 190, loss = 2.5904078483581543\n",
      "epoch 93, batch 200, loss = 2.6449596881866455\n",
      "epoch 93, batch 210, loss = 2.6045217514038086\n",
      "epoch 93, batch 220, loss = 2.5781755447387695\n",
      "epoch 93, batch 230, loss = 2.6267781257629395\n",
      "epoch 93, batch 240, loss = 2.6058051586151123\n",
      "epoch 93, batch 250, loss = 2.5789613723754883\n",
      "epoch 93, batch 260, loss = 2.580791711807251\n",
      "epoch 93, batch 270, loss = 2.559098720550537\n",
      "epoch 93, batch 280, loss = 2.573377847671509\n",
      "epoch 94, batch 0, loss = 2.6048402786254883\n",
      "epoch 94, batch 10, loss = 2.5328595638275146\n",
      "epoch 94, batch 20, loss = 2.5911548137664795\n",
      "epoch 94, batch 30, loss = 2.5036137104034424\n",
      "epoch 94, batch 40, loss = 2.5291554927825928\n",
      "epoch 94, batch 50, loss = 2.586965799331665\n",
      "epoch 94, batch 60, loss = 2.5870237350463867\n",
      "epoch 94, batch 70, loss = 2.552063465118408\n",
      "epoch 94, batch 80, loss = 2.589005470275879\n",
      "epoch 94, batch 90, loss = 2.5871493816375732\n",
      "epoch 94, batch 100, loss = 2.5955491065979004\n",
      "epoch 94, batch 110, loss = 2.616626739501953\n",
      "epoch 94, batch 120, loss = 2.572558641433716\n",
      "epoch 94, batch 130, loss = 2.5819225311279297\n",
      "epoch 94, batch 140, loss = 2.6199183464050293\n",
      "epoch 94, batch 150, loss = 2.595170497894287\n",
      "epoch 94, batch 160, loss = 2.5863471031188965\n",
      "epoch 94, batch 170, loss = 2.600461959838867\n",
      "epoch 94, batch 180, loss = 2.5441884994506836\n",
      "epoch 94, batch 190, loss = 2.64001202583313\n",
      "epoch 94, batch 200, loss = 2.6522884368896484\n",
      "epoch 94, batch 210, loss = 2.6008553504943848\n",
      "epoch 94, batch 220, loss = 2.555020570755005\n",
      "epoch 94, batch 230, loss = 2.5951619148254395\n",
      "epoch 94, batch 240, loss = 2.632418632507324\n",
      "epoch 94, batch 250, loss = 2.5841894149780273\n",
      "epoch 94, batch 260, loss = 2.599569797515869\n",
      "epoch 94, batch 270, loss = 2.554157257080078\n",
      "epoch 94, batch 280, loss = 2.6407575607299805\n",
      "epoch 95, batch 0, loss = 2.5681910514831543\n",
      "epoch 95, batch 10, loss = 2.569453716278076\n",
      "epoch 95, batch 20, loss = 2.5310072898864746\n",
      "epoch 95, batch 30, loss = 2.547123432159424\n",
      "epoch 95, batch 40, loss = 2.5495309829711914\n",
      "epoch 95, batch 50, loss = 2.546919822692871\n",
      "epoch 95, batch 60, loss = 2.587257146835327\n",
      "epoch 95, batch 70, loss = 2.609516143798828\n",
      "epoch 95, batch 80, loss = 2.5407521724700928\n",
      "epoch 95, batch 90, loss = 2.582473039627075\n",
      "epoch 95, batch 100, loss = 2.5981357097625732\n",
      "epoch 95, batch 110, loss = 2.5911307334899902\n",
      "epoch 95, batch 120, loss = 2.6594185829162598\n",
      "epoch 95, batch 130, loss = 2.553882598876953\n",
      "epoch 95, batch 140, loss = 2.56168270111084\n",
      "epoch 95, batch 150, loss = 2.565901279449463\n",
      "epoch 95, batch 160, loss = 2.5754427909851074\n",
      "epoch 95, batch 170, loss = 2.543269634246826\n",
      "epoch 95, batch 180, loss = 2.5753934383392334\n",
      "epoch 95, batch 190, loss = 2.621816635131836\n",
      "epoch 95, batch 200, loss = 2.5511467456817627\n",
      "epoch 95, batch 210, loss = 2.591818332672119\n",
      "epoch 95, batch 220, loss = 2.600640296936035\n",
      "epoch 95, batch 230, loss = 2.6150405406951904\n",
      "epoch 95, batch 240, loss = 2.578472137451172\n",
      "epoch 95, batch 250, loss = 2.603184700012207\n",
      "epoch 95, batch 260, loss = 2.6249802112579346\n",
      "epoch 95, batch 270, loss = 2.6198573112487793\n",
      "epoch 95, batch 280, loss = 2.6049692630767822\n",
      "epoch 96, batch 0, loss = 2.5242714881896973\n",
      "epoch 96, batch 10, loss = 2.5190720558166504\n",
      "epoch 96, batch 20, loss = 2.537684440612793\n",
      "epoch 96, batch 30, loss = 2.5705723762512207\n",
      "epoch 96, batch 40, loss = 2.567790985107422\n",
      "epoch 96, batch 50, loss = 2.5900654792785645\n",
      "epoch 96, batch 60, loss = 2.6258788108825684\n",
      "epoch 96, batch 70, loss = 2.5881295204162598\n",
      "epoch 96, batch 80, loss = 2.5588865280151367\n",
      "epoch 96, batch 90, loss = 2.5814764499664307\n",
      "epoch 96, batch 100, loss = 2.5636849403381348\n",
      "epoch 96, batch 110, loss = 2.612210273742676\n",
      "epoch 96, batch 120, loss = 2.5968050956726074\n",
      "epoch 96, batch 130, loss = 2.5643787384033203\n",
      "epoch 96, batch 140, loss = 2.556811809539795\n",
      "epoch 96, batch 150, loss = 2.58388090133667\n",
      "epoch 96, batch 160, loss = 2.5507395267486572\n",
      "epoch 96, batch 170, loss = 2.567073345184326\n",
      "epoch 96, batch 180, loss = 2.5845377445220947\n",
      "epoch 96, batch 190, loss = 2.551530361175537\n",
      "epoch 96, batch 200, loss = 2.591559648513794\n",
      "epoch 96, batch 210, loss = 2.589435577392578\n",
      "epoch 96, batch 220, loss = 2.5599653720855713\n",
      "epoch 96, batch 230, loss = 2.5404868125915527\n",
      "epoch 96, batch 240, loss = 2.5796518325805664\n",
      "epoch 96, batch 250, loss = 2.6458020210266113\n",
      "epoch 96, batch 260, loss = 2.6065850257873535\n",
      "epoch 96, batch 270, loss = 2.62545108795166\n",
      "epoch 96, batch 280, loss = 2.629049301147461\n",
      "epoch 97, batch 0, loss = 2.5960776805877686\n",
      "epoch 97, batch 10, loss = 2.573610305786133\n",
      "epoch 97, batch 20, loss = 2.5580601692199707\n",
      "epoch 97, batch 30, loss = 2.5956075191497803\n",
      "epoch 97, batch 40, loss = 2.573014974594116\n",
      "epoch 97, batch 50, loss = 2.581315040588379\n",
      "epoch 97, batch 60, loss = 2.544650077819824\n",
      "epoch 97, batch 70, loss = 2.606870174407959\n",
      "epoch 97, batch 80, loss = 2.5618975162506104\n",
      "epoch 97, batch 90, loss = 2.610396385192871\n",
      "epoch 97, batch 100, loss = 2.5911526679992676\n",
      "epoch 97, batch 110, loss = 2.558574676513672\n",
      "epoch 97, batch 120, loss = 2.6391425132751465\n",
      "epoch 97, batch 130, loss = 2.5996885299682617\n",
      "epoch 97, batch 140, loss = 2.559659242630005\n",
      "epoch 97, batch 150, loss = 2.588836669921875\n",
      "epoch 97, batch 160, loss = 2.5499463081359863\n",
      "epoch 97, batch 170, loss = 2.568635940551758\n",
      "epoch 97, batch 180, loss = 2.6230483055114746\n",
      "epoch 97, batch 190, loss = 2.584805965423584\n",
      "epoch 97, batch 200, loss = 2.559074878692627\n",
      "epoch 97, batch 210, loss = 2.5744199752807617\n",
      "epoch 97, batch 220, loss = 2.601978302001953\n",
      "epoch 97, batch 230, loss = 2.6228437423706055\n",
      "epoch 97, batch 240, loss = 2.5631585121154785\n",
      "epoch 97, batch 250, loss = 2.5597925186157227\n",
      "epoch 97, batch 260, loss = 2.6296653747558594\n",
      "epoch 97, batch 270, loss = 2.660762310028076\n",
      "epoch 97, batch 280, loss = 2.628385305404663\n",
      "epoch 98, batch 0, loss = 2.571367025375366\n",
      "epoch 98, batch 10, loss = 2.523087739944458\n",
      "epoch 98, batch 20, loss = 2.599135160446167\n",
      "epoch 98, batch 30, loss = 2.5490450859069824\n",
      "epoch 98, batch 40, loss = 2.602092742919922\n",
      "epoch 98, batch 50, loss = 2.6285126209259033\n",
      "epoch 98, batch 60, loss = 2.5607199668884277\n",
      "epoch 98, batch 70, loss = 2.5735325813293457\n",
      "epoch 98, batch 80, loss = 2.5592801570892334\n",
      "epoch 98, batch 90, loss = 2.5923256874084473\n",
      "epoch 98, batch 100, loss = 2.5968732833862305\n",
      "epoch 98, batch 110, loss = 2.604207992553711\n",
      "epoch 98, batch 120, loss = 2.5609207153320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98, batch 130, loss = 2.5812244415283203\n",
      "epoch 98, batch 140, loss = 2.6138205528259277\n",
      "epoch 98, batch 150, loss = 2.6346042156219482\n",
      "epoch 98, batch 160, loss = 2.5827860832214355\n",
      "epoch 98, batch 170, loss = 2.6426639556884766\n",
      "epoch 98, batch 180, loss = 2.5460586547851562\n",
      "epoch 98, batch 190, loss = 2.5762939453125\n",
      "epoch 98, batch 200, loss = 2.592587947845459\n",
      "epoch 98, batch 210, loss = 2.5769104957580566\n",
      "epoch 98, batch 220, loss = 2.588428020477295\n",
      "epoch 98, batch 230, loss = 2.588514566421509\n",
      "epoch 98, batch 240, loss = 2.569443464279175\n",
      "epoch 98, batch 250, loss = 2.6090621948242188\n",
      "epoch 98, batch 260, loss = 2.6080105304718018\n",
      "epoch 98, batch 270, loss = 2.6114678382873535\n",
      "epoch 98, batch 280, loss = 2.5581717491149902\n",
      "epoch 99, batch 0, loss = 2.533545970916748\n",
      "epoch 99, batch 10, loss = 2.5092971324920654\n",
      "epoch 99, batch 20, loss = 2.562070369720459\n",
      "epoch 99, batch 30, loss = 2.5905275344848633\n",
      "epoch 99, batch 40, loss = 2.575561285018921\n",
      "epoch 99, batch 50, loss = 2.539111375808716\n",
      "epoch 99, batch 60, loss = 2.539125919342041\n",
      "epoch 99, batch 70, loss = 2.540433168411255\n",
      "epoch 99, batch 80, loss = 2.6282436847686768\n",
      "epoch 99, batch 90, loss = 2.559023857116699\n",
      "epoch 99, batch 100, loss = 2.553739547729492\n",
      "epoch 99, batch 110, loss = 2.550516128540039\n",
      "epoch 99, batch 120, loss = 2.531148672103882\n",
      "epoch 99, batch 130, loss = 2.6166458129882812\n",
      "epoch 99, batch 140, loss = 2.5860047340393066\n",
      "epoch 99, batch 150, loss = 2.6628684997558594\n",
      "epoch 99, batch 160, loss = 2.5859992504119873\n",
      "epoch 99, batch 170, loss = 2.5260937213897705\n",
      "epoch 99, batch 180, loss = 2.5893826484680176\n",
      "epoch 99, batch 190, loss = 2.6097571849823\n",
      "epoch 99, batch 200, loss = 2.6202011108398438\n",
      "epoch 99, batch 210, loss = 2.6487693786621094\n",
      "epoch 99, batch 220, loss = 2.6224634647369385\n",
      "epoch 99, batch 230, loss = 2.5575177669525146\n",
      "epoch 99, batch 240, loss = 2.5892257690429688\n",
      "epoch 99, batch 250, loss = 2.5694661140441895\n",
      "epoch 99, batch 260, loss = 2.5638253688812256\n",
      "epoch 99, batch 270, loss = 2.558544635772705\n",
      "epoch 99, batch 280, loss = 2.597092390060425\n",
      "1790.2773835659027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ad1e2cb250>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt4ElEQVR4nO3dd3hUZdr48e9NCqG3BERaRJrISougIIiICOLKWpe1u676qq8/dVEXu4K+a9nFvipiX3XtirJSlK4ChhJ6E1CaEAihlyTcvz/mzGRmciaZhEk5w/25rlycOeeZM/fJhHueec5TRFUxxhjjfdUqOwBjjDGxYQndGGPihCV0Y4yJE5bQjTEmTlhCN8aYOGEJ3Rhj4kTUCV1EEkRkgYh87XKsuoh8KCJrRGSOiKTHNEpjjDElKk0N/XZgeYRj1wM7VbUN8Azw5NEGZowxpnSiSugi0hwYAoyNUGQo8Laz/QlwtojI0YdnjDEmWolRlnsWuAeoE+F4M2ADgKrmi8guoBGwPdIJU1NTNT09PepAjTHGwLx587araprbsRITuoicD2xT1Xki0u9oAhGRG4EbAVq2bElmZubRnM4YY445IvJLpGPRNLn0Bi4QkfXAf4D+IvLvsDKbgBbOiyUC9YAd4SdS1TGqmqGqGWlprh8wxhhjyqjEhK6q96pqc1VNB4YBU1T1yrBi44BrnO1LnDI265cxxlSgaNvQixCRkUCmqo4DXgfeFZE1QA6+xG+MMaYClSqhq+o0YJqz/VDQ/oPApbEMzBhjTOnYSFFjjIkTltCNMSZOWEI3xpg44bmEvmrrHkZPWsn2vYcqOxRjjKlSPJfQV2/dy/NT1pCz73Blh2KMMVWK5xK6n/VyN8aYUJ5L6P4pvxTL6MYYE8x7Cb2yAzDGmCrKcwndz5pcjDEmlOcSeqDJxRK6McaE8FxCt0YXY4xx58GE7mM3RY0xJpTnErotbGeMMe48l9D9rA3dGGNCeS6hWwXdGGPceS+hW5uLMca48lxC97MmF2OMCeW5hO6vn1svF2OMCVViQheRFBGZKyJZIrJURB51KdNSRKaKyAIRWSQi55VPuNbLxRhjIommhn4I6K+qnYEuwCAROS2szAPAR6raFd8C0f+KaZQurMnFGGNClbhItKoqsNd5mOT8hKdTBeo62/WAzbEKMJzV0I0xxl1UbegikiAiC4FtwGRVnRNW5BHgShHZCPwXuC2WQbqxCroxxoSKKqGraoGqdgGaAz1EpFNYkT8Bb6lqc+A84F0RKXJuEblRRDJFJDM7O7tMAYtzW1StzcUYY0KUqpeLquYCU4FBYYeuBz5yyvwIpACpLs8fo6oZqpqRlpZWpoBtZJExxriLppdLmojUd7ZrAOcAK8KK/Qqc7ZQ5CV9CL1sVPEpWPzfGmFAl3hQFmgJvi0gCvg+Aj1T1axEZCWSq6jhgOPCaiNyJL9deq+XUJhLoh24Z3RhjQkTTy2UR0NVl/0NB28uA3rENzZ0N/TfGGHeeGylayKroxhgTzHMJ3ernxhjjznMJ3c/a0I0xJpTnEnpgkejKDcMYY6oc7yV0a3QxxhhXnkvoftbkYowxoTyX0ANNLpbRjTEmhPcSemUHYIwxVZTnErqf1c+NMSaU9xK6VdGNMcaV9xK6w5rQjTEmlOcSemA+dGt0McaYEN5L6NbkYowxrjyX0AOsgm6MMSE8l9AD86FXahTGGFP1eC+hW5uLMca48lxC97NeLsYYE8pzCd0q6MYY4y6aRaJTRGSuiGSJyFIReTRCuctEZJlT5v3YhxrKui0aY0yoaBaJPgT0V9W9IpIEzBKRb1R1tr+AiLQF7gV6q+pOEWlcTvHaQFFjjIkgmkWiFdjrPExyfsKrxzcAL6nqTuc522IZpHtc5f0KxhjjLVG1oYtIgogsBLYBk1V1TliRdkA7EfleRGaLyKAYxxkUS3md2RhjvC2qhK6qBaraBWgO9BCRTmFFEoG2QD/gT8BrIlI//DwicqOIZIpIZnZ29tHEbS3oxhgTplS9XFQ1F5gKhNfANwLjVDVPVdcBq/Al+PDnj1HVDFXNSEtLK2PI4j9XGZ9vjDHxKZpeLmn+2raI1ADOAVaEFfsCX+0cEUnF1wSzNoZxBsVTHmc1xhjvi6aXS1PgbRFJwPcB8JGqfi0iI4FMVR0HTAQGisgyoAC4W1V3lFvUWJOLMcaEi6aXyyKgq8v+h4K2Ffir81OurIJujDHuPDdSNMCq6MYYE8JzCd0m5zLGGHeeS+h+NvTfGGNCeS6hW/3cGGPceS6h+1k3dGOMCeW5hG5N6MYY485zCd3PaujGGBPKcwldrBXdGGNceS6h+1kF3RhjQnkuoVsbujHGuPNcQvez2RaNMSaUZxO6McaYUJ5N6FY/N8aYUJ5L6P42dGtxMcaYUN5L6NZt0RhjXHkuoReyKroxxgTzXEK3bovGGOPOcwndz9rQjTEmVDSLRKeIyFwRyRKRpSLyaDFlLxYRFZGM2IYZ/BrldWZjjPG2aBaJPgT0V9W9IpIEzBKRb1R1dnAhEakD3A7MKYc4i7AKujHGhCqxhq4+e52HSc6PWz4dBTwJHIxdeEVZLxdjjHEXVRu6iCSIyEJgGzBZVeeEHe8GtFDV8bEP0Z21oRtjTKioErqqFqhqF6A50ENEOvmPiUg1YDQwvKTziMiNIpIpIpnZ2dllCtja0I0xxl2permoai4wFRgUtLsO0AmYJiLrgdOAcW43RlV1jKpmqGpGWlpamYMGWyTaGGPCRdPLJU1E6jvbNYBzgBX+46q6S1VTVTVdVdOB2cAFqppZHgFbBd0YY9xFU0NvCkwVkUXAT/ja0L8WkZEickH5hheZtaEbY0yoErstquoioKvL/ocilO939GFFZm3oxhjjzrsjRSs7AGOMqWI8mNCtim6MMW48mNB9bAk6Y4wJ5bmEbm3oxhjjznsJvbIDMMaYKspzCd3PWlyMMSaU5xK6WJuLMca48lxC97Oh/8YYE8pzCd3q58YY485zCd3P2tCNMSaU5xK6NaEbY4w7zyV0P6uhG2NMKM8ldFuCzhhj3HkuoftZBd0YY0J5LqH729Bz9x+u3ECMMaaK8VxCz9nnS+SPjV9eyZEYY0zV4rmEfrjgSGWHYIwxVZLnErr1bjHGGHfRLBKdIiJzRSRLRJaKyKMuZf4qIstEZJGIfCcirconXDhiGd0YY1xFU0M/BPRX1c5AF2CQiJwWVmYBkKGqpwCfAE/FNMogGa0aANCnbWp5vYQxxnhSiQldffY6D5OcHw0rM1VV9zsPZwPNYxplkMSEatSpnkibxrXL6yWMMcaTompDF5EEEVkIbAMmq+qcYopfD3wTg9gi2nMon13788rzJYwxxnOiSuiqWqCqXfDVvHuISCe3ciJyJZABPB3h+I0ikikimdnZ2WUM2eezBZuO6vnGGBNvStXLRVVzganAoPBjIjIAuB+4QFUPRXj+GFXNUNWMtLS0MoRrjDEmkmh6uaSJSH1nuwZwDrAirExX4FV8yXxbOcRpjDGmBIlRlGkKvC0iCfg+AD5S1a9FZCSQqarj8DWx1AY+dpaI+1VVLyivoI0xxhRVYkJX1UVAV5f9DwVtD4hxXMYYY0rJcyNFjTHGuPN0Qj9wuKCyQzDGmCrD0wn96YkrKzsEY4ypMjyd0Dfu3F9yIWOMOUZ4OqFPWra1skMwxpgqw9MJ3RhjTCFL6MYYEycsoRtjTJywhG6MMXHCEroxxsQJS+jGGBMnLKEbY0ycsIRujDFxwhK6McbECU8m9Msyym0NamOM8SxPJvTLe7aq7BCMMabK8WRCV9XAdl7BkUqMxBhjqg5PJvRgOfsOV3YIxhhTJUSzSHSKiMwVkSwRWSoij7qUqS4iH4rIGhGZIyLp5RKto3Vq7cC2JXRjjPGJpoZ+COivqp2BLsAgETktrMz1wE5VbQM8AzwZ0yjD1KuZFNge/NzM8nwpY4zxjBITuvrsdR4mOT8aVmwo8Laz/QlwtohIzKI0xhhToqja0EUkQUQWAtuAyao6J6xIM2ADgKrmA7uARjGMs1jLt+yuqJcyxpgqK6qErqoFqtoFaA70EJFOZXkxEblRRDJFJDM7O7ssp3BlzS7GGFPKXi6qmgtMBQaFHdoEtAAQkUSgHrDD5fljVDVDVTPS0tLKFLAxxhh30fRySROR+s52DeAcYEVYsXHANc72JcAUDe4sbowxptwlRlGmKfC2iCTg+wD4SFW/FpGRQKaqjgNeB94VkTVADjCs3CI2xhjjqsSErqqLgK4u+x8K2j4IXBrb0Mpu1/48bn5vHv+8rDNN69Wo7HCMMaZCeH6kqN9LU9cEtj9bsJEfft7Bq9PXVmJExhhTseImoT89cSUFR6zZ3hhz7PJsQh/yu6ZF9vkn6rLbscaYY5FnE3rH4+sW2dfhwQns2p9XCdEYY0zl82xCv6FPa9f9nUdOKjIvgTHGHAs8m9CTEyOH/v6cXwA4lG9zpRtjjh2eTejF+Tl7HwAfzP21kiMxxpiKE5cJPdjQF2dVdgjGGFMh4j6hZ23cxfItu9l1wG6WGmPiW9wndPDNxnjeczNZ+dsexs5ci6qyOfcANt2MMSaeRDOXS1zYlHuAc5+dAUCDmskM/ziLB8/vyPVnnFDJkRljTGx4uoZ+Rc+WZXreO7N9vWBGfb0M8K1LuvtgXmDbau7GGC/ydEKvWyOp5EIusjbkhjzuNmoyGY99y4ac/XQbNZlXZ7jPAaOqvPvjenYfzGP3wTybasAYU6V4OqG3aljzqM/hX77ucP4R1mzzLZ06YclvrmXn/7qTB79cyt8+WcQpj0xiyPO2UpIxpurwdEK/uHvzoz5H8PJ11731EwALN+SybPNufs7eG1L2YJ5voNLW3QcBWPHbHjblHjjqGIwxJhY8ndCTEsov/POen8nZ/5zO4+OXke9M+jVlxTYAgltaPvxpQ7nFYIwxpeHphA7wypXdy/X8r81cR5v7v2HkV8t4fdY6AI4E3TR9/rvV7D2UX64xGGNMNDyf0Ad1Oq5CXueN79cFtsNvhu4/7EvoW3YdYMfeQ4Cvm+TnCzZyKL+gQuIrD6rKXz9ayLxfdlZ2KMaYKESzSHQLEZkqIstEZKmI3O5Spp6IfCUiWU6Z68on3Kph6ebdIY8f+HwJM1Zlc/rfp9D9sW9ZvmU3vZ+Ywp0fZvF/45eTV3CE0ZNXse9QPjn7DnPNG3MDib8q23Ugj8/mb+K6N+dWdiiVYs/BPE56cAIzVmVXdijGRCWaGno+MFxVOwKnAbeKSMewMrcCy1S1M9AP+KeIJMc00mI8N6xLRb2Uq0nLtnL1G4VJL/hG69s//sLnCzbx/HerOfnhiXQbNZnpq7K5//MlfL5gI4dLMSPkzNXZDH3p+0Cb/tH6Zcc+63NfjJW/7eFAXgHPfbe6skMxJiolJnRV3aKq853tPcByoFl4MaCOiAhQG8jB90FQIYZ2acYDQ06qqJcrtYVh/d4BJiz9jTs/zKLdA9+QvecQSzbtYuzMtbzz43rSR4wPmXvmjVnr2JCzn7s/XkTWhlyyY1C7X7JpF2c+PY2xM9dFLCPIUb9OPLAPPeMVpRr6LyLpQFdgTtihF4FxwGagDvBHVa3QycjTG9WqyJcrlffnFD+N7xVjZ7Nqa2gXyc6PTuKNazPo1rIBI79exls/rKeak18X/ppL09/VoOCIsvtAHg1qlf7L0Mad+wH4aX0ON/R1XyzkWCfO77sy0vnstTvYue8wg12WWjQmkqhviopIbeBT4A5V3R12+FxgIXA80AV4UUSKrBEnIjeKSKaIZGZnx7ZdMqGad2uT4cnc789vZQa6Sv6asx9xMszN780H4Mqxc+g6ajLpI8ZzMK90N1/95youWekxv/ZT5f1NDRszO/A+GxOtqBK6iCThS+bvqepnLkWuAz5TnzXAOqBDeCFVHaOqGaqakZaWdjRxF1G/ZtmmAajq/vpRVmA7eBDTtj0H+XHtjsDjX3P2M/TFWaSPGM+fnQFS4WauzmatM1jKn6qKa07wv54/+R+rrMXFeEU0vVwEeB1YrqqjIxT7FTjbKd8EaA+4T4hSTrq2bFCRL1fprhob2vNk4DMzyNq4C/ANgPrHxJX8smMfM1Zls2bbXg7lF3DV63Pp/8/pQGGS/nb5tohzxQ95PrrFQWav3cG+OOyLX5lNLsaURTRt6L2Bq4DFIrLQ2Xcf0BJAVV8BRgFvichifJW/v6nq9tiHW7xrTm/FV4u2kLPvcEW/dIVbuXVPscdfnLqGF6euiXh80cbcwPblr83mlSu70yKKuXHyC45wRAvXdN26+yDDxsxm0MnH8cpV0Q/ymrN2Bw1rJdO2SZ0Syz41YQWvTP+ZtX8fEvX5Y+HY/l5ivKjEhK6qsyjhb1tVNwMDYxVUWT06tBMP//5kuj02mdz9tkJRJCt/28MLUwqT/dLNu+nz1FTWPzGEDTn7ydqYy/mnHO/63HOemcG67ftY/4QvuU512vi/Xb414uttzj3A8fVrBB5n7znEH8fMBgicx03WhlymrNjGv6b9HP3FlQcPtLnkFxxhf14BdVPis+nRRMfzI0XDVasmPHXxKZUdRpU2eZn7bJILN+TS56mp/O/7C4q0refuP8x/F29h3fZ9Ifs/zPTNZZPvjJ4d+uIsBoyezrxfcgCYtXo7vZ6YwldZmwPPOfXxbwPb+QVHXEfTnv737xj60vcx6wM+Lmsz6SPGs+dg9B/00dw4rirucWYANce2uEvoAOd0bMLjF3aq7DCqrFenu9/e+MNL3we2P52/KbC960AeXUZO5pagXhfpI8azfe8h9h4sbDv/cuEmsjbuYs22vVz88o/8sGY7V77u6+EaafqAi17+gfYPTAAIGTC1ZdfBMlxZZP9ymp827ox+dkwvNbl8tmBTyYXKgary5IQVgZvtpnLF5RJ0IsIVPVtxQmotTkitxZ6D+SzdvIs7P8wq+cnHgD1R3MC86+OSf1f3fraY1dsK/yPf/p+FIccvH1s4XOGtH9ZzSffmgTnn/RY5N3IHPTuDFb/t4Z5B7WlcJyXia970biYTl251barJLzjCWz+sZ94vO2lSN4VHLjg5cMz/hSO4w86RI0rugTwaltCP3wMtLhVq98E8aicnUq2asHHnAV6e9jPfLN7CtLvPquzQjnlxmdD9ep2YCkDTetCuSR0u7Nqc0ZNW8vyUyDcLTfQmL4vcbu7m/Bci95pZ8ZvvJu9TE1YWe46JSwtf82BeAUdUqZmcyIac/Qz/KIu563MCx0MSutNwMnVFNi0b1mTuuhwy1+/kxalreOFPXRnyu6ZUCxvLUNjLpTCjZ23IZcaqbH7J2c+1vdLp1KxeCVcN/5q2hpemrOHFK7pxVvvGJZaP1rrt+1iyaRe/7+x+v6M87D6YxymPTOKmM1tz7+DC0dl5BfapVxXEdUJ3c2v/NpbQ40SHB31NNX/MaBFoyw+mqoXt4E6+eXLCCp6csCKk3G0fLGDJ5l0hCQpgp3NjPS+/MFkNDWqW+mHNdn649+wS4/R/SN3y7/ksHzWoxPLRGjB6OgVHNCShB19zuE/nbSStTnX6tiv7GJBdzu/k66wtRX5fpvLFZRt6caonJlR2CKaMgm+mpo8YH9h2S+bga7d/9KulpI8YT0EJ7SavTl/LB3MLp2h49KulXONMuBapi6iIMHXlNrL3FM6ts2PvoaOeMnnNtsLX+8/cXyNOxlbaNW2Hf5wVMomcm7yCI2zI2R/1OQPfYqxdqohNuQfIi9FEetE65hJ6uPN+VzHzqZujF5w4o7HnUD5vfr8egLXZ+4ovjO+egKqycef+wPP8Mtfn8OXC0BuPm3IPcN2bPzFszI+AL6l1f+xbhjldMgFedulyOWftDn7bdZBhY37kpnczWbJpF1t2HWDoi7N4ZfrP3Pf5kkDZEZ8tDpmLv7w99OUS+jw1NVATL4mXegJVpF0H8uj9xBQe+nJphb7uMdfkEiz4xlqvv3/H5hj3rDCV67o33adAKM75L8wqMt89wCWv/BjxOT9n7yN3/2G6jJwMwIJfc/nv4i20TqsV0rxzKL8g5JuF38SlW6kmvqUNszbuosNxoYOtXpm+lvwjSmrt6qBw2aktQo4Hn7PgiDL844Xc2Lc1Jx9f2L5/JKg2n73nEGl1qrN++z4a1U6mTlDf9RmrfOMB9xzKo57LdBr+Gvmm3AMM/yiL/h189wTcKuirtu6hTVrtIvcm3OTsO0zOvsO0aVy7xLJu/NNQ+we8VRRV5d3Zv3Bh12Yhv0d/99jpK33jND5fsJEeJzSiWdB4jPJwzNbQh5wSOovdtLvPYv6D5zD97n6BfR/ccFoFR2Uqm1syj4Y/mfvd8t78kG6gELoWbbjgY/4bxH45+w7z1ISV3PPJIu75dBHPfrsqYrPOLzn7+XLhZm4Nm9hr9ORVgW1/01W/f0zjsldnh5TzJ+wjQS0F3y3fGmiGCW6f/3T+Rm59330CsXm/5DDwmRk8P8V9HEFewRFu+2ABq53mrIHPTGfA6On8d/EW1/LhDuYV8PmCjYGmno4PTaDdA99E9dxY+nHtDh76cikPh9XEC3tVCYfzj3Dnh1lcVkylIFaOyYS++vHBvDCsa8i+5MRqNKyVTKugaXhPP7ERE+7ow5JHz6VmsrW9m9I5mFc+7afPfruajzM3uh7zJ7jwG6OfR+invnxL6AeYv5/+Oz+uD8zjf/3bmfR5airZew5F7Jv/2+6DIYPOLn75x0Csc9flMM2pqQLsO5RP1oZcvsrazPCPs5ixKpvte33TddwS9kF063vzA2v5BvvHxJXc+WEW01b6Zm3Nj+J+wt5D+a73I857bmbIojSlcch5j3P2h043EtxN1t9LatseXwvAxKW/ldvcR8dkQk9KqBbV10CADsfVpXb1RC7u1rzIsal39YtxZMZE50gJNyH9f92fztvID2u2F6nRBzfTpI8YT+7+w7wUNPfP2FnrinzD8N8riOQL50Nj7rqckP2Xvfoj1zrNX7/u2M/JD08M3GcQ4IWwWvxXWZu597PFAIxfvIVRXy9j9todzFiVHViQfatzP6U08zZ1enii65TEy7bsLvLBVlqqvnEQF7w4ix17DwWSuEjhQjGqsOK33dz07jzu+3zxUb1eJMd0G3pp3D/kJN6d/Uvg8emtG3FCatVdVMPEt0g32waMngHA2u37ePP7dTz61bKozhfeZOQ3dmbhqOKfs/fR64kpEc/x3Heri52qYcaq7EAvm0CNWqTI6N3bPlgAwN8v+l1gX/CN5sl39g1MJTH84yyGdnHvh79z32EGPzeTHic05OlLfdOB+MdOzFydTc3kBLq3ahhS3m2xGFXl/bm/MrRLM2pX96XMfYfyOfnhibRrUtjmf+rj37Jzfx7dH/uWaU5lr5pIyGC2Pc7I6tKMWC4NS+hRSkkKbXJ54XJfk83ykYO465MsDucfoXVqLbbtORTx660xFSnaZF6cx8Yvj0EkPm5dJoXII3EjjVYOXzYxuLnk3dm/8OAXS1gxahBdR/k+pMZlbaZ2Smiqu+p1XyzBHSPyjygbcvZz3vMzA4kX4LWrM7j/8yXc//mSQPlcZ8pp/+I0P2fvDYxbAN/9Cf/1BZ//UqcdvbymlbCEXgZ92qb6ehwANZITeOnybiHHU2sn89rMdZzSvB4/b9vLvsMF1KmeGNWQe2OOJW7r7fp9Ms/9PkH4uIPg6Sce/MLX5XPU16EfZvOD5hLq7yRbCJ1j6NlvV/Gey3KRN7yTGdh+98f1POjy7ShSjXv9jv2uyftQKRaHL41jsg29JKe1bsjLV3SLePzFyyMfC3b+KU2Zclc/6lRP5N2/9Azsf+riUxh7dQbzHzwnsO+1qzPKHrAxJkR4Yg7uObQ25ObtDxGf48YtmZfEbSzC9hgs9O7Gaugu/nPj6a77Z997NkkJQr0a0c05rQpN6qaw+NFzQ0bShfcjBmgfxUIPxhjv+WdQl1G/WM8m6mc19FI4rl4KjZymluK4zaUhIqwYNYi1/3ee63NaNqrJ05cUncf939f35OcIzzHGmGCW0MvBn3q0pEHNJM4PmwUvJSmh2O6S/kmT3vlzj8C+M9qmklBN6NyiPgCvXBldc48x5thTYpOLiLQA3gGa4JuyYYyqPudSrh/wLJAEbFfVM2MZqJeckFqLBQ+VfkW+JnVTAnfR+3doHOhzC/Dlrb0D23ef256nJ66kS4v6LNyQS8emdWlYK5lZa3zDtuumJLL7YOgN2Jv7ncikpb/xcxRzmhhjvCmaGno+MFxVOwKnAbeKSMfgAiJSH/gXcIGqngxcGutAjzVvXHsqH93k3pZ/Wmtf39leJzYCoHpSNVKSCt/KW89qU+Q5yQnV+G54v5B9Z7X3fSMY2LEJM+85y27MGuNxJSZ0Vd2iqvOd7T3AcqBZWLHLgc9U9Ven3DZMVIIHJkSre6uGLH5kIGef1KTIsTFXdeeCoIEW/6+/L7mHN+t/fdsZtHVuxHZv1YAWDWtyTscmdGxaN6TcW9edWur4jDGVo1Rt6CKSDnQF5oQdagc0EJFpIjJPRK6OUXxx74tbe/PT/QNK/bw6KUnUq+FrMWvbuDbBQxWa1qvB+ieGsP6JIZzlzIZ3ZtiiBp2a1eOkpr6EHjzDXZ+2qYHthQ+dQ7/2jVkxahDnnlz0w8MYU7VEndBFpDbwKXCHqoZPfJAIdAeGAOcCD4pIO5dz3CgimSKSmZ2dfRRhx4+ayYmk1Sm554ybNo3r8N5fejJyaOGC2OGD7rq2bMD6J4bQtWUDADq3qE/XlvUB+EOXZky6s29ITd///Iu6NaN+Td8w6JSkBF69KqPcpyZ96uJTnA8nY0xZRPU/VESS8CXz91T1M5ciG4GJqrpPVbcDM4DO4YVUdYyqZqhqRlpa2ZfBMoV6t0klJSmhSJNKJF/e2pvPb/HdYBUR2oX1f6/mnOik4+oWee6kO/oW2fe3QR0C2zPuPot3/tyDG/qcAEDzBr65ny/pHjqx2bQIk5pddmoLJv/1mL2XbsxRKzGhi69T9evAclUdHaHYl8AZIpIoIjWBnvja2k0FO9qVwG4960SuOq0VV57Wqsix9NRa/HT/AKbf3Y9vbu/DlOFncnO/EwPHWzaqSd92adRw5r0Z2NG3GtRlGS34brgvUf90/wDSU2sxZfiZHFc3JTBIq4vTLRPg+xH9I8Y39a5+zL2/5HU8jTkWRTNStDdwFbBYRBY6++4DWgKo6iuqulxEJgCLgCPAWFVd4nYyUz4KK+hHl9HrpCQx6g+dIh73NQ8VbSI6Nb1BYPuWs9qQmFCNm/udyEO/L+wQFTwRUuu02sy+72xy9x9m1prtnH9K4Y3c4FVdbuvfhheCFvWOZobLtDrVS1yu7qJuzfhsvm8StdvPblvsLIHGeEWJCV1VZxHF5GCq+jTwdCyCMqUXbZNLeVg28lySEgq/7KUkJfD/zm4b1XPr10wOSeZ+IwZ34IsFmxg+sD3DB7YvsnDxA0NO4sDhgsCw6hWjBnHNG3OZsy6HG/qcQO7+PNbv2Md/F/8GwLW90unTNpXr3/ZNtDT6si5c0bMlLRrUJPdAniV0ExdspGic8PdUiWZqglirmZwYktBj4X/OPJEJQW32LRrWpEXDmoHHf+nTmtvObstF3Zox4KQmpCQlBO4HpCQlcM+gDqQ3Cq3Nh3fz7N6qIY3rphSprfRtV/T+zurHB9O5eb0i+8MtemQgdarbFEmmclhCjxN3DmjH+3/pyanpDUsuHEdGX9aFsdf4BkT5Fyzu5vTouX1A28CCy9WK+QrTpnFtbu53Ig8MOYmRQ0/mnT/3YPEjAwP3Bz69+XSSEqrRs3WjwHP8N34BbuzbGoCOTetSNyWJxY+eW+Q1nhvW5Siu0pjoWEKPE4kJ1ejVJrXkgnHsrA6NWfP4YDo189WkqycmcIszaraZ0+Pm7T/34N7BHUKeJyL8bVAH/tKnNVefng747iXcNbA9H//P6SGr2vjdP6QjX9zam45N6wb6+Efq1tm8QQ2GdmlG1kMDefSCk13L/L6z+6o7vuuI/X/TlkHfdo5GQpRLOZqKYQndxJXEsKaf35/SlLFXZ3Bdr3TAN8DqpjNPdHlmUQnVJOQbj4Z1IerSoj7/vb0PXVrUp1GtZO4+t33g2Ge39OL9G3oy7a5+jP9/fQCoVzOJa5w4AI6rm8I9g3zPOb5+Cjed2do1jkl39o34QeD3t0EdmHnPWVFdF0DvNo1c9/t7IxWnddCN6WuDrsdUPkvoJq6JCAM6Nol6UfDi+PN5cOIGqFU9kXkPnkPvoG9I3Vo2oNeJqaSn1ioyf76/Jj/utt5c0r05HY6rwzWnp3Pv4JP45vY+RV63VaNaXNMrnayHB9I6zZdMT01vEJJM2zWpTYuGNXn1qu6Bfa0j9Ahq3qBGSPfW7q0akPXwQP59fU9OTHMf2LXokcLJ5ibd2Zcf7+1Pau1krujZ0rV8cI+mo/WHCGuGepnbovOxYAndmCgd73Sn9A+YKquf7h9A5gMDaFwnhcZ1UphwR9/AuU9qWnRAl1+9Gkk0b+BrKrnlrDaBEcaptZMDN3zPPfk41jw+mB9G9A/p2+/36AUnMzVsYNd953WgXo0kzmjr3mTXp20qdVMKP5QSE6rRtF4NMh84h9ZBHwD92kceLDhq6MlMGX4mI4cW/00DYPRlhWMSMx8YwLPDuhaZeqJmckL40zyjZcOaPH5h5K7BR8MSujFRurZXOq9dncEFxbR3R6NejaTAmrTFubR7c165snvIvqZ1UwCoUz0x0FX1ku6hK2AlJlTj+Po1GPWHTjzzx87849LODDu1BfMeGMA1vdJDeiR1alY3cBPZL7jp5nfN6vHCn7oGHl/XO71InOufGMLa/zsv5NsBhHalrZ6UQOu02lzZs3DAWp2ghZszHyicz+iioNqr//f06lWhM4GO+9/eIY8/uOG0InEdVzcF/xez3m0aFVn7101Sgvs3uayHC7+h/DGj6IpjpXFW+7Qii87HivWvMiZK1aoJ53SsuEnKnr60yOwZPHxBR3q1aURGekPmrs8BQCMMJqtVPZELu/qSY/j0C35X9GxVZIWtFg1rcv0ZJ/D6rHVc0Pn4wJw+xTWjVKsmyJHQ86z7+xD2H85n7Mx1XNS1WaCc3/jb+tD36akART7gvri1NwVHihskF/payYlCh+PqhKwd+uZ1p5K1IZcnJ6zg39f3RES49X3fscf+0Iktuw7QpnFt7vwwK/Ccf1/fkz+OmV3k1YKbzZ50VhZrUCuZ12etJa+gMM5Tmtdj0cZdxcTtvqJZrFhCN6aKmXvf2RGH8tVMTmRoF19y9DepZLj0wilJ7zap/OenDUWmS/br2y6N12eto1urBq7HixN8u6JmcmLEQWYtG0XuaePWXPSvK7ohwIINuZyYFnp/oGZyIp/d0ou9h/IZM30tY2eto32TOpzUtC7DehRt5w+e2mL11r38a9rP9GufRs/Wjch6eCA/rNlO47rVmb4yO9CcdW2v9MDvw5/URwzuQPqI8YFzXd6jJYs2Li7yem0b12b1tr1A+fYMsoRuTBXT2GlWKUmvE1OZ98CAMg0m+33n4+nbLi3igudntktjxahBZWoaKK7Pf7iPbjo96kXXz/tdUwAGO//6vXxFt8C9h5rJidw/5CTuO+8k1xvhE+/oW+Qbzd3ntic9tVbg/PVqJAVeI7jL6iMl9DQ6rm5K4MzN6tfg8Qs7ce2bP5GcUI1Pbu7FfZ8vZvyiLYG5jsqDJXRjPOxoRgaXlEhLm8z9ibI0Cb3HCWUfCHdRt2Z8u2xrkQQvIhGnwmh/XJ0i+0SEy46iXXzhQ+eQs+8wqXWqM37RFsB3I7lf+8bMue9sqidWo16NJJ65rAutU2txS7+iK4rFiiV0Y0xM+LtCRpPPz3AZBHdJ9+almi109GVdoi9cjurXTA7cZwjXJOjbVnJiNYYPbO9aLlYsoRtjYsKfjGuVMJfNmscHu9bi/+FyE9hrft/5eCYt/Y3bB0Q3OV2sWUI3xsREjeQERgzuwACXtW6DhY/mjSe1qyfy5nU9Ku31LaEbY2Lmf6KcVsGUj/j9qDTGmGOMJXRjjIkTltCNMSZORLNIdAsRmSoiy0RkqYjcXkzZU0UkX0QuiW2YxhhjShLNTdF8YLiqzheROsA8EZmsqsuCC4lIAvAkMKkc4jTGGFOCEmvoqrpFVec723uA5UAzl6K3AZ8C22IaoTHGmKiUqg1dRNKBrsCcsP3NgAuBl2MWmTHGmFKJOqGLSG18NfA7VHV32OFngb+p6pESznGjiGSKSGZ2dnapgzXGGBOZhK+T6FpIJAn4GpioqqNdjq+jcMLPVGA/cKOqflHMObOBX8oQs/81tpfxuVWZXZe32HV5RzxdUytVdV0eqsSELr7Z2N8GclT1jpJeSUTeAr5W1U9KH2d0RCRTVTNKLuktdl3eYtflHfF4TW6i6eXSG7gKWCwiC5199wEtAVT1lfIJzRhjTGmUmNBVdRYR109xLX/t0QRkjDGmbLw6UnRMZQdQTuy6vMWuyzvi8ZqKiOqmqDHGmKrPqzV0Y4wxYTyX0EVkkIisFJE1IjKisuMpiYisF5HFIrJQRDKdfQ1FZLKIrHb+beDsFxF53rm2RSLSLeg81zjlV4vINZVwHW+IyDYRWRK0L2bXISLdnd/TGue55bc0esnX9YiIbHLes4Uicl7QsXudGFeKyLlB+13/LkXkBBGZ4+z/UETc1yqL/XW5zsHk5fesmGvy/PsVM6rqmR8gAfgZaA0kA1lAx8qOq4SY1wOpYfueAkY42yOAJ53t84Bv8N2EPg2Y4+xvCKx1/m3gbDeo4OvoC3QDlpTHdQBznbLiPHdwJV7XI8BdLmU7On9z1YETnL/FhOL+LoGPgGHO9ivAzRV0XU2Bbs52HWCVE79n37Nirsnz71esfrxWQ+8BrFHVtap6GPgPMLSSYyqLofj69uP8+4eg/e+oz2ygvog0Bc4FJqtqjqruBCYDgyoyYFWdAeSE7Y7JdTjH6qrqbPX9T3on6FzlKsJ1RTIU+I+qHlLVdcAafH+Trn+XTo21P+AfkxH8OypXGnkOJs++Z8VcUySeeb9ixWsJvRmwIejxRop/Q6sCBSaJyDwRudHZ10RVtzjbvwH+RRgjXV9Vve5YXUczZzt8f2X6X6fp4Q1/swSlv65GQK6q5oftr1ASOgdTXLxnUnReqbh5v46G1xK6F52hqt2AwcCtItI3+KBTu/F8V6N4uQ7Hy8CJQBdgC/DPSo3mKEgxczB59T1zuaa4eb+OltcS+iagRdDj5s6+KktVNzn/bgM+x/d1b6vzlRXnX/+Uw5Gur6ped6yuY5OzHb6/UqjqVlUtUN9kc6/he8+g9Ne1A1/TRWLY/gohvjmYPgXeU9XPnN2efs/crile3q9Y8FpC/wlo69yJTgaGAeMqOaaIRKSW+BYFQURqAQOBJfhi9vcWuAb40tkeB1zt9Dg4DdjlfD2eCAwUkQbO18mBzr7KFpPrcI7tFpHTnHbMq4POVeH8Cc9xIb73DHzXNUxEqovICUBbfDcGXf8unRrwVMC/glfw76i8r0GA14HlGjqhnmffs0jXFA/vV8xU9l3Z0v7guxu/Ct9d6vsrO54SYm2N7w56FrDUHy++trrvgNXAt0BDZ78ALznXthjICDrXn/Hd1FkDXFcJ1/IBvq+zefjaFq+P5XUAGfj+I/4MvIgz6K2SrutdJ+5F+JJC06Dy9zsxriSoV0ekv0vnb2Cuc70fA9Ur6LrOwNecsghY6Pyc5+X3rJhr8vz7FasfGylqjDFxwmtNLsYYYyKwhG6MMXHCEroxxsQJS+jGGBMnLKEbY0ycsIRujDFxwhK6McbECUvoxhgTJ/4/1zm4zOlskasAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "device = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cpu\")  # If no GPU on the machine\n",
    "\n",
    "# train_id = np.random.choice(len(dat), 10000)\n",
    "# train = [dat[i] for i in train_id]\n",
    "train = dat\n",
    "\n",
    "n = len(train)\n",
    "n_hidden = 256\n",
    "nepoch = 100\n",
    "bs = 256\n",
    "\n",
    "rnn = RNN(charset_size, n_hidden)\n",
    "rnn = rnn.to(device=device)\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
    "train_ind = np.arange(n)\n",
    "lossfn = nn.NLLLoss(reduction=\"none\")\n",
    "losses = []\n",
    "\n",
    "t1 = time.time()\n",
    "for k in range(nepoch):\n",
    "    np.random.shuffle(train_ind)\n",
    "    # Update on mini-batches\n",
    "    for j in range(0, n, bs):\n",
    "        # Create mini-batch\n",
    "        ind = train_ind[j:(j + bs)]\n",
    "        mb = [train[i] for i in ind]\n",
    "        mb_size = len(mb)\n",
    "        input, actual_len, target = names2tensor(mb)\n",
    "        input = input.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "        max_len = input.shape[0]\n",
    "        hidden = rnn.init_hidden(mb_size).to(device=device)\n",
    "        loss = 0.0\n",
    "        for s in range(max_len):\n",
    "            output, hidden = rnn(input[s], hidden)\n",
    "            loss_s = lossfn(output, target[s])\n",
    "            valid = torch.tensor((s < actual_len).astype(int)).to(device=device)\n",
    "            loss = loss + loss_s * valid\n",
    "        loss = torch.mean(loss / torch.tensor(actual_len).to(device=device))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if j // bs % 10 == 0:\n",
    "            print(f\"epoch {k}, batch {j // bs}, loss = {loss.item()}\")\n",
    "t2 = time.time()\n",
    "print(t2 - t1)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76a09a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (i2h): Linear(in_features=307, out_features=256, bias=True)\n",
       "  (i2o): Linear(in_features=307, out_features=51, bias=True)\n",
       "  (o2o): Linear(in_features=307, out_features=51, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (logsoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(rnn.state_dict(), \"gen_en.pt\")\n",
    "rnn.load_state_dict(torch.load(\"gen_en.pt\", map_location=device))\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7bec938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雷斯塔\n"
     ]
    }
   ],
   "source": [
    "family_names = np.unique([name[0] for name in dat])\n",
    "def random_family_name():\n",
    "    return np.random.choice(family_names, 1)[0]\n",
    "\n",
    "def random_name(max_len=4):\n",
    "    rnn.eval()\n",
    "    family_name = random_family_name()\n",
    "    input = char2tensor(family_name).to(device=device)\n",
    "    char_ind = [torch.argmax(input).item()]\n",
    "    hidden = rnn.init_hidden(batch_size=1).to(device=device)\n",
    "    for i in range(max_len - 1):\n",
    "        output, hidden = rnn(input, hidden)\n",
    "        ind = torch.argmax(output).item()\n",
    "        if ind == charset_size - 1:\n",
    "            break\n",
    "        char_ind.append(ind)\n",
    "        input.zero_()\n",
    "        input[0, ind] = 1.0\n",
    "    return char_ind\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "ind = random_name(10)\n",
    "print(\"\".join([dict[i] for i in ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "587c6a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['雷斯塔' '伊尔马斯' '瓦尔德' '耶尔维' '西尔韦斯特里' '布拉伊科夫斯基'\n",
      " '库尔蒂耶' '迪亚科' '拉斯特里' '罗斯托' '维尔斯' '马尔基奥' '埃斯特拉德'\n",
      " '维尔斯' '韦尔尼' '维尔斯' '马尔基奥' '格拉斯科' '库尔蒂耶' '尔德'\n",
      " '萨尔瓦尼' '维尔斯' '巴尔巴里尼' '内斯托拉' '克拉斯尼奇' '伊尔马斯'\n",
      " '德拉斯科' '诺尔贝格' '伊尔马斯' '德拉斯科' '马尔基奥' '勒布罗' '达尔马斯'\n",
      " '莱斯科' '瓦尔德' '西尔韦斯特里' '罗斯托' '托尔托拉' '米尔科' '特里斯塔尼'\n",
      " '耶尔维' '罗斯托' '奇科' '贝尔托利尼' '克拉斯尼奇' '迪亚科' '利亚尔迪'\n",
      " '亚尔马' '塔尔迪' '耶尔维']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "names = []\n",
    "for i in range(50):\n",
    "    ind = random_name(10)\n",
    "    names.append(\"\".join([dict[i] for i in ind]))\n",
    "np.set_printoptions(linewidth=50)\n",
    "print(np.array(names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
